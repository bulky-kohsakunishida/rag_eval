{
  "doc-bbf0fec98d89af7805b36aa0590649d4": {
    "status": "processing",
    "chunks_count": 1,
    "content": "テキスト生成AIの \n導入・運用ガイドライン \n \n \n \n2024年7月 \n独立行政法人情報処理推進機構 \n産業サイバーセキュリティセンター \n中核人材育成プログラム 7期生 \n生成AIのセキュリティリスクと対策プロジェクト \n（DALL·E 3を用いて作成）",
    "content_summary": "テキスト生成AIの \n導入・運用ガイドライン \n \n \n \n2024年7月 \n独立行政法人情報処理推進機構 \n産業サイバーセキュリティセンター \n中核人材育成プログラム 7期生 \n生成AIのセキュリティリスクと対策プロジェクト \n（DALL·E 3を用いて作成）",
    "content_length": 131,
    "created_at": "2025-05-12T08:37:34.473803+00:00",
    "updated_at": "2025-05-14T08:35:48.908682+00:00",
    "file_path": "unknown_source"
  },
  "doc-852fc5e518b486f1a61a328587fb5f57": {
    "status": "processing",
    "chunks_count": 1,
    "content": "40 \n \n 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプト（図 \n4-4） \n \n図 4-4: 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプトの例 \n \nまた、Anthropic社やGoogle社、OpenAI社などが公式ドキュメントとして公開している、用途に\n応じたプロンプトのサンプルを参考にすることも、ユーザが望む内容の出力に有効な手段となります。 \n[20] \n \n以上のようなプロンプトのサンプルや参考サイトを利活用ガイドラインに記載することで、ユーザ\nは効果的なプロンプトの書き方を把握し、自身の業務に活用できるプロンプトの書き方の参考とする\nことができます。 \n \n 入力制限に関する項目 \n生成AIに入力したプロンプトが学習データとして利用されると、第三者によるプロンプトの生成物\nにそれらの情報が含まれる可能性があります。 以下に示す情報は、 ユーザによる入力を制限することが\n推奨されます。 \n 著作権保護情報 \n生成物に著作権で保護された内容と類似した内容が含まれる可能性があります。そのような生\n成物の利用は著作権侵害となり、法的トラブルや組織の信用失墜を引き起こします。 \n 個人情報 \n氏名や住所、 電話番号といった情報が学習し生成されると、 プライバシーの侵害に繋がります。 \n 組織の機密情報 \n組織の内部文書や秘密保持契約を締結した情報がプロンプトに含まれると、組織の機密情報が\n漏洩するリスクがあります。",
    "content_summary": "40 \n \n 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプト（図 \n4-4） \n \n図 4-4: 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプトの例 \n \nまた、Anthropic社やGoogle社、OpenAI社などが公式ドキュメントとして公開している、用途に\n応じたプロンプトのサンプルを参考にすることも、ユーザが望む内容の出力に有効な手段となります。 \n[20] \n \n以上のようなプロンプトのサンプルや参考サイトを利活用ガ...",
    "content_length": 660,
    "created_at": "2025-05-12T09:49:11.103552+00:00",
    "updated_at": "2025-05-14T08:35:48.909334+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=42"
  },
  "doc-9a88cdfbe1d4e48cb89f45cc7e666663": {
    "status": "processing",
    "chunks_count": 1,
    "content": "42 \n \n 著作権（※2024年6月時点の情報） [23] \n生成AIが提供する生成物は著作物に該当しない場合があります。著作物は「思想又は感情を\n創作的に表現したものであつて、文芸、学術、美術又は音楽の範囲に属するもの」 （文化庁, 2023, \np.56） とされており、 生成AIの生成物は 「思想又は感情を創作的に表現したもの」 （文化庁, 2023, \np.57）ではないためです。一方で、人が思想感情を創作的に表現するための道具としてAIを使\n用したものと認められれば、 著作物に該当し、 生成AIのユーザが著作者となる場合もあります。\n生成物の著作権に関しては現在も議論が進められているため、常に動向を調査する必要があり\nます。 \n 商用利用の制限 \n生成物の商用利用は、利用する生成AIの利用規約により制限されている場合があります。商\n用利用する際は、必要に応じて許可を得ることが求められます。 \n 権利侵害の確認 \n生成物が以下に該当しないことを確認する必要があります。 \n- 著作権侵害：既存のキャッチコピーや他者の著作物と類似していないか確認します。 \n- 商標権、意匠権侵害：他者の商標や意匠を侵害していないか確認します。 \n- 虚偽の個人情報・名誉毀損：生成物が虚偽の情報を含んでいないか、または個人や団体の\n名誉を毀損する内容でないかを確認します。 \n \n4.2 ユーザへの教育 \n4.2.1 教育によって期待される効果 \n生成AIを効果的に活用するためには、生成AI自体の性能だけでなく、ユーザが適切に生成AIを利用\nすることが必要不可欠です。ユーザが生成AIに関する正しい知識を身に付け適切に活用することによっ\nて、以下に示す2点の効果を得られます。 \n \n 生成AI利用における倫理観およびセキュリティ意識の醸成 \nユーザが生成AIの使用において、 コンプライアンスに留意して知識を深めることで、AIの利用\nにおける倫理観が醸成され、企業の信用失墜のリスクを軽減できます。 \n \n 業務効率の向上 \nユーザが生成AIの操作方法や効果的な使用方法を習得することで、業務の効率化を図り、業務\nプロセスの迅速化と生産性の向上が期待されます。",
    "content_summary": "42 \n \n 著作権（※2024年6月時点の情報） [23] \n生成AIが提供する生成物は著作物に該当しない場合があります。著作物は「思想又は感情を\n創作的に表現したものであつて、文芸、学術、美術又は音楽の範囲に属するもの」 （文化庁, 2023, \np.56） とされており、 生成AIの生成物は 「思想又は感情を創作的に表現したもの」 （文化庁, 2023, \np.57）ではないためです。一方で、人が思想感情を創作的に表現するための道具としてAIを使\n用したものと認められれば、 著作物に該当...",
    "content_length": 940,
    "created_at": "2025-05-12T09:49:11.103557+00:00",
    "updated_at": "2025-05-14T08:35:56.170547+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=44"
  },
  "doc-faf83b456ab613922feb87149390c1ce": {
    "status": "processing",
    "chunks_count": 1,
    "content": "22 \n \n 法的および社会的リスクに関する課題 \nテキスト生成AIのトレーニングデータには第三者の著作物が含まれる場合があり、 意図\nせず著作権を侵害する可能性があります。加えて、データが収集・処理される場合、個人情\n報保護法やGDPRなどの法規制に抵触する可能性もあり罰則や訴訟のリスクもあります。\nまた、テキスト生成AIにはトレーニングデータによってバイアス（偏り、偏見）が発生し\nてしまうことが懸念されています。システムのユーザがバイアスを含んだ回答を正しい情\n報として捉え、その情報を使用する場合、組織の信用失墜や法的トラブルに繋がる可能性\nもあります。 \n \n 攻撃に起因するリスク \nLLMを対象としたサイバー攻撃には多種多様な攻撃が存在しており、AI特有の被害を\n引き起こすサイバー攻撃がいくつか存在しています。 \n有名な攻撃として、LLMや学習データに関する情報の再構築を目的とした情報抽出攻撃\n（プライバシー攻撃） やLLMの応答動作を意図的に操作、 敵対的プロンプトを用いてLLM\nへの入力を誤分類させることを目的とした回避攻撃、LLMを汚染することで誤動作や性能\n劣化を引き起こすことを目的としたポイズニング攻撃などが存在します。 \n \nこのようにテキスト生成AIの組織導入においては、数多くのリスクを検討する必要があります。これ\nらのリスクのうち、導入・運用における内部リスクについては、第3章から第5章で留意事項を述べて\nいきます。 \n \n2.4 テキスト生成AIの組織導入・運用プロセスと担当者 \n本節では、後の第3章～第5章を読む上で、本書が定義する「生成AIの組織導入 ・運用プロセス」の\n全体像と担当者の役割について説明します。なお、以降ではテキスト生成AIを生成AIと呼称します。 \n2.4.1 導入・運用の前提事項 \n本節では、一般的な新技術導入についても当てはまりますが、生成AIの導入・運用プロセス全体を通\nして重要となる要素を以下の3点に分けて説明します。 \n① 段階的導入（スモールスタート） \n② ドキュメンテーション \n③ 継続的改善",
    "content_summary": "22 \n \n 法的および社会的リスクに関する課題 \nテキスト生成AIのトレーニングデータには第三者の著作物が含まれる場合があり、 意図\nせず著作権を侵害する可能性があります。加えて、データが収集・処理される場合、個人情\n報保護法やGDPRなどの法規制に抵触する可能性もあり罰則や訴訟のリスクもあります。\nまた、テキスト生成AIにはトレーニングデータによってバイアス（偏り、偏見）が発生し\nてしまうことが懸念されています。システムのユーザがバイアスを含んだ回答を正しい情\n報として捉え、その情報を使用...",
    "content_length": 895,
    "created_at": "2025-05-12T09:49:11.103503+00:00",
    "updated_at": "2025-05-14T08:35:56.171331+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=24"
  },
  "doc-3f9c57781135eb17d4d9efc06bcefa2b": {
    "status": "pending",
    "content": "92 \n \n \nニューラルネットワーク 人間の脳(ニューロン)の働きを模してコンピュータに学習さ\nせる手法。入力層と出力層の間に中間層を設ける３層化構造\nを用いてデータを分析して学習する。中間層をより多層化し\nたものをディープラーニングと呼ぶ。 \nノイズ HTMLタグや改行コードなどLLMに学習させたいデータ\nやベクトルDBに格納したいデータとは関係のない文字のこ\nと。回答精度の低下につながる。 \nハルシネーション AIが事実に基づかない情報を生成する現象。AIが幻覚（ハ\nルシネーション）を見ているかのようにもっともらしい嘘を\n出力するため、そのように呼ばれる。 \nバックエンド DBなどの直接ユーザの目に触れない部分。生成AIにおい\nては、LLMそのものや、ユーザとLLMの間の処理を行う\n統合ミドルウェア等を指す。 \nビッグデータ 「日々生成される多種多様なデータ群」のこと。Volume\n（大量さ） 、Variety（多種多様さ） 、Velocity（発生頻度・処\n理速度の速さ）という3つのVの特徴を持ち、構造化デー\nタと非構造化データで構成されている。 \nファインチューニング 学習済みのモデルに対して新たなデータを追加で学習させる\n技術で、LLMに限らずディープラーニングで作成されたモ\nデルには広く用いられている。 \nフィッシング攻撃 悪意のある人間が、価値ある情報をユーザから詐取すること\nを目的としたサイバー犯罪。詐取の対象としては、クレジッ\nトカード番号、個人情報、企業データなどが挙げられる。 \nフロントエンド WebサービスやWebアプリケーションで直接ユーザの目に\n触れる部分。生成AIにおいては、Web UI等のユーザが直\n接操作する部分やバックエンドのソフトウェアとのやり取り\nをする部分を指す。 \nブラックボックス 利用者が内部構造や動作原理についてわからない構造になっ\nていること。AIにおいては、どのような判断基準で回答を\n生成しているのかが見えないことを指す。 \nプロンプト 生成AIに対する質問や指示のこと。 \nプロンプトインジェクション 生成AIを意図的に誤作動させるような指令入力を与え、提\n供側が出力を禁止している情報（開発に関する情報、犯罪に\n使われうる情報等）を生成させる攻撃。 \nプロンプトエンジニアリング 生成AIへの問い合わせを具体的に指示し適切に組み合わせ\nることで、目的の出力を生成しやすくするための手法。",
    "content_summary": "92 \n \n \nニューラルネットワーク 人間の脳(ニューロン)の働きを模してコンピュータに学習さ\nせる手法。入力層と出力層の間に中間層を設ける３層化構造\nを用いてデータを分析して学習する。中間層をより多層化し\nたものをディープラーニングと呼ぶ。 \nノイズ HTMLタグや改行コードなどLLMに学習させたいデータ\nやベクトルDBに格納したいデータとは関係のない文字のこ\nと。回答精度の低下につながる。 \nハルシネーション AIが事実に基づかない情報を生成する現象。AIが幻覚（ハ\nルシネーション）を見て...",
    "content_length": 1036,
    "created_at": "2025-05-12T09:49:11.103678+00:00",
    "updated_at": "2025-05-12T09:49:11.103678+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=94"
  },
  "doc-dcdc23d3056c11d0e5ffc327cbc806ab": {
    "status": "pending",
    "content": "35 \n \n3.3.2 RAG利用に関する留意点 \n生成AIの利用において、社内情報を検索するためにRAGを利用する場合、ベクトルDBに格納する\n情報の精査が重要です。以下のような情報が格納された場合、ハルシネーションや誤った回答の出力が\n発生し、回答精度の低下につながります。 \n \n回答精度を低下させる情報の例： \n ノイズが含まれる情報 \n 重複した情報 \n 最新版ではない古い情報 \n \nまた、RAGの利用に関しては、 現在さまざまな課題が存在しています。 以下の課題を認識した上でRAG\nの利用を検討する必要があります。 \n \nRAG利用時の課題の例： \n ベクトルDBに機密情報を含むデータを格納した場合、全てのユーザが機密情報を参照できる。 \n ユーザや部門ごとにRAGに格納するデータを分けることや、 参照するデータに閲覧権限を設定する\nことができない。 \n 従来の方法で上述の課題を解決するためにはRAGの環境を複数構築する必要があり、 コストが高く\nなる。 \n \nこれらの課題については、2024年6月現在も研究が進められているため、組織として最新の動向を確\n認していくことを推奨します。 \n \n3.4 テスト・実装 \nテスト・実装フェーズでは、構築した生成AIシステムの品質を保証するためのテストおよび生成AI\nの実装を行います。本章ではその中でも実装に先立って行われるテストフェーズでの考慮事項について\n記載します。 \n3.4.1 システムテスト \n一般的な新システムを導入する際と同様に、生成AIの導入する際にもシステムテストを行うことは重\n要です。通常のシステムテストの流れに沿って、システムが設計通りに動作しているかどうかを確認す\nる必要があります。",
    "content_summary": "35 \n \n3.3.2 RAG利用に関する留意点 \n生成AIの利用において、社内情報を検索するためにRAGを利用する場合、ベクトルDBに格納する\n情報の精査が重要です。以下のような情報が格納された場合、ハルシネーションや誤った回答の出力が\n発生し、回答精度の低下につながります。 \n \n回答精度を低下させる情報の例： \n ノイズが含まれる情報 \n 重複した情報 \n 最新版ではない古い情報 \n \nまた、RAGの利用に関しては、 現在さまざまな課題が存在しています。 以下の課題を認識した上でRA...",
    "content_length": 746,
    "created_at": "2025-05-12T09:49:11.103534+00:00",
    "updated_at": "2025-05-12T09:49:11.103534+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=37"
  },
  "doc-b052f3737a3d3191b61488bdb58b12a1": {
    "status": "pending",
    "content": "54 \n \n実施タイミング \n \n図 5-4: 導入プロセスとセキュリティ担当の該当フェーズ \n \nリスク管理は、導入時から運用時にわたり、継続的に幾度も実施されるものです。ただ、工程（特定・\n分析・評価・対応）によって、その実施タイミングは僅かに異なると考えられます。リスク対応は、対策\nごとに異なるタイミングで実施されますし、組織ごとに各対応のタイミングは異なります。一方、それ以\n外の3工程については、一般的な推奨タイミングを述べます。 \n図 5-4は、2.4.2で定義した、生成AI導入プロセスにおけるPDCAの1サイクルです。その1サイク\nル内のどこでリスクアセスメントをすればよいかを以下に記載します。 \n \n リスク特定・分析・評価（まとめて「リスクアセスメント」と称す） \n特定の期間を取り、3工程をまとめて実施。 \n 1サイクル目の「要件定義」時 \n理想的には 「運用・評価」時より前の各工程（ 「構想策定」「要件定義」「設計」「テスト・デプロ\nイ」 ）で毎回リスクアセスメントを実施すべきですが、現実的には、初回サイクル時には何かと\n不明点が多く、毎回リスクアセスメントを実施しても十分な結果が得られない（費用対効果が\n見込めない）場合も多いでしょう。そこで本書では、 「要件定義」を必ず実施すべきタイミング\nと定めます （もし1回のみの実施となるなら、ここで実施します） 。リスクアセスメントはなる\nべく早期段階での実施がよいですが、初回サイクルでは何かと不明点が多いため、 「構想策定」\nフェーズでの実施が難しいと考えた結果の推奨です。 \n \n 1サイクル目の「運用・評価」時 \n定期的なリスクアセスメント実施を推奨します。現在、生成AIは発展途上であり、変化が激し\nいため、新たなリスクが明らかになるかもしれません。それを反映して、定期的な実施を推奨し\nます。 \n \n 2サイクル目以降の「要件定義」時 \n生成AIシステムに何らかの改修を行う場合は、2サイクル目のPDCAを実施します。この時\nには、再度「要件定義」時にリスクアセスメントを実施しましょう。",
    "content_summary": "54 \n \n実施タイミング \n \n図 5-4: 導入プロセスとセキュリティ担当の該当フェーズ \n \nリスク管理は、導入時から運用時にわたり、継続的に幾度も実施されるものです。ただ、工程（特定・\n分析・評価・対応）によって、その実施タイミングは僅かに異なると考えられます。リスク対応は、対策\nごとに異なるタイミングで実施されますし、組織ごとに各対応のタイミングは異なります。一方、それ以\n外の3工程については、一般的な推奨タイミングを述べます。 \n図 5-4は、2.4.2で定義した、生成AI導入プロセ...",
    "content_length": 895,
    "created_at": "2025-05-12T09:49:11.103585+00:00",
    "updated_at": "2025-05-12T09:49:11.103586+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=56"
  },
  "doc-36991f0761ac83c176f9dc2028a15995": {
    "status": "pending",
    "content": "3.2.1 実現可能性の検討 ........................................................................................... 28 \n3.2.2 目標の設定 ...................................................................................................... 29 \n3.2.3 利害関係者の整理 ........................................................................................... 29 \n3.2.4 リスクアセスメント ....................................................................................... 30 \n3.2.5 システムの選定............................................................................................... 30 \n3.2.6 回答精度向上における選択肢 ......................................................................... 34 \n3.3 設計・開発 ............................................................................................................. 34 \n3.3.1 導入ベンダへのフィードバック ..................................................................... 34 \n3.3.2 RAG利用に関する留意点 .............................................................................. 35 \n3.4 テスト・実装 .......................................................................................................... 35 \n3.4.1 システムテスト............................................................................................... 35 \n3.4.2 生成AIの性能評価 ......................................................................................... 36 \n3.4.3 利活用ガイドラインの策定 ............................................................................ 36 \n第4章 生成AIの運用について ......................................................................................... 37 \n4.1 利活用ガイドラインの策定 .................................................................................... 37 \n4.1.1 利活用ガイドライン策定の重要性 ................................................................. 37 \n4.1.2 利活用ガイドラインに記載すべき項目 .......................................................... 38 \n4.2 ユーザへの教育 ...................................................................................................... 42 \n4.2.1 教育によって期待される効果 ......................................................................... 42 \n4.2.2 ユーザへの教育方法 ....................................................................................... 43 \n4.3 生成AIの更新管理 ................................................................................................ 43 \n4.3.1 透明性の確保と維持 ....................................................................................... 43 \n4.3.2 RAGを利用する場合の注意 ........................................................................... 46 \n4.4 評価とフィードバック ........................................................................................... 46 \n4.4.1 評価項目の策定............................................................................................... 46 \n4.4.2 ユーザとの情報共有 ....................................................................................... 48 \n4.4.3 評価結果を踏まえた各種改善 ......................................................................... 49 \n第5章 生成AIのリスク管理について .............................................................................. 50 \n5.1 生成AIに関するセキュリティインシデント事例 ................................................. 50 \n5.2 リスク管理全体の概観 ........................................................................................... 52 \n5.3 生成AIにおけるリスクアセスメントの例 ............................................................ 55 \n5.3.1 特定・分析に向けた一般的な生成AIリスクの把握 ...................................... 55 \n5.3.2 特定の例 ......................................................................................................... 57 \n5.3.3 分析の例 ......................................................................................................... 58 \n5.3.4 評価の例 ......................................................................................................... 60 \n5.4 リスク対応 ............................................................................................................. 60",
    "content_summary": "3.2.1 実現可能性の検討 ........................................................................................... 28 \n3.2.2 目標の設定 ...................................................................................................... 29 \n3.2.3 利害関係者の整理 ........",
    "content_length": 3840,
    "created_at": "2025-05-12T09:49:11.103449+00:00",
    "updated_at": "2025-05-12T09:49:11.103450+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=4"
  },
  "doc-19dda3abfde6045d4184c432922d4609": {
    "status": "pending",
    "content": "66 \n \n5.4.3 生成AIにおける最新の攻撃手法 \nこれまで、生成AIにおけるリスクアセスメントとリスク対応について説明しました。今回はOWASP\nに記載されているリスクを元に解説を行いましたが、現在も生成AIに対する新たな攻撃手法や脆弱性は\n報告され続けています。ここでは、現在研究されている攻撃手法の一例として、間接プロンプトインジェ\nクションについて説明します。 \n \nRAG（検索拡張生成）への攻撃手法（間接プロンプトインジェクション） \n間接プロンプトインジェクションとは、回答生成時にWebクロールを行う生成AIを対象とした攻撃\nです。この攻撃により、攻撃者は事前にウェブサイトに記載しているデータの中に悪意のある指示文を\n紛れ込ませ、生成AIに指示を与えてその挙動を乗っ取ることができます（図 5-13） 。 \n \n \n \n図 5-13: 間接プロンプトインジェクションにおけるイメージ \n \n今後、生成AIの組織における活用が増加すればするほど、生成AIに対する攻撃は高度化し、増加し\nていくことが懸念されます。 \nまた、攻撃者が生成AIを利用して攻撃を仕掛けるケースも考えられます。セキュリティ担当者として\nは、このような新たなセキュリティリスクが常に増え続けることを念頭に置きながらリスクマネジメン\nトを行いましょう。",
    "content_summary": "66 \n \n5.4.3 生成AIにおける最新の攻撃手法 \nこれまで、生成AIにおけるリスクアセスメントとリスク対応について説明しました。今回はOWASP\nに記載されているリスクを元に解説を行いましたが、現在も生成AIに対する新たな攻撃手法や脆弱性は\n報告され続けています。ここでは、現在研究されている攻撃手法の一例として、間接プロンプトインジェ\nクションについて説明します。 \n \nRAG（検索拡張生成）への攻撃手法（間接プロンプトインジェクション） \n間接プロンプトインジェクションとは、回答生成時...",
    "content_length": 572,
    "created_at": "2025-05-12T09:49:11.103615+00:00",
    "updated_at": "2025-05-12T09:49:11.103616+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=68"
  },
  "doc-c537be7393c4078879e2d9bdaac9eb4c": {
    "status": "pending",
    "content": "74 \n \n6.1.4 RAGを業務に活用する上での課題 \n ヒアリング内容 \nRAG （Retrieval-Augmented Generation） を既に導入済み、 または現在導入を検討中の組織に対し、\n「どのような運用をしているのか」 、 「RAGの導入に伴い新たに発生したリスクや課題は何か」につ\nいてヒアリングを実施しました。 \n \n ヒアリング結果 \nRAGはまだ比較的新しい技術であるため、既に導入が完了している組織は一部に限られていまし\nた。運用体系としては、RAG導入時から全社のデータをベクトルDBに格納するわけではなく、部\n門単位やプロジェクト単位で利用申請を行い、ドキュメントを単位毎に領域を分けてベクトルDB\nに格納し、その中で検索を実行するという運用を行う組織が多く見られました。 \nまた、現在はRAG未導入の組織でも、導入検討が進められており、今後のRAG活用は増加して\nいくと感じました。 \n一方、RAGを活用する組織の課題としては、回答精度に関するものが多く挙げられました。本課\n題においてはシステムに関する課題とユーザに関する課題の2つが存在すると考えられます。 \nまずシステムに関する課題では、RAGという技術は、第2章にも記載したように、ベクトルDB\nに格納したドキュメントを元に回答を作成するため、通常の生成AIよりも、特定分野における回答\n精度を向上させることができます。しかし、第4章にも記載したように、RAGを活用したとしても\nハルシネーションのリスクをなくすことはできません。そのため、RAGを活用したシステムであっ\nたとしてもユーザが求める回答を得ることができず、回答精度を高める手法を模索している段階と\nいう印象を受けました。 \nユーザに関する課題としては、ユーザがRAG活用に期待する効果と、現実的にRAGでできるこ\nとの間にある認識のギャップが大きいことが挙げられます。このギャップを埋めるため、各組織は\nガイドラインや定期的な情報周知で対応しようとしていましたが、このギャップを完全に埋めるこ\nとは難しい状況にあるようです。 \n \n6.2 生成AIシステム導入に際した懸念事項 \nヒアリングでは、どの組織も共通して生成AI導入後に2つの懸念事項を抱えていました。1つ目はサ\nービス利用における既存の規程やガイドラインとの兼ね合い、2つ目は導入したシステムの利用率の低さ\nです。以下でそれぞれの懸念について詳しく解説します。",
    "content_summary": "74 \n \n6.1.4 RAGを業務に活用する上での課題 \n ヒアリング内容 \nRAG （Retrieval-Augmented Generation） を既に導入済み、 または現在導入を検討中の組織に対し、\n「どのような運用をしているのか」 、 「RAGの導入に伴い新たに発生したリスクや課題は何か」につ\nいてヒアリングを実施しました。 \n \n ヒアリング結果 \nRAGはまだ比較的新しい技術であるため、既に導入が完了している組織は一部に限られていまし\nた。運用体系としては、RAG導入時から全...",
    "content_length": 1044,
    "created_at": "2025-05-12T09:49:11.103634+00:00",
    "updated_at": "2025-05-12T09:49:11.103635+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=76"
  },
  "doc-9be437b46ca04e8acba57636c0c6c70d": {
    "status": "pending",
    "content": "67 \n \n5.5 実機検証 \n5.5.1 ガードレールの実装 \n本ガイドラインではガードレール6の実装として、Apache License, Version 2.0.として公開されている\nNVIDIAのNeMo GuardrailsというOSSで検証しています。 \nまた、検証に使用したオンプレ環境を表 5-4に示します。 \n \n表 5-4: オンプレ検証環境の構成の一部 \n \n \n本ツールは、特定の話題に応答しないように制限する機能や敵対的プロンプトを防ぐことができます。\n設定ファイルに制限したい事象と関連がある文字列やその応答文、入出力ポリシーを設定することがで\nきます。 \n  \n \n6 ユーザの入力やLLMの出力を評価しフィルタリングする手法。有害なコンテンツ（特定の話題を制\n限する）や敵対的なプロンプト文を制限することができる。",
    "content_summary": "67 \n \n5.5 実機検証 \n5.5.1 ガードレールの実装 \n本ガイドラインではガードレール6の実装として、Apache License, Version 2.0.として公開されている\nNVIDIAのNeMo GuardrailsというOSSで検証しています。 \nまた、検証に使用したオンプレ環境を表 5-4に示します。 \n \n表 5-4: オンプレ検証環境の構成の一部 \n \n \n本ツールは、特定の話題に応答しないように制限する機能や敵対的プロンプトを防ぐことができます。\n設定ファイルに制限し...",
    "content_length": 373,
    "created_at": "2025-05-12T09:49:11.103618+00:00",
    "updated_at": "2025-05-12T09:49:11.103619+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=69"
  },
  "doc-080846f0932be5c168336b972e266225": {
    "status": "pending",
    "content": "58 \n \n今回は、例示することが目的であるため、簡易的に生成AI特有のリスクのみを考えます。 \n 「a) 資産の特定」では、今回の資産は、図 5-5の構成に存在する資産のみを考えまし\nた。 \n 「b) リスクの特定」では、OWASP T op 10 for LLMの中から選出5した5つのリスクのみ\nを考え、その5つのリスクが図 5-5の構成図内の資産に存在するかを考えました。 \nその結果が表 5-2です。 \n \n表 5-2: リスクとアセットの対応表 \n \n \n5.3.3 分析の例 \nリスク特定の結果を基に、リスク分析を行いましょう。分析は以下の手順で実施します（この手順は一\n例であり、実際の手順は組織で決定すればよいです） 。 \na) 前節で特定したリスク毎に、影響度を3ランク（High、Medium、Low）に分類。同じ\nく、リスクの発生可能性を3ランクに分類。 \nb) 上記ランクから、リスクマトリクスを作成。 \n \n手順a) 影響度と発生可能性の決定 \n影響度の決定では、そのリスクが顕在化した場合に想定される影響度や、影響範囲（連携しているシス\nテムまで影響するか等）を基準とします。今回は、次の観点でランク分けを行いました。 \n 生成AIシステム以外の組織内システムへの被害拡大の可能性 \n 組織の機密情報漏洩に繋がる可能性 \n  \n \n5 現時点で、組織としての対応優先度が比較的高いと思われるリスクを選出した。",
    "content_summary": "58 \n \n今回は、例示することが目的であるため、簡易的に生成AI特有のリスクのみを考えます。 \n 「a) 資産の特定」では、今回の資産は、図 5-5の構成に存在する資産のみを考えまし\nた。 \n 「b) リスクの特定」では、OWASP T op 10 for LLMの中から選出5した5つのリスクのみ\nを考え、その5つのリスクが図 5-5の構成図内の資産に存在するかを考えました。 \nその結果が表 5-2です。 \n \n表 5-2: リスクとアセットの対応表 \n \n \n5.3.3 分析の例 \nリス...",
    "content_length": 623,
    "created_at": "2025-05-12T09:49:11.103595+00:00",
    "updated_at": "2025-05-12T09:49:11.103596+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=60"
  },
  "doc-48b2084285c3f473bf82c87c3c928091": {
    "status": "pending",
    "content": "62 \n \n具体的な入口対策の例を以下に示します。 \n プロンプト文の検証 \n拒否する文字列（コードの実行などを促すものなど）を事前に登録し、プロンプト文に該当の文字\n列が含まれていないかを確認する。これにより、システムへの侵害を事前に防ぐことができる。 \n ガードレールの設置 \nガードレールを設置することで、入力されたプロンプト文が事前に設定したポリシーに違反してい\nるかLLMを使用して検証する。これにより、表現の違いによる攻撃の軽減することができる。 \n ログの保存 \nユーザが入力したプロンプト文を保存する。後に「出口対策」に記載する出力に関するログを一緒\nに保存することで、生成物に対する問題が発生した際には、確認を行うことができる。 \n \n内部対策 \n内部対策では、 バックエンドにある統合ミドルウェアやLLMと連携システムとの処理を行う場所での\n対策を考えます。図 5-5のシステム構成図における入口対策の場所を、図 5-10に緑色の盾マークで示\nします。 \n \n図 5-10: 内部対策場所のイメージ \n \n具体的な内部対策の例を以下に示します。 \n 権限管理 \n統合ミドルウェアなどのバックエンドで実行されているソフトウェアを管理者権限ではなく、必要\n最小限の権限で実行する。これにより、LLMによって生成されたコマンドによる被害を軽減するこ\nとができる。",
    "content_summary": "62 \n \n具体的な入口対策の例を以下に示します。 \n プロンプト文の検証 \n拒否する文字列（コードの実行などを促すものなど）を事前に登録し、プロンプト文に該当の文字\n列が含まれていないかを確認する。これにより、システムへの侵害を事前に防ぐことができる。 \n ガードレールの設置 \nガードレールを設置することで、入力されたプロンプト文が事前に設定したポリシーに違反してい\nるかLLMを使用して検証する。これにより、表現の違いによる攻撃の軽減することができる。 \n ログの保存 \nユーザが入力した...",
    "content_length": 592,
    "created_at": "2025-05-12T09:49:11.103604+00:00",
    "updated_at": "2025-05-12T09:49:11.103605+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=64"
  },
  "doc-0d4f9032f9d8d1592b7ffa0242c02f60": {
    "status": "pending",
    "content": "46 \n \n4.3.2 RAGを利用する場合の注意 \nLLMが学習していない内容のうちRAGを使用して精度の高い回答が得られるのは、ベクトルDBを\n検索して得られた質問に関連した上位数件のデータの内容のみです。そのため、ベクトルDBに格納さ\nれていない新しい情報について質問する場合や、ベクトルDBに古い情報や重複した情報が存在する場\n合には、誤った回答を生成する可能性が高くなります （図 4-9） 。そのため、RAGの精度の維持には、ベ\nクトルDBに格納されている情報の更新を定期的に行い、できるだけ最新かつ内容が重複しない状態に\n保つことが重要になります。 \n \n \n図 4-9: ベクトルDB内のデータが重複している場合 \n \nまた、ベクトルDBに格納されている情報の重要度に関しても考慮が必要です。注意点として、格\n納した情報はユーザ全員が閲覧する可能性があるため対象ユーザの役職と所属部署に適していること\nを確認する必要があります。 \n \n4.4 評価とフィードバック \n4.4.1 評価項目の策定 \n導入効果の評価とフィードバックを定期的に行うことが重要です。導入した生成AIを継続して使用し\n続けるかの判断や使用実績を踏まえたより効果的な活用のため、生成AIを導入した目的を振り返り、当\n初目的に対しての達成度合いや定量・定性的な効果を評価することが必要です。 \n生成AIの評価軸を以下に示します。 評価軸は導入目的によって異なるため、 以下に代表例を示します。",
    "content_summary": "46 \n \n4.3.2 RAGを利用する場合の注意 \nLLMが学習していない内容のうちRAGを使用して精度の高い回答が得られるのは、ベクトルDBを\n検索して得られた質問に関連した上位数件のデータの内容のみです。そのため、ベクトルDBに格納さ\nれていない新しい情報について質問する場合や、ベクトルDBに古い情報や重複した情報が存在する場\n合には、誤った回答を生成する可能性が高くなります （図 4-9） 。そのため、RAGの精度の維持には、ベ\nクトルDBに格納されている情報の更新を定期的に行い、できる...",
    "content_length": 639,
    "created_at": "2025-05-12T09:49:11.103567+00:00",
    "updated_at": "2025-05-12T09:49:11.103567+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=48"
  },
  "doc-d71453296bc166364cadcf8b0f58f3d5": {
    "status": "pending",
    "content": "68 \n \n特定の話題に応答しないようにする機能 \n特定の話題に応答しないようにガードレールを設定する場合、担当者が特定のキーワードやフレーズ\nを指定（図 5-14）し、それに基づいてAIモデルが応答を回避するように設定します。この設定により、\n設定した話題に関連する質問やコメントを受けた場合、予め決められた無害な応答を返すか、その話題\nに関しては応答を避けるようになります。 \n \n図 5-14: 政治に関する情報を制限する設定（Colang7形式） \n \n「deﬁne user ask about politics」では、制限したい話題に関連するキーワードやフレーズを登録するこ\nとができます。検索にはベクトル検索8が使用されているため、プロンプト文で全く同じ文章やキーワー\nドを入力せずとも似たような文章であれば、検知することができます。また、検知した際のユーザへの返\n答は、 「deﬁne bot refuse to about politics」で設定が可能です。ここで、 「politics」は、担当者が適宜設定\nする変数です。 \n実際に図 5-14で政治に関する制限をした後に、 チャットアプリにて政治に関する内容をプロンプト文\nに入力し問い合わせると、制限されていることがわかります（図 5-15） 。 \n \n図 5-15: 政治に関する話題が制限されているイメージ \n  \n \n7 会話型アプリケーション用のモデリング言語。 \n8 テキストや画像などのデータを数値ベクトルとして表現し、それらのベクトル間のコサイン類似度を\n計算することで、関連する情報を見つけ出す検索方法のこと。",
    "content_summary": "68 \n \n特定の話題に応答しないようにする機能 \n特定の話題に応答しないようにガードレールを設定する場合、担当者が特定のキーワードやフレーズ\nを指定（図 5-14）し、それに基づいてAIモデルが応答を回避するように設定します。この設定により、\n設定した話題に関連する質問やコメントを受けた場合、予め決められた無害な応答を返すか、その話題\nに関しては応答を避けるようになります。 \n \n図 5-14: 政治に関する情報を制限する設定（Colang7形式） \n \n「deﬁne user ask abo...",
    "content_length": 701,
    "created_at": "2025-05-12T09:49:11.103620+00:00",
    "updated_at": "2025-05-12T09:49:11.103621+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=70"
  },
  "doc-fcbc16a2127950bd8a12e45fd561dd3e": {
    "status": "pending",
    "content": "33 \n \nしかし、海外リージョンを利用する場合、データベースが海外に設置されていることから、デ\nータの格納が安全保障貿易管理（輸出管理）の対象となる可能性があるため注意が必要です。ま\nた、セキュリティについても、サービス提供側で実施されている対策は必ずしも完璧なものでは\nないという点にも注意が必要です。利用するサービスや設定によっては自社のデータが外部に漏\n洩するリスクも存在するため、利用する際には適切なセキュリティ設定が求められます。 \n \nサービスの例： \n- Amazon Bedrock （AWS） \n- Azure OpenAI （Azure） \n- Vertex AI （GCP） \n \n SaaS型 \nSaaS型は、 各社が構築した生成AIのサービスをネットワーク経由で利用する方式のことです。\nSaaS型のサービスを利用することで、組織への生成AI導入や運用にかかる手間を大幅に軽減で\nきます。生成AIのサービスをインターネット経由で即座に利用開始でき、サービスの管理やセキ\nュリティ対策も提供者側が行うため、ユーザ側の管理負荷を抑えながら、常に最新の機能を利用\nできます。一方、SaaS型のサービスは標準化された機能セットを提供するため、一般的には自社\nのニーズに合わせたカスタマイズが難しいとされています。また、利用するサービスやその設定\n内容によっては入出力データがサービス提供者側の生成AIに学習される可能性があり、PaaS型\nのセキュリティリスクやリージョンの問題と併せて注意が必要です。 \n \nサービスの例： \n- ChatGPT Enterprise （Open AI） \n- Claude 3 Opus（Anthropic） \n- Copilot for Microsoft 365 （Microsoft）  \n- Gemini Advanced（Google） \n \n ハイブリッド型 \nハイブリッド型とは、AI提供者が提供しているAPIを利用して、組織に生成AIシステムを導入する\n方法です。自社のシステムからAPIを経由して生成AI機能を呼び出して利用することで、自社システム\nとの連携が容易となる点が特徴です。しかし、クラウド型と同様、入出力データが外部サーバに保存され\nる場合があるなどのセキュリティリスクもあり、利用する際には適切なセキュリティ設定が必要です。\n利用するモデルやAPIごとにサービスの仕様や制限をしっかりと確認することが重要です。",
    "content_summary": "33 \n \nしかし、海外リージョンを利用する場合、データベースが海外に設置されていることから、デ\nータの格納が安全保障貿易管理（輸出管理）の対象となる可能性があるため注意が必要です。ま\nた、セキュリティについても、サービス提供側で実施されている対策は必ずしも完璧なものでは\nないという点にも注意が必要です。利用するサービスや設定によっては自社のデータが外部に漏\n洩するリスクも存在するため、利用する際には適切なセキュリティ設定が求められます。 \n \nサービスの例： \n- Amazon Bedrock...",
    "content_length": 1050,
    "created_at": "2025-05-12T09:49:11.103529+00:00",
    "updated_at": "2025-05-12T09:49:11.103530+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=35"
  },
  "doc-af5c0e52e94376cd4dc2d7fbb721c34a": {
    "status": "pending",
    "content": "32 \n \n以下に3つの導入環境について説明します。 \n \n オンプレ型 \nオンプレ型とは、自社で保有するサーバ上にAIサーバを構築し運用することで組織に生成AIを導入\nする方式のことです。全てのリソースを完全に自社の管理下に置くことができるためカスタマイズの自\n由度が高く、情報流出等のセキュリティリスクを抑えることができます。しかし、環境を構築するために\nは高度な専門知識が必要となり、多くのコストや開発期間がかかる点に注意が必要です。 \n \n クラウド型 \nクラウド型とは、クラウドサービスを利用して組織に生成AIを導入する方式のことです。現在、各ク\nラウドプロバイダーから生成AIを導入するためのさまざまなサービスが提供されています。オンプレ環\n境に生成AIを導入する場合と比べて導入難易度が低く、管理の手間も少なく済みます。しかし、入出力\nデータが外部サーバに保存されるなどのセキュリティリスクがあり、入力データを学習許可させないオ\nプトアウト申請などのセキュリティの検討が必要となります。また、サービスごとに設定できる内容も\n異なるため、導入前に各サービスの仕様や制約をしっかりと確認することも必要です。 \nまたクラウド環境を利用した環境構築において、 担当者に割り振る権限の調整が重要となります。 組織\n内でRAG環境を構築する場合、割り当てられた担当者の権限によっては、利用が制限される機能が存在\nします。そのため、円滑な生成AIシステムの導入にあたり、担当者への権限付与の設定が重要です。 \nクラウド型には利用するクラウドの形式によって、さらにPaaS型とSaaS型の2種類が存在します。\nSaaS型を利用する際は特に利用規約やセキュリティについて留意しましょう。 \n \n PaaS型 \nPaaS型は、モデルの開発や既存モデルの利用・デプロイを簡素化するためのプラットフォーム\nを提供するサービスのことです。PaaS型のサービスを利用することで、生成AIシステムを構築\nする上でネックとなるリソースをアウトソーシングすることができ、また、提供されているさま\nざまな機能を活用することで効率的に開発を行うことができます。セキュリティについてもサー\nビス提供者側で対策を講じている場合が多く、一定のセキュリティレベルが担保されています。",
    "content_summary": "32 \n \n以下に3つの導入環境について説明します。 \n \n オンプレ型 \nオンプレ型とは、自社で保有するサーバ上にAIサーバを構築し運用することで組織に生成AIを導入\nする方式のことです。全てのリソースを完全に自社の管理下に置くことができるためカスタマイズの自\n由度が高く、情報流出等のセキュリティリスクを抑えることができます。しかし、環境を構築するために\nは高度な専門知識が必要となり、多くのコストや開発期間がかかる点に注意が必要です。 \n \n クラウド型 \nクラウド型とは、クラウドサービス...",
    "content_length": 978,
    "created_at": "2025-05-12T09:49:11.103527+00:00",
    "updated_at": "2025-05-12T09:49:11.103527+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=34"
  },
  "doc-84cf8b6c7edcc5428fb3b0bb52071295": {
    "status": "pending",
    "content": "19 \n \nまた、 テキスト生成AIの回答精度向上を目的にRAGを導入した場合にも同様にギャップが存在します。 \n \n誤解例⑤ RAGを利用するとどのような質問に対しても正しく回答できる \nRAGを利用して回答精度が向上するのはベクトルDBに格納された情報についてのみであり、ベクト\nルDBに格納されていない情報については回答精度が向上しません。そのため、RAGを利用したテキス\nト生成AIをユーザに活用してもらう場合には、どのような情報について回答できるのか周知しておく必\n要があります。 \n \n誤解例⑥ ベクトルDBに格納した情報であれば正確に回答できる \n必ずしも正確な回答ができるとはいえません。RAGを使用していたとしてもテキスト生成AIの根幹\nであるLLMによる回答を生成する仕組みは変わらないため、 前述したとおり誤った回答を出力する可能\n性があります。 \n \n上記の事例以外にも多くの制約や過剰な期待による認識誤りがあると考えられ、関連する学術論文も\n発表されています [12]。そのためテキスト生成AIの効果的な活用には、ユーザがテキスト生成AIに対\nして認識を誤りやすい事象について十分に理解しておく必要があります。テキスト生成AIは強力なツー\nルではありますが、決して万能ではないため、利用には人間の判断と組み合わせることが重要です。ユー\nザは出力内容を単純に鵜呑みにせず、常に批判的に検証した上で利用すべきです。 \n \n2.3 テキスト生成AIの組織導入に向けて \n2.3.1 テキスト生成AI導入と課題 \nテキスト生成AIを組織に導入する上では、課題やリスクを正しく認識し対策を講じることがポイント\nとなります。本項では、1.1.4でも触れた組織が感じているさまざまな課題を改めて整理していきます。 \n組織が感じている課題には、利用時のプロンプトエンジニアリングに関するサポートやユーザの過剰\nな期待、機密情報の流出や意図しない著作権侵害などのリスクも含まれています。 \n課題やリスクへの対応に関する1つの指針として、NISTのAI RMFでは信頼できるAIシステムの特\n徴という形で提唱されています。この指針を認識した上で、組織導入におけるテキスト生成AIの考慮す\nべきリスクについて述べていきます。",
    "content_summary": "19 \n \nまた、 テキスト生成AIの回答精度向上を目的にRAGを導入した場合にも同様にギャップが存在します。 \n \n誤解例⑤ RAGを利用するとどのような質問に対しても正しく回答できる \nRAGを利用して回答精度が向上するのはベクトルDBに格納された情報についてのみであり、ベクト\nルDBに格納されていない情報については回答精度が向上しません。そのため、RAGを利用したテキス\nト生成AIをユーザに活用してもらう場合には、どのような情報について回答できるのか周知しておく必\n要があります。 \n \n誤...",
    "content_length": 964,
    "created_at": "2025-05-12T09:49:11.103495+00:00",
    "updated_at": "2025-05-12T09:49:11.103496+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=21"
  },
  "doc-9741bd49a5028cbbdd6855335a47c723": {
    "status": "pending",
    "content": "55 \n \n 2サイクル目以降の「運用・評価」時 \n1サイクル目と同様、定期的なリスクアセスメント実施を推奨します。 \n \n リスク対応 \n対策ごとに、異なるタイミングで実施。具体的なタイミングは組織によって異なります。 \n \n注意事項 \n リスク管理では、セキュリティ担当者には導入者や運用者と協力することが求められます。また、 導\n入者・運用者のほかにも必要な関係者と協力しましょう。組織・チームとして取り組むことで、抜け\n漏れの少なく、精度の高いリスクの特定・分析・評価に繋がります。 \n リスク評価は、 リスク対策を決める意思決定の工程となります。 ゆえに、 経営層をはじめとした意思\n決定者の協力が得ることが重要です。 \n \n5.3 生成AIにおけるリスクアセスメントの例 \n5.3.1 特定・分析に向けた生成AIリスクの把握 \n \n※本節のリスクアセスメントで使用する構成は一例であり、実際には、所属組織の構成を把握し、リス\nクと照らし合わせた上で実施してください。 \n \n本節では、リスク特定・分析を行う上で参考となるように、生成AI特有のリスクを紹介します。ここ\nでは「OWASP Top 10 for LLM」を使って、一般的な生成AI特有のリスクを見ていきましょう。なお、\nリスクがシステム上のどこに発生するかを併せて紹介4しますが、そのシステムは、3.2.5にて定義したハ\nイブリッド型またはオンプレ型を想定しています（図 5-5。これは図 2-5の再掲） 。 \n  \n \n4 実際にリスク特定を行う際には、資産に対してリスクを特定します。その参考となるように、ここ\nで、代表的な生成AIシステム構成のどこに、何のリスクが紐づくかを紹介します。",
    "content_summary": "55 \n \n 2サイクル目以降の「運用・評価」時 \n1サイクル目と同様、定期的なリスクアセスメント実施を推奨します。 \n \n リスク対応 \n対策ごとに、異なるタイミングで実施。具体的なタイミングは組織によって異なります。 \n \n注意事項 \n リスク管理では、セキュリティ担当者には導入者や運用者と協力することが求められます。また、 導\n入者・運用者のほかにも必要な関係者と協力しましょう。組織・チームとして取り組むことで、抜け\n漏れの少なく、精度の高いリスクの特定・分析・評価に繋がります。 \n...",
    "content_length": 737,
    "created_at": "2025-05-12T09:49:11.103588+00:00",
    "updated_at": "2025-05-12T09:49:11.103589+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=57"
  },
  "doc-3953775760fdec198a30bf89ff444334": {
    "status": "pending",
    "content": "5.4.1 多層防御 ......................................................................................................... 61 \n5.4.2 チェックリストの作成 .................................................................................... 64 \n5.4.3 生成AIにおける最新の攻撃手法 ................................................................... 66 \n5.5 実機検証 ................................................................................................................. 67 \n5.5.1 ガードレールの実装 ....................................................................................... 67 \n5.5.2 RAGにおけるアクセス管理の実装 ................................................................ 70 \n第6章 組織ヒアリング分析 ............................................................................................... 71 \n6.1 ヒアリング結果から見る組織の生成AIとの在り方 ............................................. 71 \n6.1.1 導入目的とプロセス ....................................................................................... 71 \n6.1.2 セキュリティとガイドライン ......................................................................... 72 \n6.1.3 ユーザのフィードバック ................................................................................ 73 \n6.1.4 RAGを業務に活用する上での課題 ................................................................ 74 \n6.2 生成AIシステム導入に際した懸念事項 ................................................................ 74 \n第7章 各国の動向 ............................................................................................................. 78 \n7.1 開発と投資について ............................................................................................... 78 \n7.1.1 米国について .................................................................................................. 78 \n7.1.2 欧州の生成AI ................................................................................................. 79 \n7.2 法規制について ...................................................................................................... 80 \n7.2.1 米国の場合 ...................................................................................................... 81 \n7.2.2 EUの場合 ....................................................................................................... 81 \n7.3 日本 ........................................................................................................................ 83 \n第8章 終わりに ................................................................................................................. 86 \n8.1 あとがき ................................................................................................................. 86 \n8.2 謝辞 ........................................................................................................................ 87 \n付録  ................................................................................................................................... 88 \n用語集 ................................................................................................................................ 88 \n参照文献 ............................................................................................................................. 95",
    "content_summary": "5.4.1 多層防御 ......................................................................................................... 61 \n5.4.2 チェックリストの作成 .................................................................................... 64 \n5.4.3 生成AIにおける最新の攻撃手法 ....",
    "content_length": 3089,
    "created_at": "2025-05-12T09:49:11.103452+00:00",
    "updated_at": "2025-05-12T09:49:11.103453+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=5"
  },
  "doc-1dc8fb0443e4dd65531cfd79dfeebdf0": {
    "status": "pending",
    "content": "84 \n \nAIは未完成な技術であり、今後追い付ける可能性があると考えます。その一つが学習データの枯渇に\n関する問題です。AI Index Reportでは、 「信頼のおけるテキストデータは2024年に、中程度信頼のおけ\nるデータは2030年代に、画像データは2040年代までに枯渇する」可能性について触れています。つま\nり、 信頼のおけるデータが枯渇する2024年を境目にAIの性能向上が鈍化する可能性を示唆しています。\n2つ目は、よりスマートなAIの開発です。生成AIを開発するには大規模なスーパーコンピュータを使\nう必要があり、大きな電力を消費しています [59]。運用についても同様です。そこで、より小さい処理\n量で演算を行う省エネルギーなAIの開発が求められています。このスリムなAIの開発はただの投資額\nの競争ではありませんし、省エネルギーなスリムなAIの開発は世界的に成長の余地があります。スリム\nなAIが、AI開発における日本の存在感を高める契機となることを期待しています。 \n \nまた日本政府も、経済安全保障においてAIの重要性を強く認識しており、国内企業がAI開発を行う\nスーパーコンピュータの整備を後押しするなど、開発支援に力を入れていく方針を打ち出しています \n[60]。日本が日本独自の価値観に合うAIを開発していくことは、AIがより高度化し信頼を獲得した際\nに、日本独自の価値観を維持 ・保護することに繋がります。価値観の違いは発想の違いを生み出し、発想\nの違いは他国と異なるビジネスに繋がる可能性があります。そもそも世界中で多様な文化が保たれるた\nめに、各国が各々のAIを開発していくことは重要です。 \n日本企業がAIを活用したビジネスの差別化を実現するためには、AIの目的、 利用範囲の設定が重要で\nす。そもそも現在普及している生成AIは「どんなことでも解決すること」を目的とした開発を行ってい\nるため、より広く多くの学習データと高性能なスーパーコンピュータを必要とします。しかし、ビジネス\nにおいて「どんなことでも解決すること」は、必ずしも求められているわけではありません。 \nビジネスにおいて重要な要素は自社と他社と間で違いを生むこと、つまり差別化です。 \n他社との差別化を可能とするAIを開発するには、学習データの広さよりも深い専門性や秘匿性、つま\nり他社が活用できない情報が重要となります。そのため、今後ビジネスにおける生成AIの活用について\nは、 “業界や会社に特化した生成AI”が鍵を握ると考えます [61]。各企業で業界に特化した生成AIを導\n入するには、自社が所属する業界の特性を分析し、学習させる自社のデータを分類するなどの準備が必\n要です。現時点のデータを整理することは、 “将来的に業界に特化した生成AIの構築をスムーズに行う\nことに繋がる”と見込まれます。この事前準備を念入りに行うことが業界に特化したAIを用いて業務効\n率化を図るための第一歩となるため、今一度、自社が持つデータの利活用について検討をすることをお\n勧めします。",
    "content_summary": "84 \n \nAIは未完成な技術であり、今後追い付ける可能性があると考えます。その一つが学習データの枯渇に\n関する問題です。AI Index Reportでは、 「信頼のおけるテキストデータは2024年に、中程度信頼のおけ\nるデータは2030年代に、画像データは2040年代までに枯渇する」可能性について触れています。つま\nり、 信頼のおけるデータが枯渇する2024年を境目にAIの性能向上が鈍化する可能性を示唆しています。\n2つ目は、よりスマートなAIの開発です。生成AIを開発するには大規模なスーパ...",
    "content_length": 1292,
    "created_at": "2025-05-12T09:49:11.103658+00:00",
    "updated_at": "2025-05-12T09:49:11.103658+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=86"
  },
  "doc-6a5c0f7902803489596058d8d5febbf9": {
    "status": "pending",
    "content": "30 \n \n 経営層 \n経営層が生成AIの導入を推進する強い意向を示すことは、組織全体に生成AI活用の重要性を広める\nことや生成AIを積極的に使う文化の構築に大きく影響します。また既存の組織内のシステムに対する影\n響の発生も考慮されるため、生成AIの積極的な導入には経営層の協力は不可欠であると考えます。 \n \n 現場担当者 \n生成AIの導入および運用において、現場担当者の意見は重要です。導入時にはユーザが生成AIに求\nめるニーズやRAG、 ファインチューニング時の学習データの調整、 運用においては導入された生成AIの\n使用感や改善点のフィードバックなど、継続運用において現場担当者の協力は重要です。 \n \n本項で述べた関係者は、あくまで一例となります。実際の要件定義時には、各担当者も含む関係者の整\n理および責任範囲の明確化の協議が重要です。 \n \n3.2.4 リスクアセスメント \n導入時にはリスクアセスメントとして、リスクの特定・分析・評価を実施することが重要です。リスク\nアセスメントを実施する際には、セキュリティ担当者も含めて検討を進める必要があり、主体とする部\n署は組織によって異なります。本書ではセキュリティ担当者が実施することとします。具体的なリスク\n管理について詳細は5.2を参照してください。 \n \n3.2.5 システムの選定 \n生成AIにおけるモデル利用方法の選定 \n生成AIの導入方法は幅広く、一般ユーザ向けにAI提供者が提供するサービスを活用する方法や、独\n自モデルの開発、既存のモデルをトレーニングして活用する方法など多岐にわたります。そのため、利用\n方法に適した導入方法を選定することが重要です。",
    "content_summary": "30 \n \n 経営層 \n経営層が生成AIの導入を推進する強い意向を示すことは、組織全体に生成AI活用の重要性を広める\nことや生成AIを積極的に使う文化の構築に大きく影響します。また既存の組織内のシステムに対する影\n響の発生も考慮されるため、生成AIの積極的な導入には経営層の協力は不可欠であると考えます。 \n \n 現場担当者 \n生成AIの導入および運用において、現場担当者の意見は重要です。導入時にはユーザが生成AIに求\nめるニーズやRAG、 ファインチューニング時の学習データの調整、 運用にお...",
    "content_length": 717,
    "created_at": "2025-05-12T09:49:11.103522+00:00",
    "updated_at": "2025-05-12T09:49:11.103523+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=32"
  },
  "doc-587ae5f90827a4fac07718e82ab0e8f2": {
    "status": "pending",
    "content": "53 \n \n リスク分析 \n潜在的な脅威を考えることで、洗い出した各リスクの「影響度（Impact）」および「発生可能\n性（Likelihood） 」を定量的に分析する工程。一般的に、影響度と発生可能性を独立に分析し、\n両方の結果を考慮してそのリスクの定量値とします。各リスクの定量値を比較する方法には、\n例えばリスクマトリクスがあります （図 5-3） 。リスクマトリクスでは影響度と発生可能性をも\nとに各リスクを2次元的にマッピングします。 \n \n図 5-3: リスクマトリクスの一例 \n \n リスク評価 \nリスク分析結果（各リスクの比較）から総合的にリスク対応策を決定する工程。対策の方向性\nとして、回避・軽減・受容・移転のいずれかを選択し、具体的な対応策を決定します3。対応す\nる範囲や優先度の決定により、限られたリソースを適切に振り分けることができます。 \n \n リスク対応 \n具体的な対策計画を立て、決定した対策を実施する工程。 \n  \n \n3 より現実的には、各リスクの分析結果を列挙して、リスク分析値に対し閾値を設定することで、ある\n閾値以上は回避または軽減、ある閾値以下は受容のように判断します。",
    "content_summary": "53 \n \n リスク分析 \n潜在的な脅威を考えることで、洗い出した各リスクの「影響度（Impact）」および「発生可能\n性（Likelihood） 」を定量的に分析する工程。一般的に、影響度と発生可能性を独立に分析し、\n両方の結果を考慮してそのリスクの定量値とします。各リスクの定量値を比較する方法には、\n例えばリスクマトリクスがあります （図 5-3） 。リスクマトリクスでは影響度と発生可能性をも\nとに各リスクを2次元的にマッピングします。 \n \n図 5-3: リスクマトリクスの一例 \n \n...",
    "content_length": 510,
    "created_at": "2025-05-12T09:49:11.103583+00:00",
    "updated_at": "2025-05-12T09:49:11.103584+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=55"
  },
  "doc-6a61ecb8c1fd6814413d6822c751741f": {
    "status": "pending",
    "content": "12 \n \n1.6 免責事項 \n 本書は単に情報として提供され、内容は予告なしに変更される場合があります。  \n 本書に誤りがないことの保証や、商品性または特定目的への適合性の黙示的な保証や条件を含め\n明示的または黙示的な保証や条件は一切ないものとします。  \n 本書に記載の内容は、独立行政法人情報処理推進機構および産業サイバーセキュリティセンター\nの意見を代表するものではなく、著者の見解に基づいています。 \n 本書の利用によるトラブルに対し、本書著者ならびに監修者は一切の責任を負わないものとしま\nす。 \n 本書の有効期限は、発行日から2年間とします。",
    "content_summary": "12 \n \n1.6 免責事項 \n 本書は単に情報として提供され、内容は予告なしに変更される場合があります。  \n 本書に誤りがないことの保証や、商品性または特定目的への適合性の黙示的な保証や条件を含め\n明示的または黙示的な保証や条件は一切ないものとします。  \n 本書に記載の内容は、独立行政法人情報処理推進機構および産業サイバーセキュリティセンター\nの意見を代表するものではなく、著者の見解に基づいています。 \n 本書の利用によるトラブルに対し、本書著者ならびに監修者は一切の責任を負わない...",
    "content_length": 284,
    "created_at": "2025-05-12T09:49:11.103476+00:00",
    "updated_at": "2025-05-12T09:49:11.103477+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=14"
  },
  "doc-ec92b218bd8af9f63b3bba87dc20c537": {
    "status": "pending",
    "content": "86 \n \n第8章 終わりに \n8.1 あとがき \nここまで本書を読んでいただき、誠にありがとうございました。 \n本書は、日本の産業界における生成AIの利活用を促進したいという強い思いから作成されました。 \n生成AIに限らず、セキュリティという言葉には、面倒くさい、利便性が下がるといったマイナスなイ\nメージがつきまといがちです。特に、セキュリティに直接関係のない業務に携わっている方々には、その\n傾向が強いのではないでしょうか。 \n生成AIの技術進歩は非常に早く、日々新しいサービスが展開されています。その中で、セキュリティ\nを後回しにしてしまうこともあるかもしれません。しかし、生成AIには特有の脆弱性があり、世界中で\nこれらの課題と対策について活発な議論が行われています。セキュリティインシデントが発生すれば、\n生成AIの利用が制限される可能性もあります。だからこそ、生成AIのセキュリティを考えることが重\n要だと考えます。 \nさて、本書は独立行政法人情報処理推進機構 産業サイバーセキュリティセンター 中核人材育成プロ\nグラムにおける卒業プロジェクトの成果物として、日本の産業界におけるさまざまなメンバーが議論を\n重ねて作成されました。現在、日本の多くの組織では、機械学習やディープラーニングに詳しい人材が少\nなく、 導入に対する不安を抱えていることでしょう。 我々も最初から知見があったわけではありません。\n多くのドキュメントを読み、オンプレ・クラウド環境での検証を行い、メンバー間で意見をぶつけ合う、\nこのサイクルを繰り返すことで、本書の内容をまとめることができました。このような環境を与えてく\nださった全ての方に感謝申し上げます。 \n2024年6月現在、生成AIは日々進化しています。新しい技術やサービスが次々と登場し、情報収集\nを怠ると取り残されてしまいます。本書を作成する期間中にも、EUのAI規制法の成立、日本のスーパ\nーコンピュータ「富岳」で学習した「Fugaku-LLM」の登場、高校生が開発した日本語性能世界一のLLM\nモデル （7Bモデル、2024年5月9日時点）など、大きな出来事がありました。これらの進展は今後も加\n速することが予想されます。現状、日本は生成AIの分野において後発の立場にありますが、これらの事\n例を見れば、日本も確実に進歩していることがわかります。このような技術革新が続く中で、日本が生成\nAIの分野でリーダーシップを発揮する可能性も十分にあると考えています。 \nまた、本書を手に取っていただいた皆様が、生成AIの新しい技術やサービスを活用し、組織の発展に\n貢献されることを期待しています。生成AIの導入には挑戦も伴いますが、それを乗り越えるための知識\nを提供することが、本書の目的です。本書が皆様の成功と成長に繋がることを心より願っております。 \n生成AIの未来は明るく、その可能性は無限大です。共に学び、成長し続けていきましょう。",
    "content_summary": "86 \n \n第8章 終わりに \n8.1 あとがき \nここまで本書を読んでいただき、誠にありがとうございました。 \n本書は、日本の産業界における生成AIの利活用を促進したいという強い思いから作成されました。 \n生成AIに限らず、セキュリティという言葉には、面倒くさい、利便性が下がるといったマイナスなイ\nメージがつきまといがちです。特に、セキュリティに直接関係のない業務に携わっている方々には、その\n傾向が強いのではないでしょうか。 \n生成AIの技術進歩は非常に早く、日々新しいサービスが展開されていま...",
    "content_length": 1242,
    "created_at": "2025-05-12T09:49:11.103663+00:00",
    "updated_at": "2025-05-12T09:49:11.103664+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=88"
  },
  "doc-60b1c05037b13075492e4afbe4117b24": {
    "status": "pending",
    "content": "47 \n \n 業務効率化の寄与 \n生成AIを導入することで幅広い分野で業務効率化を図ることができます。一例を挙げると、調\n査の時間短縮、各システムの自動化・連携、データ分析、アイデア出し等です。導入目的が業務\n効率化の場合、 生成AIの導入によってどの程度業務効率化が達成できたのかを測る必要があり\nます。業務効率化の測定について、定量評価が困難な面もありますが、評価手法としては生成\nAI導入前後の残業時間の推移を参考データとするほか、アンケートを実施して定性的に効果を\n確認することなどが考えられます。 \n \n 業務品質の改善、向上 \n業務知識の乏しい方でも生成AIを使用することにより、 知識豊富な方と同等の水準で業務を行\nうことができます。つまり、従来、業務知識の差異に伴って発生していた業務品質のばらつき\nが軽減され、導入企業全体の品質水準の向上が期待できます。また、文書の要約、添削、議事録\n作成など、 業務内容によっては既に人間が行うよりも生成AIが担う方が正確かつ迅速に処理で\nきることもあります。導入目的に業務品質の改善、向上が含まれる場合、業務品質を評価する\nための手法としては、アンケートやユーザインタビュー等があります。 \n \n 生成AIの社内普及率 \n導入した生成AIが利用されているか利用率を評価することで、 業務において積極的に利用され\nているかどうかを確認することができます。システムの普及について、類似点のある理論にマ\nーケティング分野において新しい商品が普及していく過程を分析した理論として、イノベータ\nー理論があります [24]。普及が進んでいく過程における利用者をイノベーター、アーリーアダ\nプター、アーリーマジョリティ、レイトマジョリティ、ラガードという5つの区分に分けてい\nます。",
    "content_summary": "47 \n \n 業務効率化の寄与 \n生成AIを導入することで幅広い分野で業務効率化を図ることができます。一例を挙げると、調\n査の時間短縮、各システムの自動化・連携、データ分析、アイデア出し等です。導入目的が業務\n効率化の場合、 生成AIの導入によってどの程度業務効率化が達成できたのかを測る必要があり\nます。業務効率化の測定について、定量評価が困難な面もありますが、評価手法としては生成\nAI導入前後の残業時間の推移を参考データとするほか、アンケートを実施して定性的に効果を\n確認することなどが考えら...",
    "content_length": 765,
    "created_at": "2025-05-12T09:49:11.103569+00:00",
    "updated_at": "2025-05-12T09:49:11.103570+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=49"
  },
  "doc-8cf4fc31253d05bb7a833c117d1aa9f3": {
    "status": "pending",
    "content": "17 \n \n システムの構成 \n「フロントエンド」は、ユーザが直接見て操作する部分であり、Web UIが該当します。 「バックエン\nド」はLLMへの問い合わせを行う部分であり、LLMそのものや、ユーザとLLMの間の処理を行う統\n合ミドルウェアが該当します。統合ミドルウェアの例にはLangChainがあります。最後に「連携システ\nム」は、LLMへの問い合わせのほかにシステムに必要な処理に関係する部分を指し、RAGに使用するベ\nクトルDBや入出力内容のログを保管するサーバなどが該当します。 \n \n システムの処理 \nまず、ユーザがWeb UIを通してシステムへ質問や指示（プロンプト）を入力します。そのプロンプト\nは統合ミドルウェアに渡り、LLMへの問い合わせが行われます。問い合わせの際、プロンプトはLLM\nで処理可能にするため、トークンと呼ばれる形式に変換されます。RAGを使用する場合は、問い合わせ\nの前にベクトルDBへの検索が行われ、検索結果がプロンプトに追加されてからトークンへの変換と問\nい合わせが行われます。その後、LLMが出力した回答は統合ミドルウェアを経由してWeb UIに表示さ\nれ、ユーザは入力内容に対する回答を得ることができます。 \n \n2.2 テキスト生成AIの組織活用 \n2.2.1 組織活用可能な場面 \nテキスト生成AIは一般企業等を含め多様な組織での普及が進み、さまざまな業務への活用が始まって\nいます。ここでは、有効に活用できる場面として、大きく3つの区分を紹介します。 \n \n 業務の効率化 \nテキスト生成AIは、人手を介さず高速に自然言語処理を提供できるため、文章の校正、資料の\n要約、Excelマクロのコード生成等、作業時間の短縮およびコスト削減、品質向上に寄与すること\nが期待されます。 \n \n 意思決定の補助 \nテキスト生成AIは、 大量のデータを素早く分析してさまざまな観点からの示唆を提示できるた\nめ、過去事例や公開情報の調査、必要な情報の抽出等、 意思決定プロセスを強力に支援することが\n期待されます。 \n \n 新事業の提案補助 \nテキスト生成AIは既存データ （市場の売り上げ等）から新しいアイデアのブレーンストーミン\nグの補助が可能なため、ソリューションの提案や近年の需要が高いソリューション傾向の抽出等\nの新たな事業機会の創出や新規サービスの構想策定に活用されることが期待されます。",
    "content_summary": "17 \n \n システムの構成 \n「フロントエンド」は、ユーザが直接見て操作する部分であり、Web UIが該当します。 「バックエン\nド」はLLMへの問い合わせを行う部分であり、LLMそのものや、ユーザとLLMの間の処理を行う統\n合ミドルウェアが該当します。統合ミドルウェアの例にはLangChainがあります。最後に「連携システ\nム」は、LLMへの問い合わせのほかにシステムに必要な処理に関係する部分を指し、RAGに使用するベ\nクトルDBや入出力内容のログを保管するサーバなどが該当します。 \n \n...",
    "content_length": 1025,
    "created_at": "2025-05-12T09:49:11.103490+00:00",
    "updated_at": "2025-05-12T09:49:11.103491+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=19"
  },
  "doc-9477bbdc163fe595f14efc578b575ee9": {
    "status": "pending",
    "content": "41 \n \n生成AIからの生成物（回答）について \n生成AIが出力する回答については、以下の点に注意して取扱うことが重要です。 \n 生成物の解釈に関する注意 \n 誤りの確認（ハルシネーション） \n生成AIが提供する生成物には誤りが含まれる可能性があります。特に、生成物が現実には存\n在しない情報や事実と異なる内容を含む場合があるため、常にその正確性を確認する必要があ\nります。ハルシネーションの軽減策として、例えばRAGを活用する方法などが知られています\nが、完全に解消することはできないため、重ねてユーザに周知することが重要です。 \n \n図 4-5: 生成物にハルシネーションが含まれる例 \n \n 偏りの確認（バイアス） \n生成物にはモデルが使用した学習データに基づくバイアスが含まれる可能性があります。公\n平性を保つために、生成物が特定の視点に偏っていないか、差別的な表現が含まれていないか\n注意深く確認することが必要です。 \n \n図 4-6: 生成物にバイアスが含まれる例 \n \n 生成物の引用および外部公開に関する注意 \n 引用元の注釈 \n生成AIからの生成物を引用する場合は、生成AIにより生成した事実を明示することが求め\nられます。適切な引用元の注釈を行い、情報の出所を明らかにすることで、生成物の透明性を\n確保します。",
    "content_summary": "41 \n \n生成AIからの生成物（回答）について \n生成AIが出力する回答については、以下の点に注意して取扱うことが重要です。 \n 生成物の解釈に関する注意 \n 誤りの確認（ハルシネーション） \n生成AIが提供する生成物には誤りが含まれる可能性があります。特に、生成物が現実には存\n在しない情報や事実と異なる内容を含む場合があるため、常にその正確性を確認する必要があ\nります。ハルシネーションの軽減策として、例えばRAGを活用する方法などが知られています\nが、完全に解消することはできないため、重...",
    "content_length": 571,
    "created_at": "2025-05-12T09:49:11.103555+00:00",
    "updated_at": "2025-05-12T09:49:11.103555+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=43"
  },
  "doc-4fcc087f6e0671eb51dfad9ff90cd3bd": {
    "status": "pending",
    "content": "96 \n \n[13] The Federal Oﬃce for Information Security, “Generative AI Models - Opportunities and Risks \nfor Industry and Authorities” Generative AI Models - Opportunities and Risks for Industry and \nAuthorities, 2024. [アクセス日: 2024-06]. \n[14] OWASP, “LLM AI Cybersecurity & Governance Checklist”, 2024-04-11, \nhttps://genai.owasp.org/wp-\ncontent/uploads/2024/05/LLM_AI_Security_and_Governance_Checklist-v1.1.pdf. [アクセス日: \n2024-06]. \n[15] O. Ovadia, M. Brief , M. Mishaeli, “Fine-Tuning or Retrieval? Comparing Knowledge Injection \nin LLMs”, Microsoft, 2023. [アクセス日: 2024-06]. \n[16] Anthropic, “Usage Policy”, 2024-06-06, https://www.anthropic.com/legal/aup. [アクセス日: \n2024-06]. \n[17] Google, “生成 AI の使用禁止に関するポリシー”, 2023-03-14, \nhttps://policies.google.com/terms/generative-ai/use-policy. [アクセス日: 2024-06]. \n[18] Open AI, “使用に関するポリシー”, 2024-01-10, https://openai.com/ja-JP/policies/usage-\npolicies/. [アクセス日: 2024-06]. \n[19] DAIR.AI, “Prompt Engineering Guide”, 2024, https://www.promptingguide.ai/jp. [アクセス\n日: 2024-06]. \n[20] Anthropic, “プロンプトライブラリ”, https://docs.anthropic.com/ja/prompt-library/library. \n[アクセス日: 2024-06]. \n[21] Google, “Generative AI prompt samples”, 2024-06-14, https://cloud.google.com/vertex-\nai/generative-ai/docs/prompt-gallery. [アクセス日: 2024-06]. \n[22] OpenAI, “Prompt examples”, https://platform.openai.com/docs/examples. [アクセス日: 2024-\n06]. \n[23] 文化庁, “令和5年度著作権セミナー AIと著作権”, 2023-06, \nhttps://www.bunka.go.jp/seisaku/chosakuken/pdf/93903601_01.pdf. [アクセス日: 2024-06]. \n[24] ワンマーケティング株式会社, “イノベーター理論とは？”, 2023-04-04, \nhttps://www.onemarketing.jp/contents/innovation-theory_re/. [アクセス日: 2024-06]. \n[25] E. Dreibelbis, “Samsung Software Engineers Busted for Pasting Proprietary Code Into \nChatGPT”, 2023-04.  \n[26] 東京新聞, “生成AI使いコンピューターウイルス作成疑い 警視庁が男を再逮捕”, 2024-05-28, \nhttps://www.tokyo-np.co.jp/article/329884.  \n[27] 日本経済新聞, “ChatGPTで資料作成、実在しない判例引用 米国の弁護士” 日本経済新聞, \n2023-05-31.  \n[28] G. Rohan, “ChatGPT cited ‘bogus’ cases for a New York federal court ﬁling. The attorneys \ninvolved may face sanctions.” CNBC, 2023-05-30.",
    "content_summary": "96 \n \n[13] The Federal Oﬃce for Information Security, “Generative AI Models - Opportunities and Risks \nfor Industry and Authorities” Generative AI Models - Opportunities and Risks for Industry and \nAuthorities, 2024. [アクセス日: 2024-06]. \n[14] OWASP, “L...",
    "content_length": 2041,
    "created_at": "2025-05-12T09:49:11.103688+00:00",
    "updated_at": "2025-05-12T09:49:11.103689+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=98"
  },
  "doc-4c311edf607fe1b2b623f20264b239f8": {
    "status": "pending",
    "content": "91 \n \nイノベーター イノベーター理論におけるユーザ層の5つの区分のうち、最\nも早く新製品・サービスを採用する層で、ユーザの約2.5%\nを占めている。新しい商品やサービスなどを最も早い段階で\n受け入れ受容する層。 \nイノベーター理論 新製品・サービスの市場への普及率を表したマーケティング\n理論で、1962年にエベレット・M・ロジャーズによって提\n唱された。 \nウォーターフォール システム開発手法の一種。要件定義からテストまで事前に定\nめられた工程で開発する手法 \nエキスパートシステム 特定の専門分野の知識をもち、専門家のように事象の推論や\n判断ができるようにしたコンピューターシステムのこと。 \nオプトアウト ユーザが情報を送り付けられる場合やユーザ本人の情報が事\n業者等に利用される場合などにおいて、それらの行為を拒否\nすること。生成AIにおいては入力した情報をLLMの学習\nデータとして利用することを拒否する場合などを指す。 \nキャズム イノベーター理論におけるアーリーアダプターとアーリーマ\nジョリティの間に存在にする容易に越えられない深い溝のこ\nと。この溝を越えて市場で存続するために、アーリーアダプ\nターだけでなくアーリーマジョリティへのマーケティングも\n必要であるという「キャズム理論」がジェフリー・Ａ・ムー\nアによって提言された。 \nサプライチェーン 原料の生産から製品の提供までの一連の流れのこと。生成\nAIにおいては使用するモデルや学習データを考慮に入れる\n必要がある。 \nチャットボット ユーザとの会話に対してロボットに自動で応答させる技術の\nこと。ロボットに生成AIを利用することでより柔軟な応答\nが可能となった。 \nディープラーニング ニューラルネットワークにおける入力層と出力層の間に存在\nする中間層を多層化し、各中間層において特徴点を抽出する\nことで複雑なデータを詳細に分析して学習する。 \nデプロイ システム開発工程で、アプリケーションの機能やサービスを\nサーバ上に配置・展開し、利用可能な状態にする一連の作業 \nトークン LLMへ問い合わせを行う際に分割したプロンプトの最小単\n位。生成AIのクラウドサービスを利用する際はトークンの\n数が料金に影響する場合がある。プロンプトが長いほど、ま\nた、より細かく分割するほどトークンは増加することに留意\nが必要。",
    "content_summary": "91 \n \nイノベーター イノベーター理論におけるユーザ層の5つの区分のうち、最\nも早く新製品・サービスを採用する層で、ユーザの約2.5%\nを占めている。新しい商品やサービスなどを最も早い段階で\n受け入れ受容する層。 \nイノベーター理論 新製品・サービスの市場への普及率を表したマーケティング\n理論で、1962年にエベレット・M・ロジャーズによって提\n唱された。 \nウォーターフォール システム開発手法の一種。要件定義からテストまで事前に定\nめられた工程で開発する手法 \nエキスパートシステム 特定の...",
    "content_length": 998,
    "created_at": "2025-05-12T09:49:11.103675+00:00",
    "updated_at": "2025-05-12T09:49:11.103676+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=93"
  },
  "doc-1269c9c3288ddd6c0a8ba7c90ad93a38": {
    "status": "pending",
    "content": "61 \n \n5.4.1 多層防御 \n多層防御（Defense in Depth）は、単一の防御策に頼るのではなく、複数の異なる防御層を設けること\nでセキュリティを強化する手法です。この手法は、各防御層がそれぞれ異なる種類の脅威に対応し、他の\n層が失敗した場合でもシステム全体の保護が維持されるように設計されています。多層防御の基本的な\n考え方は、攻撃者がシステムに侵入する際に直面する障壁を増やすことです（図 5-8） 。 \n \n図 5-8: 多層防御の考え方（スイスチーズモデル） \n \nこれにより、 攻撃者が攻撃を成功させるためには、 複数のセキュリティ対策を突破しなければならず、\n攻撃の難易度とコストが大幅に上昇します。また、攻撃を早期に検知し、対応するための時間を確保する\nことも可能になります。 \n多層防御は一般的に以下3つの対策の組合せとなります。 \n 侵入を防ぐための入口対策 \n 侵入されたことを検知して被害の拡大を防ぐための内部対策 \n 情報の流出を防ぐための出口対策 \nこれら複数の対策により、システム全体のセキュリティを向上できます。 \n \n入口対策 \n入口対策では、ユーザがフロントエンドにあるWeb UIに入力したプロンプト文をバックエンドへ送\nる場所での対策を考えます。図 5-5のシステム構成図における入口対策の場所を、図 5-9に緑色の盾マ\nークで示します。 \n \n図 5-9: 入口対策場所のイメージ",
    "content_summary": "61 \n \n5.4.1 多層防御 \n多層防御（Defense in Depth）は、単一の防御策に頼るのではなく、複数の異なる防御層を設けること\nでセキュリティを強化する手法です。この手法は、各防御層がそれぞれ異なる種類の脅威に対応し、他の\n層が失敗した場合でもシステム全体の保護が維持されるように設計されています。多層防御の基本的な\n考え方は、攻撃者がシステムに侵入する際に直面する障壁を増やすことです（図 5-8） 。 \n \n図 5-8: 多層防御の考え方（スイスチーズモデル） \n \nこれにより...",
    "content_length": 621,
    "created_at": "2025-05-12T09:49:11.103602+00:00",
    "updated_at": "2025-05-12T09:49:11.103603+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=63"
  },
  "doc-03cf2955b7f4aaf184220a4fd7b6dc72": {
    "status": "pending",
    "content": "88 \n \n付録 \n用語集 \n用語 概要 \nAI \n（Artiﬁcial Intelligence：人工知能） \n人間の思考プロセスと同じような形で動作するコンピュータ\nープログラム、コンピュータ上で知的判断を下せるシステ\nム。 \nAI RMF（Artificial Intelligence Risk \nManagement Framework） \n米国商務省の国立標準技術研究所（NIST）がAIに関連する\nリスクを管理するために開発されたフレームワーク。 \nAPI（Application Programming \nInterface） \nソフトウェアやプログラム、Webサービスの間をつなぐ \nインターフェース。 \nAmazon Bedrock Amazon Web Service の生成AIアプリケーションを構築する\nために必要な幅広い機能を統合API経由で利用できるよう\nにするフルマネージドサービス。 \nAzure OpenAI Service Microsoft Azure のクラウドプラットフォーム上で提供され\nる、OpenAI社のAIサービス。 \nBERT \n（Bidirectional Encoder \nRepresentations from Transformers） \nGoogle社が開発した自然言語処理のためのディープラーニ\nングモデル。文脈を理解し、単語や文の意味表現を学習する\nために設計されているため、文章全体の文脈を考慮して、単\n語の意味を正確に捉えることに優れている。 \nCSRF（Cross Site Request Forgery） Web アプリケーションのユーザ認証やセッション管理の不\n備を突いて、サイトのユーザにWebアプリケーションに対\nする不正な処理を行わせる攻撃手法。 \nChatGPT OpenAI 社が提供している生成AIサービス。2024年6月時\n点での最新・最高性能モデルはChatGPT-4oである。 \nChatGPT Enterprise ChatGPT の全ての機能が利用でき、企業向けにアップデー\nトされたバージョン。企業利用を想定した管理コンソールを\n始め、入力データの暗号化、オプトアウト設定などのセキュ\nリティ機能も有する。 \nClaude Anthropic が提供している生成AIサービス。2024年6月時\n点での最新・最高性能サービスはClaude3 Opusである。 \nCopilot for Microsoft 365  OpenAI のGPT-4をベースにした大規模言語モデル。\n（LLM）を各Oﬃceアプリケーションに組み込み、生産性\nの向上や業務効率化を改善するためのツール。",
    "content_summary": "88 \n \n付録 \n用語集 \n用語 概要 \nAI \n（Artiﬁcial Intelligence：人工知能） \n人間の思考プロセスと同じような形で動作するコンピュータ\nープログラム、コンピュータ上で知的判断を下せるシステ\nム。 \nAI RMF（Artificial Intelligence Risk \nManagement Framework） \n米国商務省の国立標準技術研究所（NIST）がAIに関連する\nリスクを管理するために開発されたフレームワーク。 \nAPI（Application Pr...",
    "content_length": 1140,
    "created_at": "2025-05-12T09:49:11.103668+00:00",
    "updated_at": "2025-05-12T09:49:11.103669+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=90"
  },
  "doc-deda79190e4aec67bce9116e478cb194": {
    "status": "pending",
    "content": "59 \n \n次に発生可能性の決定では、そのリスクの組織内での実際の発生確率を基準とします。今回は、そのリ\nスク発生が、ユーザ起因か攻撃者起因かという点でランク分けを行いました。但し、影響度や発生可能性\nの判定基準は組織によって変化するため、各組織で明確な基準を設け、多角的な視点からリスク分析を\n行うことが重要です。 \n各リスクの分析結果が表 5-3です。 \n \n表 5-3: リスク分析 \n \n \n手順b) リスクマトリクスの作成 \nリスクマトリクスでは、ここまでにランク分けした各リスクを、視覚的に比較できます。今回のリスク\nマトリクスは図 5-6で、 表 5-3でランク分けしたリスクをマッピングしました。 今回のリスクの中では、\n最も大きいものが「機密情報の漏洩」 、次点が「ハルシネーション」でした。 \n \n図 5-6: リスクマトリクス分析",
    "content_summary": "59 \n \n次に発生可能性の決定では、そのリスクの組織内での実際の発生確率を基準とします。今回は、そのリ\nスク発生が、ユーザ起因か攻撃者起因かという点でランク分けを行いました。但し、影響度や発生可能性\nの判定基準は組織によって変化するため、各組織で明確な基準を設け、多角的な視点からリスク分析を\n行うことが重要です。 \n各リスクの分析結果が表 5-3です。 \n \n表 5-3: リスク分析 \n \n \n手順b) リスクマトリクスの作成 \nリスクマトリクスでは、ここまでにランク分けした各リスクを、視覚的...",
    "content_length": 376,
    "created_at": "2025-05-12T09:49:11.103597+00:00",
    "updated_at": "2025-05-12T09:49:11.103598+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=61"
  },
  "doc-7598123a27712a3f26b0c2c6f8127605": {
    "status": "pending",
    "content": "73 \n \n ハルシネーションについて \nハルシネーションは生成AIが抱える大きなリスクの1つです。 このリスクを完全に取り除く\nことは現状の技術では困難であり、軽減策を講じることしかできません。ヒアリング先の組織\nもユーザが誤った情報を信用してしまうリスクや重要な意思決定が誤った情報に基づいて行わ\nれるリスクに対して大きな危機感を抱いていました。 \n現在このリスクに対し、組織が講じている対策として挙げられたのは、ユーザの生成AIに対\nする認識とスキルを向上させるための教育や、RAGを用いた回答精度の向上です。ただ、これ\nらの対策のみでは本リスクへの根本的な対応にはならず、今後も継続的に組織内で検討が必要\nであると考えます。 \nなお、プロンプトインジェクションやジェイルブレイクのような生成AIを対象とした敵対的\nプロンプト攻撃のリスクは低いものと認識されている傾向があり、敵対的プロンプト攻撃をは\nじめとしたサイバー攻撃への対策は、 具体的な対策手法を含め、 現在も組織内で検討を進めてい\nる途中であるということがわかりました。 \n \n6.1.3 ユーザのフィードバック \n ヒアリング内容 \n生成AIの本格稼働後に、ユーザからあったフィードバックや問い合わせ内容などについて、回数\nの多いものをヒアリングしました。 \n \n ヒアリング結果 \n組織にヒアリングする中で多く回答されたのは次の内容でした。システム導入当初は、 「生成AI\nというものがどういうものか」、 「どのように活用すればよいか （活用法）」など、ユーザからの質問\nには基本的な内容が多い傾向にあったものの、導入から約1年が経過した現在では、 「新たなサービ\nス （画像生成AIや動画生成AIなど） を導入してほしい」 、 「RAGの効果的な使い方がわからない」 、\n「外販に活用するためにはどうしたらよいのか」などの、当初の質問に比べ高度な質問に変化して\nいることがわかりました。 \n質問内容の高度化は、組織が今までに実施した情報周知や教育で、ユーザの生成AIへの理解度が\n向上したからと考えられます。組織における努力の賜物ではないかと感じ取れました。",
    "content_summary": "73 \n \n ハルシネーションについて \nハルシネーションは生成AIが抱える大きなリスクの1つです。 このリスクを完全に取り除く\nことは現状の技術では困難であり、軽減策を講じることしかできません。ヒアリング先の組織\nもユーザが誤った情報を信用してしまうリスクや重要な意思決定が誤った情報に基づいて行わ\nれるリスクに対して大きな危機感を抱いていました。 \n現在このリスクに対し、組織が講じている対策として挙げられたのは、ユーザの生成AIに対\nする認識とスキルを向上させるための教育や、RAGを用いた回...",
    "content_length": 919,
    "created_at": "2025-05-12T09:49:11.103632+00:00",
    "updated_at": "2025-05-12T09:49:11.103633+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=75"
  },
  "doc-a070631ada358044af4aca62c1426b07": {
    "status": "pending",
    "content": "77 \n \n \n図 6-2: プロンプトテンプレート選択イメージ②。 \n \nC) セキュリティの担保された環境を構築し、利用を促す \n最後に、セキュリティが担保された環境を構築し、ユーザに安心感を与えることも効果的で\nす。具体的には3.2.5にて記載した、セキュリティが担保されたPaaS型サービスの利用や、社\n内ローカル環境に独自の生成AIシステムを構築し、 社内環境の中で回答を生成できるサービス\nの提供です。これによって社内情報の入力制限が不要となり、ユーザの不安感を軽減し、利用\n率の向上を促すことが期待できます。 \n \nこれらの対策例はあくまでも今回ヒアリングを実施した組織における対策であり、これらの対策\nを行ったからといって利用率の問題が必ず解消されるわけではありません。そのため、上述の対策\n例を参考にしつつも、自身の組織において何が利用率の低さの根本原因なのかを特定した上で、効\n果的な対策を講じていくことが重要です。",
    "content_summary": "77 \n \n \n図 6-2: プロンプトテンプレート選択イメージ②。 \n \nC) セキュリティの担保された環境を構築し、利用を促す \n最後に、セキュリティが担保された環境を構築し、ユーザに安心感を与えることも効果的で\nす。具体的には3.2.5にて記載した、セキュリティが担保されたPaaS型サービスの利用や、社\n内ローカル環境に独自の生成AIシステムを構築し、 社内環境の中で回答を生成できるサービス\nの提供です。これによって社内情報の入力制限が不要となり、ユーザの不安感を軽減し、利用\n率の向上を促...",
    "content_length": 418,
    "created_at": "2025-05-12T09:49:11.103641+00:00",
    "updated_at": "2025-05-12T09:49:11.103642+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=79"
  },
  "doc-a85f42f12c3e68a3b582d839a7b7e272": {
    "status": "pending",
    "content": "76 \n \nA) 該当の業務に生成AIの利用を義務化 \nヒアリング事例の中では、週報作成のような、毎週同じ形式で書かれる反復的な特性を持つ\n報告文書等の作成に生成AIを活用するのは非常に効果的です。週報作成に生成AIを活用する\nことで作成に費やす時間を大幅に削減することも可能になるため、 生成AIの有効性を理解する\nという点においても非常に有用な施策であると考えられます。また、ドキュメントの誤字脱字\n添削やメールのドラフト作成など、通常の業務において避けて通れない作業で形式が確定して\nいるものについて、生成AIの利用を強制するという施策は、利用を通じてユーザの生成AIへ\nの理解を深める良い機会となり、利用率向上の一助となることが期待できます。 \n \nB) 効果的なプロンプト例を提示し、システムに組み込む \nシステム内に効果的なプロンプトテンプレートを組み込み、逐次呼び出すことで効果的な回\n答を出力できるようにする対策も効果的です。 通常、 生成AIから効果的な回答を得るためには、\n高度なプロンプトエンジニアリングの能力が必要となります。しかし、全てのユーザがその能\n力をもち、適切に活用できているわけではありません。そこで活用できるのがプロンプトテン\nプレートですが、ユーザが個々で調査を行い、プロンプトを作成するのは難易度が高いことが\n想像されます。 \nこの課題への対策として考えられるのは、社内システムの機能として、プロンプトテンプレ\nートを選択可能な仕組みを導入することです。この仕組みを導入することにより、ユーザは簡\n単に効果的なプロンプトを元に生成された回答を得ることができるようになり、 生成AIの効果\nを実感し、業務において生成AIを活用したいと感じるための一助となることが期待できます。\n以下にその実装イメージを示します。 \n \n \n図 6-1: プロンプトテンプレート選択イメージ①",
    "content_summary": "76 \n \nA) 該当の業務に生成AIの利用を義務化 \nヒアリング事例の中では、週報作成のような、毎週同じ形式で書かれる反復的な特性を持つ\n報告文書等の作成に生成AIを活用するのは非常に効果的です。週報作成に生成AIを活用する\nことで作成に費やす時間を大幅に削減することも可能になるため、 生成AIの有効性を理解する\nという点においても非常に有用な施策であると考えられます。また、ドキュメントの誤字脱字\n添削やメールのドラフト作成など、通常の業務において避けて通れない作業で形式が確定して\nいるものに...",
    "content_length": 807,
    "created_at": "2025-05-12T09:49:11.103639+00:00",
    "updated_at": "2025-05-12T09:49:11.103639+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=78"
  },
  "doc-8af055acc1b7ada358f14b0e05a8a62c": {
    "status": "pending",
    "content": "69 \n \nこの機能は特定の話題を制限するだけではなく、API経由でLLMを利用する環境（ハイブリッド型）\nにおいては、業務と関係ないリクエストを減らし、コストを削減することにも繋がります。 \n \n敵対的プロンプトを防ぐ機能 \n本ツールは、敵対的プロンプトを防ぐこともできます。設定ファイルに入力ポリシーを記載する（図 \n5-16）ことで、プロンプトに入力された文章が入力ポリシーに違反していないかをLLMを使用して確認\nします。 \n \n図 5-16: 入力ポリシー設定画面（yml 形式） \n \n実際に図 5-16では、以下の3点を確認するように設定しています。 \n 日本語と英語以外を使っている。 \n 敵対的プロンプトが含まれている。 \n プログラムやコードの実行を促している。 \n図 5-17では、上記に違反する場合に、入力ポリシーに違反した旨の回答が返ることがわかります。 \n \n図 5-17: 入力ポリシーに反した場合のイメージ",
    "content_summary": "69 \n \nこの機能は特定の話題を制限するだけではなく、API経由でLLMを利用する環境（ハイブリッド型）\nにおいては、業務と関係ないリクエストを減らし、コストを削減することにも繋がります。 \n \n敵対的プロンプトを防ぐ機能 \n本ツールは、敵対的プロンプトを防ぐこともできます。設定ファイルに入力ポリシーを記載する（図 \n5-16）ことで、プロンプトに入力された文章が入力ポリシーに違反していないかをLLMを使用して確認\nします。 \n \n図 5-16: 入力ポリシー設定画面（yml 形式） \n \n実...",
    "content_length": 422,
    "created_at": "2025-05-12T09:49:11.103623+00:00",
    "updated_at": "2025-05-12T09:49:11.103623+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=71"
  },
  "doc-76bdf4a293d869724032ab4e462f4508": {
    "status": "pending",
    "content": "37 \n \n第4章 生成 AI の運用について \n本章では、組織で生成AIを運用する担当者（運用担当者）の主な考慮事項を説明します。生成AIを\n組織で運用する上で、利活用ガイドラインやルールを策定・文書化し、組織内で共有することが重要にな\nります。また、文書の中では、ユーザの行動制限や業務円滑化に関する内容を記載することがポイントで\nす。例えば、利活用ガイドラインを策定する際は、入力してはいけない内容や目的の出力を生成させるプ\nロンプトのコツ、生成物の取扱い方法などを記述します。 \n \n図 4-1: 導入プロセスと運用担当者の該当フェーズ \n \n4.1 利活用ガイドラインの策定 \n4.1.1 利活用ガイドライン策定の重要性 \n2024年1月に一般財団法人JIPDECによって実施された「企業IT利用調査2024」によると、生成AI\nに関する利用規定やガイドラインが策定されている企業の割合は、会社で構築・契約した生成AIを使用\nしている企業では68.6%、社員各自で契約・登録した生成AIを使用している企業では9.0%となってお\nり、利活用ガイドラインを策定せずに生成AIを運用している企業が多いのが現状です（図 4-2） 。 \n \n図 4-2:生成AIの利活用ガイドラインの策定状況 \nJIPDEC／ITR「企業IT利活用動向調査2024」より作成 [4]",
    "content_summary": "37 \n \n第4章 生成 AI の運用について \n本章では、組織で生成AIを運用する担当者（運用担当者）の主な考慮事項を説明します。生成AIを\n組織で運用する上で、利活用ガイドラインやルールを策定・文書化し、組織内で共有することが重要にな\nります。また、文書の中では、ユーザの行動制限や業務円滑化に関する内容を記載することがポイントで\nす。例えば、利活用ガイドラインを策定する際は、入力してはいけない内容や目的の出力を生成させるプ\nロンプトのコツ、生成物の取扱い方法などを記述します。 \n \n図 4-...",
    "content_length": 583,
    "created_at": "2025-05-12T09:49:11.103545+00:00",
    "updated_at": "2025-05-12T09:49:11.103546+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=39"
  },
  "doc-c2d51249d1c4e4707436c5109c7b18ba": {
    "status": "pending",
    "content": "72 \n \nまた、 開発手法としてはアジャイル開発が採用される傾向が見られました。これは、 現状、生成AI\nの導入に関するベストプラクティスが存在していないことに起因しており、自社に合った構成を手\n探りで検討する中で、結果的にアジャイル形式の開発手法が最も合理的な選択であったと考えられ\nます。 また、 生成AIはモデルの更新頻度が多いことや、 社会情勢の変化に対応する必要があるため、\n通常のシステム構築におけるウォーターフォール型ではなく、アジャイル型が開発手法として最も\n適しています。 \n \n6.1.2 セキュリティとガイドライン \n ヒアリング内容 \n生成AIを導入・運用する組織が、セキュリティ対策時に重点を置いたリスクや、具体的なセキュ\nリティ対策方法についてヒアリングを実施しました。また、組織における生成AIの利活用ガイドラ\nイン作成時に参考にした資料や考慮した点についてもヒアリングしました。 \n \n ヒアリング結果 \n組織が特に重視しているセキュリティリスクは情報漏洩とハルシネーションの2点でした。 \n \n 情報漏洩について \n情報漏洩は、全ての組織において最上位のリスクとして認識され、ガバナンス面・システム面の\n2つの側面から対策が実施されていました。 以下にて、 それぞれの組織が講じた対策を説明します。 \n \n ガバナンスにおける対策 \nガバナンスにおける対策として挙げられたのは、組織内の生成AIの取扱い方法や規則を記載\nしたガイドライン・ポリシーの作成です。ガイドラインを作成する上では、JDLAが2023年5\n月1日に発行した 「生成AIの利用ガイドライン」 やNISTが2023年1月に発表した 「AI RMF」 、\n既存の社内ガイドライン（クラウド規定）等を参考にされている傾向が見られました。今回ヒア\nリングを実施した組織では、クラウドサービスを活用して生成AIのシステムを利用することを\n前提としていたため、 クラウドに関する既存ルールと乖離がないかという観点が、 ガイドライン\n作成に重要であったという言及もありました。 \nまた、生成AI独自の観点として、入力内容がAI事業者・AI提供者に学習されてしまうとい\nうリスクを考慮し、オプトアウト可能なサービスを選定するという対策も講じられていました。 \n \n システムにおける対策 \nシステム面においてはログ管理によって、いつ、誰が、どのような内容を入力し、生成AIが\nどのような出力をしたのかを全て保管することで、万が一情報漏洩が発生した場合でも即座に\n原因究明が可能となるような対策が講じられていました。",
    "content_summary": "72 \n \nまた、 開発手法としてはアジャイル開発が採用される傾向が見られました。これは、 現状、生成AI\nの導入に関するベストプラクティスが存在していないことに起因しており、自社に合った構成を手\n探りで検討する中で、結果的にアジャイル形式の開発手法が最も合理的な選択であったと考えられ\nます。 また、 生成AIはモデルの更新頻度が多いことや、 社会情勢の変化に対応する必要があるため、\n通常のシステム構築におけるウォーターフォール型ではなく、アジャイル型が開発手法として最も\n適しています。 \n \n...",
    "content_length": 1107,
    "created_at": "2025-05-12T09:49:11.103630+00:00",
    "updated_at": "2025-05-12T09:49:11.103630+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=74"
  },
  "doc-139fe8f4543131b409e624e42e06d598": {
    "status": "pending",
    "content": "26 \n \n図 2-9は、 「担当者別に着目してほしい章（担当者別の考慮事項が記載） 」 、 「関連する導入・運用プロ\nセスのフェーズ」をまとめたものです。導入担当者の考慮事項については第3 章を、運用担当者の考慮\n事項については第4章を、セキュリティ担当者の考慮事項については第5章を参照してください。 \n但し、他の担当者との円滑な連携のために自身の担当に対応しない章についても閲覧を推奨します。 \n \n \n \n図 2-9: 生成AI導入・運用プロセスの1サイクルにおける担当者の役割",
    "content_summary": "26 \n \n図 2-9は、 「担当者別に着目してほしい章（担当者別の考慮事項が記載） 」 、 「関連する導入・運用プロ\nセスのフェーズ」をまとめたものです。導入担当者の考慮事項については第3 章を、運用担当者の考慮\n事項については第4章を、セキュリティ担当者の考慮事項については第5章を参照してください。 \n但し、他の担当者との円滑な連携のために自身の担当に対応しない章についても閲覧を推奨します。 \n \n \n \n図 2-9: 生成AI導入・運用プロセスの1サイクルにおける担当者の役割",
    "content_length": 243,
    "created_at": "2025-05-12T09:49:11.103512+00:00",
    "updated_at": "2025-05-12T09:49:11.103513+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=28"
  },
  "doc-2ad6c2c64f51d36f9ca4547ca1012e18": {
    "status": "pending",
    "content": "7 \n \n1.1.4 課題 \nAIの中でも、特に生成AIの加速度的な普及の流れには目を見張るものがあります。一般財団法人\nJIPDECが実施した「企業IT利活用動向調査2024」における生成AI使用状況に関するアンケート結果\nによると、 全体の69.5%が生成AIを導入済みまたは導入予定と回答しており、 今後も企業による生成AI\n利用の流れはさらに加速していくと想定されます（図 1-3） 。 \n \n \n図 1-3: 生成AIの使用状況 [4] \n（出典）JIPDEC／ITR「企業IT利活用動向調査2024」p20 \n \n生成AIが普及し、利用開始 ・導入検討している組織も多い一方で、さまざまな課題から導入に踏み切\nれない組織も存在します。 これは、 生成AI導入のために解決すべき課題が数多く存在するにも関わらず、\n企業にとってそれらの多くは未知の課題であり、課題の把握と対策方法の明確化ができていないことが\n原因ではないでしょうか。",
    "content_summary": "7 \n \n1.1.4 課題 \nAIの中でも、特に生成AIの加速度的な普及の流れには目を見張るものがあります。一般財団法人\nJIPDECが実施した「企業IT利活用動向調査2024」における生成AI使用状況に関するアンケート結果\nによると、 全体の69.5%が生成AIを導入済みまたは導入予定と回答しており、 今後も企業による生成AI\n利用の流れはさらに加速していくと想定されます（図 1-3） 。 \n \n \n図 1-3: 生成AIの使用状況 [4] \n（出典）JIPDEC／ITR「企業IT利活用動向調...",
    "content_length": 421,
    "created_at": "2025-05-12T09:49:11.103463+00:00",
    "updated_at": "2025-05-12T09:49:11.103464+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=9"
  },
  "doc-d41d8cd98f00b204e9800998ecf8427e": {
    "status": "pending",
    "content": "",
    "content_summary": "",
    "content_length": 0,
    "created_at": "2025-05-12T09:49:11.103441+00:00",
    "updated_at": "2025-05-12T09:49:11.103443+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=2"
  },
  "doc-c55f7944444fa1f92b127ad84bab2ee0": {
    "status": "pending",
    "content": "48 \n \nユーザ全体に占めるイノベーターとアーリーアダプターの合計の割合が約16%とされています。\nこの普及率約16%にはキャズム（深い溝）が存在し、ここを越えられるかどうかで新しいシス\nテムが普及するかしないかが分かれるとされています（図 4-10） 。 \n生成AIシステムの導入においても、社内普及率が約16%に達するかという観点を1つの指標\nとして利用することができます。 \n \n \n図 4-10: イノベーター理論におけるユーザの区分と普及率の溝 \n \n セキュリティ \n導入した生成AIを評価するためにはユーザの業務に関する項目だけではなく、 セキュリティに\n関する項目も必要になります。運用担当者のみでセキュリティを評価することは困難であるた\nめ、セキュリティ担当者と協力して評価を行う必要があります。具体的な評価方法については\n5.2にて記述します。 \n \n4.4.2 ユーザとの情報共有 \n生成AIの運用において、フィードバックを適切に行うために運用担当者とユーザ間で密に情報交換を\nすることが重要です。適切な情報共有をすることで、生成AIの有効活用と継続的な改善に繋がります。\n以下に、運用担当者がユーザから得るべき情報とその活用方法について説明します。",
    "content_summary": "48 \n \nユーザ全体に占めるイノベーターとアーリーアダプターの合計の割合が約16%とされています。\nこの普及率約16%にはキャズム（深い溝）が存在し、ここを越えられるかどうかで新しいシス\nテムが普及するかしないかが分かれるとされています（図 4-10） 。 \n生成AIシステムの導入においても、社内普及率が約16%に達するかという観点を1つの指標\nとして利用することができます。 \n \n \n図 4-10: イノベーター理論におけるユーザの区分と普及率の溝 \n \n セキュリティ \n導入した生成AI...",
    "content_length": 538,
    "created_at": "2025-05-12T09:49:11.103571+00:00",
    "updated_at": "2025-05-12T09:49:11.103572+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=50"
  },
  "doc-28963bb299b04e256b062f8f28af3633": {
    "status": "pending",
    "content": "83 \n \n要件②：汎用的な生成AIに対する透明性の確保 \n生成AIに対しては、 「学習データの詳細」 「学習・テストの過程」 「著作権保護の方針」に関するドキュ\nメントの提出を求め、汎用的なAIを利用するサービスを提供する事業者についても同様に 「透明性の義\n務」が求められています。 \n \n要件③：欧州の価値観に基づくAIの構築 \n生成AIの学習データや学習データから構築されたモデルの出力結果が、基本的人権やデータ保護規則\nを始めとする欧州の価値観に抵触しないようにすることが求められます。欧州外で作成されたAIモデル\nに含まれる欧州外のデータや価値観が欧州の価値観に沿わない出力を行うことで、欧州の価値観に沿っ\nた欧州のエコシステムの形成を阻害することを懸念しています。そのため、 “欧州の、欧州による、欧州\nのためのAI”を求めている背景があります。 \n \n最後に、AI規制法には興味深い一文が記載されているため、それを紹介します。 「AIは、人間の幸福\n度を高めることを究極の目的として、 人間のためのツールとして機能すべき」 という一文です。 これは、\nAIの位置づけを明確にしていますが、ここからは、 「人間に近いAIが作られること」が想定されている\nように読み取れます。 \n今現在、人間のようなAI、つまり「AGI（汎用人工知能） 」の構築を目指した各国の競争があります \n[55] 。AGIの特性は、 「さまざまなタスクをこなす汎用的な能力」「新たな情報を自己学習する能力」 「独\n自の判断をこなす能力」といえます [57]。現在盛んに開発されている生成AIは、このAGIを作り上げ\nるための大きな礎とも捉えることができます。未来学者のレイ・カーツワイルは、 「2029年にはAIが人\n間並の知能をもつ」と語っています [58]。この発言を踏まえると、AI規制法の先の一文はそう遠くない\n未来にAGIが作られ、 「上記3つの能力を持つので、AIが人格を持った」 「人よりも有能なAIが現れた」\nと言われる可能性を踏まえ追加された前提条件のようにも捉えることができます。本書の記載時点では、\n荒唐無稽で冗談のような話に思えますが、現在多くの科学者が目指している未来でもあり、そのような\nAIが作り上げられるのはすぐそこまで来ているのかもしれません。 \n \n7.3 日本 \n現在、大規模で汎用的な生成AIの構築については、米国が独走している状況です。その裏で欧州は、\n個人と権利の保護を中心とした法規制に取り組み、同時に欧州内のAI開発を進めています。ここでは、\n日本の取り組みについて触れていきます。 \n \nAI開発の未来 \n2023年の日本のAIに対する投資額は6.8億米国ドルであり、世界12位です。一方、現在の生成AIモ\nデル開発の覇権を担う米国は、日本に比べ約100倍、2位の中国と比べても約9倍の投資を行うなど、\n圧倒的な資金をAIに投じており、投資額の競争で米国に追いつくことは容易ではありません。",
    "content_summary": "83 \n \n要件②：汎用的な生成AIに対する透明性の確保 \n生成AIに対しては、 「学習データの詳細」 「学習・テストの過程」 「著作権保護の方針」に関するドキュ\nメントの提出を求め、汎用的なAIを利用するサービスを提供する事業者についても同様に 「透明性の義\n務」が求められています。 \n \n要件③：欧州の価値観に基づくAIの構築 \n生成AIの学習データや学習データから構築されたモデルの出力結果が、基本的人権やデータ保護規則\nを始めとする欧州の価値観に抵触しないようにすることが求められます。欧州...",
    "content_length": 1264,
    "created_at": "2025-05-12T09:49:11.103655+00:00",
    "updated_at": "2025-05-12T09:49:11.103656+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=85"
  },
  "doc-23304c747cfd77c22807cfddbd4cbe9e": {
    "status": "pending",
    "content": "97 \n \n[29] W. R. Owen, S. Eddy , A. Jamie, “Update on the ChatGPT Case: Counsel Who Submitted Fake \nCases Are Sanctioned”, 2023.  \n[30] Ashish Vaswani, Noam Shazeer他, “Attention Is All You Need”, 2017. \n[31] docusign, “ビジネスパーソン1,000人に聞く！生成AIの利用実態と意向”, 2024. \n[32] Stanford University, “Artiﬁcial Intelligence Index Report 2024”, 2024. \n[33] 総務省, “情報通信白書令和5年版”, 2023. \n[34] M. Shuming, W. Hongyu, M. Lingxiao, W. Lei, W. Wenhui, H. Shaohan , D. Li, W. Ruiping, X. \nJilong , W. Furu, “The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits”, 2024. \n[35] 野村総合研究所, “日本のChatGPT利用動向（2023年4月時点） ”, 2023-05-26, \nhttps://www.nri.com/jp/knowledge/report/lst/2023/cc/0526_1. \n[36] 日本貿易振興機構, “2017年のAIスタートアップ企業への投資額は前年比4倍に（フラン\nス） ”, 2019-05-17, \nhttps://www.jetro.go.jp/biz/areareports/special/2019/0502/b6e994afcb842a70.html. [アクセス\n日: 2024-06]. \n[37] 日本貿易振興機構, “連邦政府はAI戦略を発表、中堅・中小企業への浸透を狙う（ドイツ） ”, \n2019-05-17, https://www.jetro.go.jp/biz/areareports/special/2019/0502/9d342ﬀ5304e10e0.html. \n[アクセス日: 2024-06]. \n[38] 日本貿易振興機構, “ドイツ生成AIスタートアップのアレフ・アルファ、欧州最大規模の資金調\n達”, 2023-11-14, https://www.jetro.go.jp/biznews/2023/11/591d6a87c5c7bf7c.html. [アクセス\n日: 2024-06]. \n[39] WIRED, “ドイツのスタートアップAleph Alphaは“欧州のOpenAI”になれるの”, 2023-10-\n02, https://wired.jp/article/aleph-alpha-europe-openai/. [アクセス日: 2024-06]. \n[40] AT PERTNERS, “パリのAIスタートアップである\"Mistral AI\"が$6Bの評価額で$600Mを調達\n交渉中との報道”, 2024-05-10, https://www.atpartners.co.jp/news/2024-05-10-paris-based-ai-\nstartup-mistral-ai-in-talks-to-raise-600m-at-6b-valuation. [アクセス日: 2024-06]. \n[41] Amazon Web Services ブログ, “Mistral AI モデルが Amazon Bedrock で間もなく利用可能\nに”, 2024-03-02, https://aws.amazon.com/jp/blogs/news/mistral-ai-models-coming-soon-to-\namazon-bedrock/. [アクセス日: 2024-06]. \n[42] 日本放送協会, “米 NYタイムズ 著作権侵害でオープンAIとマイクロソフトを提訴”, 2023-\n12-28, https://www3.nhk.or.jp/news/html/20231228/k10014302081000.html. [アクセス日: \n2024-06].",
    "content_summary": "97 \n \n[29] W. R. Owen, S. Eddy , A. Jamie, “Update on the ChatGPT Case: Counsel Who Submitted Fake \nCases Are Sanctioned”, 2023.  \n[30] Ashish Vaswani, Noam Shazeer他, “Attention Is All You Need”, 2017. \n[31] docusign, “ビジネスパーソン1,000人に聞く！生成AIの利用実態と意向”...",
    "content_length": 1865,
    "created_at": "2025-05-12T09:49:11.103691+00:00",
    "updated_at": "2025-05-12T09:49:11.103691+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=99"
  },
  "doc-7e89c9bba01e127913f8ba8e9cfc7856": {
    "status": "pending",
    "content": "87 \n \n8.2 謝辞 \n本書の作成にあたり、ヒアリングにご協力いただきました自治体、企業の皆様には多大なるご支援・ご\n尽力を賜りました。この場を借りて心より御礼申し上げます。 \n \nまた、独立行政法人情報処理推進機構 産業サイバーセキュリティセンター 中核人材育成プログラム\n講師の、満永 拓邦先生、門林 雄基先生には、本書の元となるプロジェクトのメンター・講師として、ご\n指導・ご助言、ご支援を賜りました。改めて御礼申し上げます。加えて、本プロジェクトにご協力いただ\nいた、東洋大学学部生のお二人にも感謝いたします。 \n \nなお、有識者として、三井物産セキュアディレクション株式会社の高江洲 勲様にも有益なご助言をい\nただきました。改めて御礼申し上げます。 \n \nそして、 本書の作成や本プロジェクトを共に実施した、 以下メンバーの皆様にも感謝を伝えたいと思い\nます。 \n \n \n \n<生成AIにおけるセキュリティリスクと対策プロジェクトメンバー> \n（総勢13名） \n【リーダー】 \n辻村 凱 \n \n【サブリーダー】 \n櫻井 健太 下川部 一真 長谷川 奨 \n \n【メンバー】 \n井上 裕斗 斎藤 雅俊 安田 卓磨 \n兼子 翔伍 高橋 直人 山崎 禎章 \n小松 文彦  簱野 公嗣 横道 太志",
    "content_summary": "87 \n \n8.2 謝辞 \n本書の作成にあたり、ヒアリングにご協力いただきました自治体、企業の皆様には多大なるご支援・ご\n尽力を賜りました。この場を借りて心より御礼申し上げます。 \n \nまた、独立行政法人情報処理推進機構 産業サイバーセキュリティセンター 中核人材育成プログラム\n講師の、満永 拓邦先生、門林 雄基先生には、本書の元となるプロジェクトのメンター・講師として、ご\n指導・ご助言、ご支援を賜りました。改めて御礼申し上げます。加えて、本プロジェクトにご協力いただ\nいた、東洋大学学部生のお二...",
    "content_length": 550,
    "created_at": "2025-05-12T09:49:11.103666+00:00",
    "updated_at": "2025-05-12T09:49:11.103666+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=89"
  },
  "doc-873c8da97fc62683531830a89bda29de": {
    "status": "pending",
    "content": "51 \n \n 原因 \nこの情報漏洩の原因は、生成AIのデータ管理の仕組みと、それに対するユーザの認識不足に\nあります。生成AIは、ユーザが入力したデータをサーバに保存し、AIモデルの改善に使用しま\nすが、この過程で機密情報が外部に漏れるリスクが生じます。さらに、ユーザがチャット履歴の\n保存を手動で無効にしない限り、データは削除されずに残る可能性があります （図 5-1） 。この\nような管理体制の不備と従業員の誤操作が重なり、情報漏洩が発生しました。加えて、他の企業\nも同様の懸念から生成AIの利用を制限しており、生成AIの安全性に対する懸念が高まる原因\nとなる事件となりました。 \n \n図 5-1: 生成AIに入力した機密情報がAI提供者・AI事業者に流出するイメージ \n \n 対話型生成AIのサイバー犯罪への利用 [26] \n 背景 \n2024年5月27日、 警視庁は川崎市の男性を不正指令電磁的記録作成の容疑で逮捕しました。\nこの事件は、 対話型生成AIを使用してマルウェアを作成した国内初の事例となります （図 5-2） 。\n報道によると、作成されたマルウェアは暗号化や暗号資産の要求といったランサムウェアに類\n似した機能を持ち、容疑者は「ランサムウェアによって楽に金を稼ぎたかった」と供述してい\nます。 この事件は、 生成AIの悪用が新たなサイバー犯罪の手段となり得ることを示しています。 \n \n 原因 \n今回の事件の原因は、生成AIの普及とその悪用の容易さにあります。報道によると、容疑者\nは特別なIT専門知識を持たず、複数の生成AIサービスを利用して悪意のあるプログラムを作\n成したと報じられました。これは、技術的な知識が乏しい人でも生成AIを使って簡単にマルウ\nェアを作成できることを示し、生成AIツールの悪用リスクが顕在化した象徴的な事件です。さ\nらに、生成AIが犯罪行為を助長しうるという点で、サイバーセキュリティに新たな課題をもた\nらす可能性があります。",
    "content_summary": "51 \n \n 原因 \nこの情報漏洩の原因は、生成AIのデータ管理の仕組みと、それに対するユーザの認識不足に\nあります。生成AIは、ユーザが入力したデータをサーバに保存し、AIモデルの改善に使用しま\nすが、この過程で機密情報が外部に漏れるリスクが生じます。さらに、ユーザがチャット履歴の\n保存を手動で無効にしない限り、データは削除されずに残る可能性があります （図 5-1） 。この\nような管理体制の不備と従業員の誤操作が重なり、情報漏洩が発生しました。加えて、他の企業\nも同様の懸念から生成AIの利...",
    "content_length": 843,
    "created_at": "2025-05-12T09:49:11.103578+00:00",
    "updated_at": "2025-05-12T09:49:11.103579+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=53"
  },
  "doc-81538ea48ae3359b978cdad436e938cc": {
    "status": "pending",
    "content": "5 \n \n1.1.2 AI 発展の歴史 \n生成AIを含む近年のAIの目覚ましい発展は、これまでの技術開発が実を結んだ結果といえます（表 \n1-1） 。AIと呼ばれる技術の歴史は古く、イギリスの数学者アラン・チューリングによる1950年の著書\n『計算する機械と人間』で初めてAIの概念が提唱されたことを発端に、1956年のダートマス会議で「人\n工知能 （Artiﬁcial Intelligence） 」という用語が初めて公式に使われ、AIの研究分野が誕生しました。この\n時代には、コンピュータによる「推論」や「探索」の研究が進展し、迷路の攻略や定理の証明のような、\n明確かつ単純な問題の解決が可能になりました。 \n1970年代には、主にシンボリックAI（Symbolic AI）として知られるアプローチに焦点を当てた研究\nがなされていました。シンボリックAIは、明確なルールに基づく知識表現と演繹を重視したアプローチ\nであり、エキスパートシステムと呼ばれる特定の専門領域で専門知識をルールとして組み込まれました。\nこのシステムは、組み込まれたルールに基づいて問題解決を行うことが可能であり、大きな成果を得る\nことができました。 \n一方、1990年代以降のAI研究はニューラルネットワーク（Neural AI）を基盤とした新たなアプロー\nチへと進化しました。ニューラルネットワークは、脳の神経回路を模倣したモデルであり、入力層、出力\n層、隠れ層から構成され、層と層の間には、ニューロンの繋がりの強さを示す重みがあります。これを多\n数組み合わせることで、幅広い応用が可能となり、現在のAI技術の基盤を築き、特に画像認識や音声認\n識などのパターン認識の分野で大きな成果を得ることができました。 \nそして、2010年代にはディープラーニングと呼ばれる手法が登場したことで、高精度な予測が現実的\nとなり、AIが更なる脚光を浴びることになりました。 \nさまざまな言語処理タスクへのAI活用は、2017年頃に、Transformerと呼ばれるディープラーニング\nモデルがGoogleの研究者らによって開発され、続いてGPT、BERTが開発されたことで大きく推進し\nました。これが、テキスト生成を目的とするテキスト生成AIの発展へと繋がります。従来のAIがデー\nタから何らかの予測を得ることを目的とするのに対し、生成AIはデータを基に新たなデータを生成しま\nす。テキスト生成AIに関しては、OpenAI社によるChatGPTを皮切りにさまざまな大規模言語モデル\n（LLM）が開発されました。Google社のGemini（旧名：Bard）やAnthropic社のClaudeなどです。 \nこれらのサービスは前述のディープラーニングモデルを元に構築されているため、画像や音声のパタ\nーン認識、創造的なタスクにおいて卓越した性能を発揮しますが、シンボリックAIが得意とする明確な\nルールと論理に基づいた推論や演繹においては、まだ改善の余地があると言われています。",
    "content_summary": "5 \n \n1.1.2 AI 発展の歴史 \n生成AIを含む近年のAIの目覚ましい発展は、これまでの技術開発が実を結んだ結果といえます（表 \n1-1） 。AIと呼ばれる技術の歴史は古く、イギリスの数学者アラン・チューリングによる1950年の著書\n『計算する機械と人間』で初めてAIの概念が提唱されたことを発端に、1956年のダートマス会議で「人\n工知能 （Artiﬁcial Intelligence） 」という用語が初めて公式に使われ、AIの研究分野が誕生しました。この\n時代には、コンピュータによる「...",
    "content_length": 1270,
    "created_at": "2025-05-12T09:49:11.103457+00:00",
    "updated_at": "2025-05-12T09:49:11.103458+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=7"
  },
  "doc-fea22af0584e69946b5b4b220302055b": {
    "status": "pending",
    "content": "23 \n \n段階的導入（スモールスタート） \n本書における生成AI導入では、 「スモールスタート」を意識しています。スモールスタートとは、少な\nいコストや時間で小さな規模から技術導入等を開始することです。 \n生成AIは技術革新のスピードが著しく速いため、他のシステム開発と比較してスモールスタートの重\n要性が高くなります。実際、ヒアリングした多くの組織では、 \n 「導入工数削減のため、担当者が生成AIについて学習しつつ導入検討する」 \n 「導入失敗・手戻り発生を防ぐため、事前に試しの導入を実施して、効果・安全性を確認したい」  \nという理由から、対象ユーザを社員全員とし、実装した機能を全て盛り込んだ状態でいきなり導入する\nよりも、機能や利用範囲を制限した状態で一度試験導入・運用を実施していました。 \n \nドキュメンテーション \n生成AIの導入において、システムの設定内容やその設定を行った経緯について文書化して記録するこ\nとが重要です。スモールスタートの状態から必要に応じてシステム更新を実施する必要がありますが、\nこの文書化によって組織が意思決定を円滑に進めることができます。 \nまた、運用面においてもユーザが適切にシステムを利用できるように利活用ガイドラインやマニュア\nルなどを文書化して記録を残すことにより、業務効率の向上やリスクの軽減に寄与することができます。  \n \n継続的改善 \n生成 AI をはじめとしたシステムの導入・運用においては、システムそのものや利活用ガイドラインな\nどに対して継続的に改善を行うことで、より効果的な運用に繋げられます。特に生成AIは研究が盛んに\n行われており技術的な進歩や社会情勢の変化が激しい分野であるため、継続的な改善が求められます。 \nまた、システム全体に対してだけではなく、導入・運用プロセス内の各フェーズにおいてもPDCAサ\nイクルを回し、より良いシステムの導入を目指すことが重要です。",
    "content_summary": "23 \n \n段階的導入（スモールスタート） \n本書における生成AI導入では、 「スモールスタート」を意識しています。スモールスタートとは、少な\nいコストや時間で小さな規模から技術導入等を開始することです。 \n生成AIは技術革新のスピードが著しく速いため、他のシステム開発と比較してスモールスタートの重\n要性が高くなります。実際、ヒアリングした多くの組織では、 \n 「導入工数削減のため、担当者が生成AIについて学習しつつ導入検討する」 \n 「導入失敗・手戻り発生を防ぐため、事前に試しの導入を実施...",
    "content_length": 824,
    "created_at": "2025-05-12T09:49:11.103505+00:00",
    "updated_at": "2025-05-12T09:49:11.103506+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=25"
  },
  "doc-321a6b626cc2fc409497bef00c10efaf": {
    "status": "pending",
    "content": "57 \n \n \n図 5-5: 生成AIシステム構成例 \n \n5.3.2 特定の例 \nここからは、実際にリスクアセスメントの実施例を記載します。まず、リスク特定の実施例を説明しま\nす。 \n下記は、リスク特定の手順です。 \na) 資産の特定 \n組織で保有する資産（システム、データ、ネットワーク等）の棚卸を実施し、リスク管理を\n行う対象を明確にします。生成AIを新規導入する際であれば、既存の資産の棚卸に加え、\n生成AIシステムと関連するデータ・ネットワークを追加します。 \nb) リスクの特定 \n資産毎にどのようなリスクが存在するのか、 リスクの洗い出しを行います。例えば、 フィッ\nシング攻撃やDoS攻撃などの外部からのリスク、ユーザの過失や内部不正などの内部から\nのリスク等、様々な観点からリスクを洗い出します。",
    "content_summary": "57 \n \n \n図 5-5: 生成AIシステム構成例 \n \n5.3.2 特定の例 \nここからは、実際にリスクアセスメントの実施例を記載します。まず、リスク特定の実施例を説明しま\nす。 \n下記は、リスク特定の手順です。 \na) 資産の特定 \n組織で保有する資産（システム、データ、ネットワーク等）の棚卸を実施し、リスク管理を\n行う対象を明確にします。生成AIを新規導入する際であれば、既存の資産の棚卸に加え、\n生成AIシステムと関連するデータ・ネットワークを追加します。 \nb) リスクの特定 \n資産毎...",
    "content_length": 357,
    "created_at": "2025-05-12T09:49:11.103593+00:00",
    "updated_at": "2025-05-12T09:49:11.103593+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=59"
  },
  "doc-88c59b857c86cb3a584d1d2050ba452a": {
    "status": "pending",
    "content": "14 \n \n2.1.2 テキスト生成AIと大規模言語モデル（LLM） \n生成AIでは、テキスト、画像、動画、音声など、出力したいコンテンツによって異なるモデルが使用\nされます。ここでは、本書のスコープであるテキスト生成AIに関して少し掘り下げて紹介します。 \n \nテキスト生成AIは自然言語処理技術を利用した文章生成を行います。自然言語処理を行うモデルとし\nて、近年では、大規模言語モデル（Large Language Models、以下LLMと呼称）が使用されます。 \n言語モデルとは文章や単語の出現確率をモデル化したもので、直前の文章や単語に続く確率が最も高\nい単語を出力することができ、テキスト生成に利用されます。その中でもLLMは、大量のテキストデー\nタを学習した大規模な言語モデルを指します。LLMは従来の言語モデルと比較すると、 「計算量（コンピ\nュータが処理可能な計算量） 」 「データ量（入力した文章データの情報量） 」 「パラメータ数（ディープラー\nニング特有の確率演算を行うために必要な係数の数） 」の3点が大幅に増加し、精度が格段に向上してい\nます。 そのため単なるテキスト生成だけでなく、 チャットボットや文章要約などにも応用されます。2024\n年6月時点の代表的なLLMには、Anthropic社の 「Claude3」 、Google社の 「Gemini」 、Meta社の 「Llama3」 、\nOpenAI社の 「GPT-4」 等があります。 端的に言えば、 テキスト生成AIは広範なカテゴリーであり、LLM\nはテキスト生成AIを構成する要素の一つであると言えます。 \n \n \n図 2-2: テキスト生成AIとLLMの位置付け",
    "content_summary": "14 \n \n2.1.2 テキスト生成AIと大規模言語モデル（LLM） \n生成AIでは、テキスト、画像、動画、音声など、出力したいコンテンツによって異なるモデルが使用\nされます。ここでは、本書のスコープであるテキスト生成AIに関して少し掘り下げて紹介します。 \n \nテキスト生成AIは自然言語処理技術を利用した文章生成を行います。自然言語処理を行うモデルとし\nて、近年では、大規模言語モデル（Large Language Models、以下LLMと呼称）が使用されます。 \n言語モデルとは文章や単語の出...",
    "content_length": 727,
    "created_at": "2025-05-12T09:49:11.103482+00:00",
    "updated_at": "2025-05-12T09:49:11.103483+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=16"
  },
  "doc-d89b6780d0f346a1bf0e38f2ed938841": {
    "status": "pending",
    "content": "78 \n \n第7章 各国の動向 \n7.1 開発と投資について \nGoogle社の 「Attention Is All You Need」 （Transformerモデルに関する論文 ：2017年） [30]の発表を\n皮切りに、それまでと次元の異なる高精度なAIが多く開発されるようになりました。現時点において日\n本で最も有名な生成AIは、OpenAI社のChatGPTですが、 [31]。 無論それ以外にもGeminiやClaude、\nLlama 3などが、高度な生成AIとして広く認識されています。ここでは、これらの主な生成AIと、それ\nらに追従していく各国のAI開発について記載します。 \n \n7.1.1 米国について \n生成AIは、多くの学習データを学習させることで、AIモデルの推論能力を高めています。学習には大\n量のデータを処理する性能と、それを実現するリソースやコストが必要です。そのため、推論能力を向上\nさせたモデルを開発するには、より高い設備性能と多くの資本が求められます。 \n最も処理性能の高い生成AIの開発元もしくは業務提携先の多くには、世界で有数の資金力を持つ企業\nの数々が揃っており、特に米国企業が多いです。それらの企業は、多大な資本を武器に、大規模データを\n処理するスーパーコンピュータを用いたAIモデルの開発を行っています。AIの権威的なドキュメント\nであるAI Index Report [32]では、2023年までに開発されたAIモデルに利用されたコンピュータの計算\n処理速度が示されています（図 7-1） 。 \n \n図 7-1: AIモデルに利用されたコンピュータの計算処理速度 \n(出典)Stanford University, Artiﬁcial Intelligence Index Report 2024 p51 [32]",
    "content_summary": "78 \n \n第7章 各国の動向 \n7.1 開発と投資について \nGoogle社の 「Attention Is All You Need」 （Transformerモデルに関する論文 ：2017年） [30]の発表を\n皮切りに、それまでと次元の異なる高精度なAIが多く開発されるようになりました。現時点において日\n本で最も有名な生成AIは、OpenAI社のChatGPTですが、 [31]。 無論それ以外にもGeminiやClaude、\nLlama 3などが、高度な生成AIとして広く認識されています。...",
    "content_length": 782,
    "created_at": "2025-05-12T09:49:11.103643+00:00",
    "updated_at": "2025-05-12T09:49:11.103644+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=80"
  },
  "doc-5d521e5a7c0f100ef9268c3a361dd90d": {
    "status": "pending",
    "content": "99 \n \n2024-06]. \n[56] T. M. Stryker, “人工超知能とは”, 2023-12-18, https://www.ibm.com/jp-ja/topics/artiﬁcial-\nsuperintelligence. [アクセス日: 2024-06]. \n[57] Amazon Web Services, “AGI とは何ですか?”, https://aws.amazon.com/jp/what-is/artiﬁcial-\ngeneral-intelligence/. [アクセス日: 2024-06]. \n[58] 日経XTECH, “人間同等以上の処理が可能な汎用人工知能「AGI」 、専門家の多くは登場に肯定\n的”, 2024-01-22, https://xtech.nikkei.com/atcl/nxt/column/18/01679/113000143/. [アクセス\n日: 2024-06]. \n[59] 日本放送協会, “生成AI普及で電力需要に異変？”, 2024-05-21, \nhttps://www3.nhk.or.jp/news/html/20240521/k10014455901000.html. [アクセス日: 2024-06]. \n[60] 日本放送協会, “AI開発のスーパーコンピューター 国内整備に最大725億円補助へ”, 2024-04-\n19, https://www3.nhk.or.jp/news/html/20240419/k10014426711000.html. [アクセス日: 2024-6]. \n[61] 株式会社マクニカ, “ビジネスに最適なAI～汎用AIを超える垂直型AIとは～”, 2021-12-21, \nhttps://www.macnica.co.jp/business/ai/blog/142033/. [アクセス日: 2024-06]. \n[62] 三部 裕幸, “EUのAI規則案に対する欧州での反応の続報と米国の動向について”, 2022-04-27, \nhttps://www.soumu.go.jp/main_content/000811790.pdf. [アクセス日: 2024-06].",
    "content_summary": "99 \n \n2024-06]. \n[56] T. M. Stryker, “人工超知能とは”, 2023-12-18, https://www.ibm.com/jp-ja/topics/artiﬁcial-\nsuperintelligence. [アクセス日: 2024-06]. \n[57] Amazon Web Services, “AGI とは何ですか?”, https://aws.amazon.com/jp/what-is/artiﬁcial-\ngeneral-intelligence/....",
    "content_length": 953,
    "created_at": "2025-05-12T09:49:11.103699+00:00",
    "updated_at": "2025-05-12T09:49:11.103700+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=101"
  },
  "doc-bfc6073794cfc6cd4b58be47a7d9c27b": {
    "status": "pending",
    "content": "27 \n \n第3章 生成 AI の導入について \n本章では、組織に生成AIを導入する担当者 （導入担当者）の主な考慮事項を説明します。2.4.3で説明\nした通り、導入担当者が主に担当するのは「構想策定」 「要件定義」 「設計・開発」 「テスト・デプロイ」\nの4つのフェーズです。各フェーズの考慮事項を明確化することで、効果的かつセキュアな生成AIの導\n入を目指します。 \n \n \n図 3-1: 導入プロセスと導入担当者の該当フェーズ \n \n3.1 構想策定 \n3.1.1 利用ニーズの調査 \n構想策定において、従業員に対する生成AI利用のニーズ調査は導入目的を明確にするために重要な要\n素となるため、早期に実施することを推奨します。生成AIは汎用性が高く、多彩な用途に利用可能な技\n術です。ただし、現場のニーズを正しく理解できていない場合、適切な導入目的の設定ができず、生成AI\nを導入しても従業員による活用が進まず、期待した効果が得られない原因になります。そのため、従業員\nが生成AI導入でどのような効果を求めているのかをアンケートや有識者のヒアリング等で調査し、従業\n員のニーズに基づいた適切な導入目的の設定が求められます。 \n \n3.1.2 導入目的の決定 \n利用ニーズの調査後、生成AIの導入目的を明確に定めることが重要です。生成AIは多様な用途に適\n用可能で技術進化が非常に早いため、明確な目的がなければ、生成AIを既存の業務プロセスでどのよう\nに活用すべきかの判断が困難です。また、導入目的は生成AI導入の効果測定においても重要です。 「生\n成AIを導入している企業が増えているから」などの曖昧な目的ではなく、明確な目的を設定した上で、\n生成AIの導入を推進するようにしましょう。 \n \n導入目的の例 \n 全社員を対象とした社内業務（文章作成・要約、プログラミング、アイデア出しなど）の効率化 \n チャットボットを利用した問い合せ窓口業務の効率化 \n RAGを活用した社内情報検索の効率化",
    "content_summary": "27 \n \n第3章 生成 AI の導入について \n本章では、組織に生成AIを導入する担当者 （導入担当者）の主な考慮事項を説明します。2.4.3で説明\nした通り、導入担当者が主に担当するのは「構想策定」 「要件定義」 「設計・開発」 「テスト・デプロイ」\nの4つのフェーズです。各フェーズの考慮事項を明確化することで、効果的かつセキュアな生成AIの導\n入を目指します。 \n \n \n図 3-1: 導入プロセスと導入担当者の該当フェーズ \n \n3.1 構想策定 \n3.1.1 利用ニーズの調査 \n構想策定...",
    "content_length": 853,
    "created_at": "2025-05-12T09:49:11.103515+00:00",
    "updated_at": "2025-05-12T09:49:11.103516+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=29"
  },
  "doc-8a7f90f61746b804a5960fc7ed7b63a4": {
    "status": "pending",
    "content": "目次 \n第1章 はじめに ................................................................................................................... 4 \n1.1 背景 .......................................................................................................................... 4 \n1.1.1 AIの組織での普及について ............................................................................. 4 \n1.1.2 AI発展の歴史 ................................................................................................... 5 \n1.1.3 ディープラーニングの発展 .............................................................................. 6 \n1.1.4 課題 ................................................................................................................... 7 \n1.2 本書の作成目的 ........................................................................................................ 8 \n1.3 本書のスコープ ........................................................................................................ 9 \n1.4 本書の特徴 ............................................................................................................. 10 \n1.5 本書の活用例 .......................................................................................................... 11 \n1.6 免責事項 ................................................................................................................. 12 \n第2章 本書を最大限に活用するために ............................................................................. 13 \n2.1 生成AIとは ........................................................................................................... 13 \n2.1.1 生成AIの定義 ................................................................................................ 13 \n2.1.2 テキスト生成AIと大規模言語モデル（LLM） ............................................ 14 \n2.1.3 テキスト生成AIの回答精度向上のための技術 ............................................. 15 \n2.1.4 テキスト生成AIの入力から回答までの流れ ................................................. 16 \n2.2 テキスト生成AIの組織活用 .................................................................................. 17 \n2.2.1 組織活用可能な場面 ....................................................................................... 17 \n2.2.2 組織活用における実態 .................................................................................... 18 \n2.3 テキスト生成AIの組織導入に向けて ................................................................... 19 \n2.3.1 テキスト生成AI導入と課題 .......................................................................... 19 \n2.3.2 AIシステムの組織導入における信頼性 ......................................................... 20 \n2.3.3 テキスト生成AIの組織導入におけるリスク ................................................. 21 \n2.4 テキスト生成AIの組織導入・運用プロセスと担当者 .......................................... 22 \n2.4.1 導入・運用の前提事項 .................................................................................... 22 \n2.4.2 導入・運用の流れ（プロセス） ..................................................................... 24 \n2.4.3 導入・運用における担当者 ............................................................................ 25 \n第3章 生成AIの導入について ......................................................................................... 27 \n3.1 構想策定 ................................................................................................................. 27 \n3.1.1 利用ニーズの調査 ........................................................................................... 27 \n3.1.2 導入目的の決定............................................................................................... 27 \n3.1.3 目的に応じたスコープの決定 ......................................................................... 28 \n3.2 要件定義 ................................................................................................................. 28",
    "content_summary": "目次 \n第1章 はじめに ................................................................................................................... 4 \n1.1 背景 ..................................................................................................................",
    "content_length": 3642,
    "created_at": "2025-05-12T09:49:11.103446+00:00",
    "updated_at": "2025-05-12T09:49:11.103447+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=3"
  },
  "doc-1d5bb58c07044dea5f6354ba935b61bb": {
    "status": "pending",
    "content": "20 \n \n2.3.2 AI システムの組織導入における信頼性 \nテキスト生成AIに限らず、システムを組織に導入する上で、組織の人間が動作について信頼性の高い\nシステムを目指すことは重要な要素であると考えます。 \nNISTのAI RMFでは、信頼できるAIシステムの特徴を7つの観点で整理しています（表 2-1） 。AI\nシステムを使用する環境や状況に応じてこの7 つのバランス（どこに重点を置くか）は異なるため、各\n項目単体ではなく全ての項目を考慮することが適切なリスク管理に繋がります。 \n \n表 2-1: 信頼できる AI システムの特徴 [7] \n \n※1：①はシステムの基本動作に影響を与える項目の為、②から⑥までに関わる形で表記する。 \n※2：⑦は他者への説明責任や情報の開示などの運用面での特徴について記載している。 \n \n信頼できるAIシステムの重要性はテキスト生成AIにおいても変わりません。組織でのテキスト生成\nAI導入では、この7つの観点をもとにリスクを軽減し、信頼できるAIシステムを目指すことが推奨さ\nれます。 \n \n  \n概要①有効性/信頼性※1故障することなく、意図したとおりに動作している状態②安全性人間の生命、健康、財産、環境が危険にさらされていない状態③セキュリティと回復力機密性や完全性、可用性などを維持する仕組みを保っている状態、予期せぬ事態から回復できる状態④説明可能かつ解釈可能AIシステムの動作の根底にあるメカニズムを言語化でき、アウトプットが解釈できる状態⑤プライバシー保護個人情報やプライバシーが保護されている状態⑥公平性（有害なバイアス管理）偏見や差別による影響がなく、平等性や公平性に配慮されている状態⑦説明責任と透明性※2AIシステムのライフサイクルに応じた適切なレベルの情報へのアクセスを提供できる状態\n信頼できるAIシステムの特徴",
    "content_summary": "20 \n \n2.3.2 AI システムの組織導入における信頼性 \nテキスト生成AIに限らず、システムを組織に導入する上で、組織の人間が動作について信頼性の高い\nシステムを目指すことは重要な要素であると考えます。 \nNISTのAI RMFでは、信頼できるAIシステムの特徴を7つの観点で整理しています（表 2-1） 。AI\nシステムを使用する環境や状況に応じてこの7 つのバランス（どこに重点を置くか）は異なるため、各\n項目単体ではなく全ての項目を考慮することが適切なリスク管理に繋がります。 \n \n表...",
    "content_length": 795,
    "created_at": "2025-05-12T09:49:11.103498+00:00",
    "updated_at": "2025-05-12T09:49:11.103499+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=22"
  },
  "doc-89c956bc863280fb7165d37e29301fa0": {
    "status": "pending",
    "content": "6 \n \n表 1-1: 生成AIが普及するまでの人工知能（AI）の歴史 [3] \n \n \n1.1.3 ディープラーニングの発展 \nここまで述べた半世紀以上の技術的発展に加え、既に述べた「ディープラーニング（機械学習を含む）\nの発展」のほかに、 「コンピュータ計算性能の向上」や「ビッグデータ」の出現が近年のAIの急速な発\n展・普及につながっています。 \n「コンピュータ計算性能の向上」は、回路の集積率に比例して性能が向上することから、大規模集積回\n路の進化と言い換えることができます。インテル社の共同創設者であるゴードン・ムーア氏が提言した\n「ムーアの法則」では、半導体の集積率は18か月ごとに2倍に増加すると謳われており、現在に至るま\nで指数関数的に性能が向上しています。 また、GPUの使用による複雑な並列計算が可能となったことも、\n計算性能向上の要因として知られています。 \n次に高速通信網の整備やクラウド技術の発展などを背景に 「ビッグデータ」という概念が生まれたこと\nにより、初期投資を抑制しつつ、膨大で多様なデータを安全かつ簡単に蓄積できようになりました。ま\nた、このデータ利用の敷居の低下に伴い、専門機関でなくとも、機械学習モデルの学習や検証が可能とな\nったことも、AIの発展・普及に大きく寄与したものと考えられます。 \n年代 年 AIに関する出来事 主な技術等1950アラン・チューリングが「チューリングテスト」を提唱し、機械が知能を持っているかどうかを評価する基準を設定1956ダートマス会議で「人工知能」という用語が初めて使われ、AI研究の分野が正式に誕生1960年代1964 人工対話システムELIZA開発1972 初のエキスパートシステムMUCIN開発MYCINの知識表現と推論を一般化したEMYCIN開発ディープラーニングの基本構造の一つ「ネオコグニトロン」が考案1982～92 第5世代コンピュータプロジェクト1984 知識記述のプロジェクト開始1986 誤差逆伝播法の発表1989 CNN（畳み込みニューラルネットワーク）が発表1990年代 1997 IBMが開発したディープブルーが、世界チェスチャンピオンに勝利2000年代2006 ディープラーニングの提唱2012 ディープラーニングの提唱技術を画像認識コンテストに適用2017 Googleの研究者らが深層学習モデル「Transformer」を発表2018 OpenAIが大規模言語モデル「GPT」を開発2022 OpenAIが対話型AIサービス「ChatGPT」を発表2023OpenAIのみならず様々な企業の大規模言語モデルが登場（Meta社,Llama2、Anthropic社,Claude2等）\n2024～上記大規模言語モデルの発展バージョンが多く公開され、急速に開発が進んでいる\n・Transformer・GPT・BERT・大規模言語モデル（LLM）2020年代\n1950年代\n2010年代 ・機械学習・ディープラーニング\n19791970年代\n・探索、推論・自然言語処理・ニューラルネットワーク・遺伝的アルゴリズム・エキスパートシステム\n1980年代 ・知識ベース・音声認識・データマイニング・オントロジー・統計的自然言語処理",
    "content_summary": "6 \n \n表 1-1: 生成AIが普及するまでの人工知能（AI）の歴史 [3] \n \n \n1.1.3 ディープラーニングの発展 \nここまで述べた半世紀以上の技術的発展に加え、既に述べた「ディープラーニング（機械学習を含む）\nの発展」のほかに、 「コンピュータ計算性能の向上」や「ビッグデータ」の出現が近年のAIの急速な発\n展・普及につながっています。 \n「コンピュータ計算性能の向上」は、回路の集積率に比例して性能が向上することから、大規模集積回\n路の進化と言い換えることができます。インテル社の共同...",
    "content_length": 1362,
    "created_at": "2025-05-12T09:49:11.103460+00:00",
    "updated_at": "2025-05-12T09:49:11.103461+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=8"
  },
  "doc-b393c9a3d516e45024a6e0d2272c3f6d": {
    "status": "pending",
    "content": "60 \n \n5.3.4 評価の例 \nリスク評価では、リスク全体から、対応/非対応の閾値決めや対応優先度付けを行います。引き続きリ\nスクマトリクスを使用します。 \n今回の閾値決めでは、 図 5-6のリスクマトリクスにてMedium （中程度）以上とされたリスクに対し、\n優先的にリスク対策を行うこととします。 図 5-7中、 赤色の点線で示した範囲内のリスクが該当します。\n実際にはさらに、各リスクに対する優先度付けを、対策に必要な費用および工数等の費用対効果の観点\nから行う手順を実施します。 \n \n図 5-7: リスクマトリクスにおける閾値決定 \n \n5.4 リスク対応 \nリスク対応では、リスクアセスメントにおいて決定したリスク対策を実施します。本節では、生成AI\n特有の対策方法に注目して記載します。生成AI特有といっても、基本的な対策の考え方には従来の考え\n方に共通する部分が多く、まず基本となる考え方として、 「多層防御」に触れます。 \nまた、 全てのリスク対策を実施しても残存リスクが完全にゼロになることはありません。 対策に過剰な\nコストやリソースをかけるのではなく、残存リスクの受容も選択肢の一つとして経営者と一緒に検討し\nていくことが重要です。",
    "content_summary": "60 \n \n5.3.4 評価の例 \nリスク評価では、リスク全体から、対応/非対応の閾値決めや対応優先度付けを行います。引き続きリ\nスクマトリクスを使用します。 \n今回の閾値決めでは、 図 5-6のリスクマトリクスにてMedium （中程度）以上とされたリスクに対し、\n優先的にリスク対策を行うこととします。 図 5-7中、 赤色の点線で示した範囲内のリスクが該当します。\n実際にはさらに、各リスクに対する優先度付けを、対策に必要な費用および工数等の費用対効果の観点\nから行う手順を実施します。 \n \n...",
    "content_length": 531,
    "created_at": "2025-05-12T09:49:11.103600+00:00",
    "updated_at": "2025-05-12T09:49:11.103600+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=62"
  },
  "doc-528fd27c91cbf32ec460ded9d723673b": {
    "status": "pending",
    "content": "34 \n \n3.2.6 回答精度向上における選択肢 \n生成AIの課題の1つとして、LLMが学習していないデータに関する回答の精度が大きく低下する点\nが挙げられます。例えば、インターネットに掲載されていない社内ドキュメントのようなデータ、専門性\nの高いデータ、LLM作成時点では公開されていない最新のデータなどに関する質問に正確に回答するこ\nとは困難です。この課題への代表的な対策としてはファインチューニングとRAG （Retrieval-Augmented \nGeneration）の2つの技術が存在します（詳細については2.1.3「テキスト生成AIの回答精度向上のた\nめの技術」を参照ください） 。 \nファインチューニングとRAGの効果は単純に比較することは難しいですが、Microsoftの検証結果で\nは、RAGのほうがファインチューニングよりも優れたパフォーマンスを発揮するとされています [15]。\nまた、2024年6月時点では導入難易度の観点においてもRAGのほうに優位性があり、組織での活用が\nより現実的であるとされています。しかし、RAGを利用することの優位性を保つためには、いくつか注\n意すべき点も存在します。例えば、時間が進むにつれて、学習させた情報は古くなっていくため、回答精\n度を安定させるためにはRAGに使用するデータを必要に応じて更新することが重要です。 \nまた、セキュリティとプライバシーの観点から、RAGに使用するデータに機密情報や個人情報が含ま\nれる場合、適切なアクセス制限やデータの定期的な棚卸が重要です。さらに、RAGをはじめとする生成\nAIに関する技術は、その進化が著しいため、常にその動向を注視することが重要です。 \n \n3.3 設計・開発 \n設計・開発のフェーズで、導入担当者は、要件定義の内容を設計書に落とし込み、設計内容を共有が必\n要な関係各位2に伝えます。設計の詳細は組織によって異なるため、ここでは一般的な考慮事項について\n記載します。 \n \n3.3.1 導入ベンダへのフィードバック \n生成AIの導入において、自社独自で設計および開発を実行できる組織は少なく、実際の導入時には主\nに導入ベンダが設計および開発を担当することが多くなると想定されます。 \n導入ベンダは事前に定めた要件定義に沿って設計・開発を進めますが、 組織の社内規定やポリシーに沿\nっているか適宜確認していく必要があります。各組織によって部署が管轄する範囲は異なりますが、導\n入担当者が運用担当者およびセキュリティ担当者の意見を収集し、導入ベンダへフィードバックしてい\nくことが重要です。 \n \n \n2 設計・開発者は組織の内部の者である場合もあれば、外部の者（外注）である場合もある。また、導\n入者＝設計・開発者の場合もある。",
    "content_summary": "34 \n \n3.2.6 回答精度向上における選択肢 \n生成AIの課題の1つとして、LLMが学習していないデータに関する回答の精度が大きく低下する点\nが挙げられます。例えば、インターネットに掲載されていない社内ドキュメントのようなデータ、専門性\nの高いデータ、LLM作成時点では公開されていない最新のデータなどに関する質問に正確に回答するこ\nとは困難です。この課題への代表的な対策としてはファインチューニングとRAG （Retrieval-Augmented \nGeneration）の2つの技術が存在...",
    "content_length": 1173,
    "created_at": "2025-05-12T09:49:11.103531+00:00",
    "updated_at": "2025-05-12T09:49:11.103532+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=36"
  },
  "doc-101bc9651f645292a6ba0fe8f1b5a14d": {
    "status": "pending",
    "content": "9 \n \n本書は、生成AIのセキュリティリスクと適切な対策を示すことで、組織における生成AI利用の不安\n感を払拭し、安全な導入と運用を促進することを目的とします。今後、ますます重要になると予想される\n生成AIですが、本書を活用することで、適切なリスク管理を施し、安全で効果的な活用ができるように\nなることを期待します。 \n \n1.3 本書のスコープ \nまず、本書の対象読者は、総務省・経済産業省発行の「AI事業者におけるガイドライン第1版」 [6]\n（以降、AIガイドライン）における 「AI利用者」とします。 「AI利用者」の中でも特に、 「組織が管理す\nる生成AIを導入・運用・管理を行う担当者」に焦点を当てています。 \nなお、AIガイドラインでは、 「AIの事業活動を担う主体」を、 「AI利用者」に加えて 「AI提供者」 、 「AI\n開発者」と、3者に大別しています。参考までに、それぞれの定義を以下に引用します。 \n \n AI利用者（AI Business User） \n事業活動において、AIシステム又はAIサービスを利用する事業者 \nAI提供者が意図している適正な利用を行い、環境変化等の情報をAI提供者と共有し正常稼\n働を継続すること又は必要に応じて提供されたAIシステムを運用する役割を担う。また、AI\nの活用において業務外利用者に何らかの影響が考えられる場合は、当該者に対するAIによる\n意図しない不利益の回避、AIによる便益最大化の実現に努める役割を担う。 \n \n AI提供者（AI Provider） \nAIシステムをアプリケーション、製品、既存のシステム、ビジネスプロセス等に組み込んだ\nサービスとしてAI利用者（AI Business User） 、場合によっては業務外利用者に提供する事業\n者 \nAIシステム検証、AIシステムの他システムとの連携の実装、AIシステム・サービスの提供、\n正常稼働のためのAIシステムにおけるAI利用者（AI Business User）側の運用サポート又は\nAIサービスの運用自体を担う。AIサービスの提供に伴い、様々なステークホルダとのコミュ\nニケーションが求められることもある。 \n \n AI開発者（AI Developer） \nAIシステムを開発する事業者（AIを研究開発する事業者を含む） \nAIモデル・アルゴリズムの開発、データ収集（購入を含む） 、前処理、AIモデル学習及び検\n証を通してAIモデル、AIモデルのシステム基盤、入出力機能等を含むAIシステムを構築す\nる役割を担う。 \n \n（総務省・経済産業省,2024, p.5）",
    "content_summary": "9 \n \n本書は、生成AIのセキュリティリスクと適切な対策を示すことで、組織における生成AI利用の不安\n感を払拭し、安全な導入と運用を促進することを目的とします。今後、ますます重要になると予想される\n生成AIですが、本書を活用することで、適切なリスク管理を施し、安全で効果的な活用ができるように\nなることを期待します。 \n \n1.3 本書のスコープ \nまず、本書の対象読者は、総務省・経済産業省発行の「AI事業者におけるガイドライン第1版」 [6]\n（以降、AIガイドライン）における 「AI利用者」...",
    "content_length": 1105,
    "created_at": "2025-05-12T09:49:11.103469+00:00",
    "updated_at": "2025-05-12T09:49:11.103469+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=11"
  },
  "doc-a65021beda3221aa2914e9d92320e508": {
    "status": "pending",
    "content": "65 \n \n ベクトルDBに格納するデータ \nデータの正確性を精査してベクトルDBに格納する際に確認する必要があります。間違ったデータ\nを格納してしまった場合、誤った回答を返答するようになる恐れがあります。 \n \n注意事項 \n 生成AIに関する情報は常に変化するため、最新の情報や外部の知見、および社会情勢を考慮し、チェ\nックリストを更新することを推奨します。",
    "content_summary": "65 \n \n ベクトルDBに格納するデータ \nデータの正確性を精査してベクトルDBに格納する際に確認する必要があります。間違ったデータ\nを格納してしまった場合、誤った回答を返答するようになる恐れがあります。 \n \n注意事項 \n 生成AIに関する情報は常に変化するため、最新の情報や外部の知見、および社会情勢を考慮し、チェ\nックリストを更新することを推奨します。",
    "content_length": 181,
    "created_at": "2025-05-12T09:49:11.103611+00:00",
    "updated_at": "2025-05-12T09:49:11.103612+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=67"
  },
  "doc-1d7a4d666e4eaae86cb258e7a2955e31": {
    "status": "pending",
    "content": "93 \n \n \nベクトルDB 情報をデータオブジェクトの数値表現であるベクトルとして\n保存するデータベース。生成AIが扱う非構造化データの格\n納・管理・照会で利用される。 \nベンチマークテスト ハードウェアおよびソフトウェアの処理性能、AIの回答精\n度などを定量的に評価するための基準となるテストのこと。 \nポイズニング攻撃 LLMを汚染することで誤動作や性能劣化を引き起こすこと\nを目的とした攻撃手法。 \nマルウェア コンピュータやそのユーザに被害をもたらすことを目的とし\nた、悪意のあるソフトウェア。 \nAIモデル あらかじめ収集されたデータや入力データの中に存在するパ\nターンや相関関係を学習したもの。未知のデータやプロンプ\nトを与えた際に学習した結果から予測や判別、データの生成\nを行う。 \nラガード イノベーター理論におけるユーザ層の5つの区分のうち、最\nも遅く新製品・サービスを採用する層で、ユーザの約16%\nを占めている。世の中の動きに関心が薄く、流行が一般化し\nてからそれを採用する、最も保守的・伝統的な層。 \nランサムウェア 感染するパソコンなどに保存されているデータを暗号化して\n使用できなくした上で、そのデータを復号する対価（金銭や\n暗号資産など）を要求する不正プログラムのこと。 \nリージョン クラウドサービスにおいて、サービスを提供する拠点を地理\n的に近いものでグループ化したもの。ユーザは利用するリー\nジョンを選択して、仮想サーバやストレージを利用すること\nができる。 \nレイトマジョリティ イノベーター理論におけるユーザ層の5つの区分のうち、2\n番目に遅く新製品・サービスを採用する層で、ユーザの約\n34%を占めている。新製品や新技術の採用には懐疑的で、周\n囲の大多数が採用している場面を見てから採用する層。 \n安全保障貿易管理（輸出管理） 武器や軍事転用可能な貨物・技術が、国家および国際社会の\n安全性を脅かす国家やテロリスト等、懸念活動を行うおそれ\nのある者に渡ることを防ぐため、先進国を中心とした国際的\nな枠組みを作り、国際社会と協調して輸出等の管理を実施す\nること。 \n回避攻撃 敵対的サンプルを利用してAIの誤認識を発生させる攻撃手\n法。",
    "content_summary": "93 \n \n \nベクトルDB 情報をデータオブジェクトの数値表現であるベクトルとして\n保存するデータベース。生成AIが扱う非構造化データの格\n納・管理・照会で利用される。 \nベンチマークテスト ハードウェアおよびソフトウェアの処理性能、AIの回答精\n度などを定量的に評価するための基準となるテストのこと。 \nポイズニング攻撃 LLMを汚染することで誤動作や性能劣化を引き起こすこと\nを目的とした攻撃手法。 \nマルウェア コンピュータやそのユーザに被害をもたらすことを目的とし\nた、悪意のあるソフトウェ...",
    "content_length": 939,
    "created_at": "2025-05-12T09:49:11.103680+00:00",
    "updated_at": "2025-05-12T09:49:11.103681+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=95"
  },
  "doc-a54d5e8d8e15e90af5f201fd7470f42b": {
    "status": "pending",
    "content": "71 \n \n第6章 組織ヒアリング分析 \n本書の記載にあたり、我々は、既に生成AI活用を開始している組織に、ヒアリングを実施しました。\n本章では、ヒアリング結果から見えた「組織が感じる生成AIの課題」を紹介します。また「生成AI活\n用で現在最も脅威と考えるリスク」 、 「実際に実施しているリスク対策」についても触れます。なお、ヒア\nリングは2024年3月～5月に実施し、内容はその時点のものを記載しました。 \n \n6.1 ヒアリング結果から見る組織の生成AIとの在り方 \n6.1.1 導入目的とプロセス \n ヒアリング内容 \n「3.1.2 導入目的の決定」にも記載した通り、組織での生成AI導入では目的の明確化が重要なた\nめ、その組織の生成AIの導入目的（生成AI導入に至った理由）を確認しました。その上で、実際\nの導入プロセス（どんな導入プロセスをとったか）も確認しました。 \n \n ヒアリング結果 \n 導入目的 \nヒアリングを行った組織の生成AI導入の目的は、以下のようなものでした。 \n- 文章校正や要約 \n- 専門性の高いドキュメントの探索時間短縮 \n- システム開発効率の改善（プログラム添削）等 \n上記結果から、組織の生成AI導入の目的は 「業務効率化による生産性の向上」や 「サービスの品\n質向上」であり、一般的な雑務のみならず、コアとなる業務の効率化も見据えていることがわかり\nました。 \n \n 導入プロセス \n全体的な印象として、導入はスモールスタートで実施されている傾向が見られました。第3 章\nに記載の通り、まずは部門単位での先行利用や、ユーザを選定した導入を行います。そこでユーザ\nの利用率や利用料金、 ユーザの活用方法を確認した上で、 全社展開を開始している組織が多く見ら\nれました。",
    "content_summary": "71 \n \n第6章 組織ヒアリング分析 \n本書の記載にあたり、我々は、既に生成AI活用を開始している組織に、ヒアリングを実施しました。\n本章では、ヒアリング結果から見えた「組織が感じる生成AIの課題」を紹介します。また「生成AI活\n用で現在最も脅威と考えるリスク」 、 「実際に実施しているリスク対策」についても触れます。なお、ヒア\nリングは2024年3月～5月に実施し、内容はその時点のものを記載しました。 \n \n6.1 ヒアリング結果から見る組織の生成AIとの在り方 \n6.1.1 導入目的とプロ...",
    "content_length": 760,
    "created_at": "2025-05-12T09:49:11.103627+00:00",
    "updated_at": "2025-05-12T09:49:11.103628+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=73"
  },
  "doc-c8929ddd0bc30547fb431e2a7729d7a3": {
    "status": "pending",
    "content": "10 \n \n \n図 1-5:一般的なAI活用の流れにおける主体の対応 \nAI事業者におけるガイドライン第1版 P5 を元に作成 \n \nまた本書は、企業における「テキスト生成AI」の安全かつ効果的な活用を対象とします。テキスト生\n成特有のリスクとその対策に焦点を当て、具体的かつ実用的なセキュリティ対策を提供することを目指\nし、画像生成AIや動画生成AIなど、テキスト生成以外のAI技術を対象外とします。 \nテキスト生成AIの活用は多岐にわたり、製品説明資料やマーケティング資料に伴うアイデア出しや文\n法修正、コードの作成や作成したコードにおける説明や修正など、企業活動の多くの場面で大きな効果\nを発揮します。本書を参照することで、組織はこれらの活用シナリオにおいてテキスト生成AIをより安\n全かつ効率的に運用する方法を学ぶことができます。 \n \n1.4 本書の特徴 \n本書は、NIST （米国国立標準技術研究所）が発行するAI RMF [7]、AI RMF Generative AI Proﬁle [8]、\nISO（国際標準化機構）が取り決めるISO/IEC 42001 [9]、JDLAが発行する生成AIの利用ガイドライ\nン [10]など、AIに関連する既存の多くのガイドラインやフレームワークを参考に作成されています。\nNISTやISOが広範囲にわたる汎用的なAI技術を記載するのに対し、本書はテキスト生成AIの導入と\n運用を担当する者に特化した内容を記載することで、より具体的な内容に言及します。また、JDLAのガ\nイドラインが生成AIの利用者（ユーザ）を対象とするのに対して、本書は、企業や組織でテキスト生成\nAIを導入・運用する担当者を対象とします。 \n加えて、本書は生成AIにおけるセキュリティリスクにフォーカスし、従来の生成AIに関連するセキ\nュリティリスクだけでなく、 今後さらに利活用されるであろうRAG （Retrieval-Augmented Generation）\nを企業で導入することによって新たに発生するセキュリティリスクについても詳述します。",
    "content_summary": "10 \n \n \n図 1-5:一般的なAI活用の流れにおける主体の対応 \nAI事業者におけるガイドライン第1版 P5 を元に作成 \n \nまた本書は、企業における「テキスト生成AI」の安全かつ効果的な活用を対象とします。テキスト生\n成特有のリスクとその対策に焦点を当て、具体的かつ実用的なセキュリティ対策を提供することを目指\nし、画像生成AIや動画生成AIなど、テキスト生成以外のAI技術を対象外とします。 \nテキスト生成AIの活用は多岐にわたり、製品説明資料やマーケティング資料に伴うアイデア出しや文\n...",
    "content_length": 887,
    "created_at": "2025-05-12T09:49:11.103471+00:00",
    "updated_at": "2025-05-12T09:49:11.103472+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=12"
  },
  "doc-c892a9dfd60f24dcc7ad47ce432808d6": {
    "status": "pending",
    "content": "82 \n \nこれらの法規には、EUに住む個人の権利を保護する価値観が反映されており、AI規制に対してもこ\nの価値観が反映されています。欧州委員会は、2020年2月に欧州データ戦略を示しました。この戦略で\nは、安全なAIシステムを利活用する世界的リーダーになること、中小企業を含めてAI市場参入を加速\nさせるエコシステムの構築、活用しきれていないデータをEU域内で利活用できる枠組み作り、厳格な\n消費者保護ルールの遵守を前提としています。つまり、個人の権利を保護しながらも、欧州内のデータを\n欧州内で活発に利用する方針を打ち出したといえます [53]。 \nまたほかには「信頼性を備えたAIのための倫理ガイドライン」が発表されており、 「人による監督」\n「プライバシーとデータのガバナンス」 「透明性」 などのデータの取り扱いが示されました [54]。 そして、\n2021年からEUにおけるAI規制法が起草され、広がり続けるAI市場と生成AIに対する危機感の声を\n反映し、AI規制法は2024年5月に可決されました。 \nこの法規は、GDPR同様、EUに関連する経済活動を行う全ての企業を対象にしており、世界各国に影\n響を与えるものです。日本企業においても、EU圏内のユーザを抱える場合もあるため、意図せず規制に\n抵触することがないよう、この規制を一読しておくことを推奨します。 \n \nAI規制法では「人間を中心とするAI」 「信頼に足るAI」 「欧州連合の価値観に沿ったAIシステムを創\n造する」という観点を重視しています。この観点から次の要件が求められ、違反時の罰則や違反者が定義\nされています。 \n リスクベース・アプローチによるAI管理 \n 汎用的な生成AIに対する透明性の確保 \n 欧州の価値観に基づくAIの構築 \nAI規制法は、AIのリスクを分析し、深刻度を段階的に分けて整理を行いました。そのリスク深刻度に従\nい活用可能な条件を整理しています。AI規制法に定められた罰則とその範囲、そして罰則の要件を簡単\nに示します。 \n罰則：厳しい罰則 \n「3500万ユーロ」か「年間売上高の7％」のいずれか高いほうの制裁金が課されます。 \n \n対象範囲：違反者の範囲 \nEU域外で利用された高リスクAIの出力を欧州の事業者が活用する場合には、利用されたEU域外の\n高リスクAI事業者が罰則の対象として含まれます。そのため高リスクと判断されるAIの出力を欧州内\nで利用することについて明示的に契約書に記載する必要があります。 \n \n要件①：リスクベース・アプローチによるAI管理 \nAIのリスクを以下のように4段階に分け、それぞれに例を示します。 \n- 許容できないリスク ：原則禁止。出身・趣向などを基にしたスコアリング、人を操作するものなど \n- 高リスク：第三者認証が必要。教育や重要インフラの管理など人権や安全に影響があるもの \n- 限定的なリスク：透明性の確保が必要。対話型AIや生成AIなど \n- 最小リスク：上記を満たさないもの",
    "content_summary": "82 \n \nこれらの法規には、EUに住む個人の権利を保護する価値観が反映されており、AI規制に対してもこ\nの価値観が反映されています。欧州委員会は、2020年2月に欧州データ戦略を示しました。この戦略で\nは、安全なAIシステムを利活用する世界的リーダーになること、中小企業を含めてAI市場参入を加速\nさせるエコシステムの構築、活用しきれていないデータをEU域内で利活用できる枠組み作り、厳格な\n消費者保護ルールの遵守を前提としています。つまり、個人の権利を保護しながらも、欧州内のデータを\n欧州内で活...",
    "content_length": 1271,
    "created_at": "2025-05-12T09:49:11.103653+00:00",
    "updated_at": "2025-05-12T09:49:11.103653+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=84"
  },
  "doc-db4f59e5cfc5d9b5557aa51645741343": {
    "status": "pending",
    "content": "21 \n \n2.3.3 テキスト生成AIの組織導入におけるリスク \n本項では、一般にテキスト生成AIにどのようなリスクが存在するのかを説明します。ドイツの情報セ\nキュリティ庁（BSI, Bundesamt für Sicherheit in der Informationstechnik）発行のレポートではテキスト\n生成AIのLLMに関する3つのリスクカテゴリーが提示されています [13]。しかし、上述のレポートを\n含めたAIセキュリティに特化したドキュメントでは、AI特有の攻撃やリスクに重点が置かれているた\nめ、組織導入におけるリスク検討としては必ずしも十分とは言えません。そのため、本書ではBSIのレ\nポートに記載されているカテゴリーをベースに、テキスト生成AIを組織に導入する上で必要と考える内\n容を加えた4つのカテゴリーにリスクを分類しました。 \nまた4 つのリスクカテゴリーは、組織の内部要因で発生するリスクと外部要因で発生するリスクに分\n類することができます（図 2-6） 。 \n \n \n図 2-6: テキスト生成AIの組織導入におけるリスク \n \n各リスクカテゴリーの概要を以下に記載します。 \n 運用時のリスク \n機密情報をテキスト生成AIに入力することによって組織内の機密情報が外部に流出する\n可能性、更新される前の古い情報に基づいた回答を生成、もしくは事実に基づかない情報\nを生成する現象であるハルシネーション（詳細は4.1.2を参照）を引き起こすことも懸念さ\nれています。ほかにも、テキスト生成AIを悪用することでマルウェアの作成等も可能にな\nる場合があることもリスクの一つです。 \n \n 悪意のある生成AIを利用するリスク \nテキスト生成AIにはさまざまなWebサービスが存在しています。その中には故意に誤\n情報を出力するサービスや、プログラムコードの校正を実施しようとした際にマルウェア\nを組み込んで回答するサービスも存在する可能性があります。 \nこれらのテキスト生成AIサービスを利用することで、 意図しないマルウェアのインスト\nール・拡散につながってしまう可能性が存在します。",
    "content_summary": "21 \n \n2.3.3 テキスト生成AIの組織導入におけるリスク \n本項では、一般にテキスト生成AIにどのようなリスクが存在するのかを説明します。ドイツの情報セ\nキュリティ庁（BSI, Bundesamt für Sicherheit in der Informationstechnik）発行のレポートではテキスト\n生成AIのLLMに関する3つのリスクカテゴリーが提示されています [13]。しかし、上述のレポートを\n含めたAIセキュリティに特化したドキュメントでは、AI特有の攻撃やリスクに重点が...",
    "content_length": 908,
    "created_at": "2025-05-12T09:49:11.103501+00:00",
    "updated_at": "2025-05-12T09:49:11.103501+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=23"
  },
  "doc-51c70709986633d6a7b71bb0d28321f0": {
    "status": "pending",
    "content": "16 \n \n② RAG（Retrieval-Augmented Generation） \nRAGは、生成AIへ入力した質問に関連するデータを外部のデータベース（ベクトルDB）から検\n索し、元の質問に追加情報として付与した上でLLMに回答を生成させる技術です。回答にはベクト\nルDBから検索されたデータが利用されるため、LLMに学習されていない内容でも関連するデータ\nをベクトルDBに格納しておくことで回答精度を向上させることができます。 \nRAGを使用するにあたって、ベクトルDBの検索を正確に行うためにはファインチューニングと\n同様に格納するデータの質を確保することが重要です。また、ベクトルDBの検索を行う分、RAG\nを使用しない場合と比較して回答までに時間がかかる点にも注意が必要です。 \n \n \n図 2-4: RAGの概要 \n \n2.1.4 テキスト生成AIの入力から回答までの流れ \n図 2-5に示す簡易的なテキスト生成AIシステムの構成を例に、 入力から回答までに行われる処理につ\nいて紹介します。 \n \n \n図 2-5: テキスト生成AIシステムの構成例",
    "content_summary": "16 \n \n② RAG（Retrieval-Augmented Generation） \nRAGは、生成AIへ入力した質問に関連するデータを外部のデータベース（ベクトルDB）から検\n索し、元の質問に追加情報として付与した上でLLMに回答を生成させる技術です。回答にはベクト\nルDBから検索されたデータが利用されるため、LLMに学習されていない内容でも関連するデータ\nをベクトルDBに格納しておくことで回答精度を向上させることができます。 \nRAGを使用するにあたって、ベクトルDBの検索を正確に行うた...",
    "content_length": 484,
    "created_at": "2025-05-12T09:49:11.103487+00:00",
    "updated_at": "2025-05-12T09:49:11.103488+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=18"
  },
  "doc-79cdb40a376c7ec5c20ccd81e85ae998": {
    "status": "pending",
    "content": "29 \n \n3.2.2 目標の設定 \n生成AI導入に関する達成目標の設定を行います。適切な達成目標を設定してはじめて、その後の効果\n的な意思決定が可能となります。 \n目標設定にあたり、 「定性的目標」と「定量的目標」をそれぞれ検討することが重要です。生成AIの導\n入や活用が組織やプロジェクトに与える影響について、業務品質の改善や目標を定める 「定性的目標」と\n具体的な数値で測定できる 「定量的目標」の観点での検討がそれぞれ必要となります。特に定量的目標に\nついては、生成AIの効果測定において指標の1つとなることから、現実的な目標値を設定することを推\n奨します。 \n \n目標の例 \n定量的目標 \n 生産性の向上（例：特定のタスク（レポート作成/データ分析）の完了時間を30％短縮） \n ユーザ利用率（例：生成AI利用申請が従業員の40％） \n \n定性的目標 \n 生成AIを利用して、リスクの特定やコンプライアンスの維持を支援する。 \n 組織やチームが新しいアイデアやソリューションを生み出す能力を向上させる。 \n \n3.2.3 利害関係者の整理 \n2.4.3では生成AIの組織活用における担当者を定義しましたが、導入、運用、セキュリティ担当者以外\nにも多くの関係者との調整が必要です。本項ではその関係者の洗い出しに焦点を当てます。 \n生成AIの導入において、NISTのAI RMFでは、生成AIを含めたAIの導入におけるライフサイクル\nの関係者（AI Actor）が定義されており、それらを参考に関係者を洗い出し、各関係者の責任範囲を明確\n化することが重要です。以下に想定される関係者や立ち位置について記載します。 \n \n 導入ベンダ \n生成AIを組織に提供する導入ベンダは、生成AIの導入時に最も重要な立ち位置を占める外部関係者\nとなる為、データの取り扱いや責任範囲についての合意が必要です。 \n \n 法務担当者 \n生成AIを利用する上で、社内情報の取り扱いや著作物の利用範囲や権利について、導入担当者や運用\n担当者、セキュリティ評価者では判断できない分野の専門的な知識を確認するために、必要に応じて組\n織内外の有識者の協力を得ることが推奨されます。",
    "content_summary": "29 \n \n3.2.2 目標の設定 \n生成AI導入に関する達成目標の設定を行います。適切な達成目標を設定してはじめて、その後の効果\n的な意思決定が可能となります。 \n目標設定にあたり、 「定性的目標」と「定量的目標」をそれぞれ検討することが重要です。生成AIの導\n入や活用が組織やプロジェクトに与える影響について、業務品質の改善や目標を定める 「定性的目標」と\n具体的な数値で測定できる 「定量的目標」の観点での検討がそれぞれ必要となります。特に定量的目標に\nついては、生成AIの効果測定において指標...",
    "content_length": 934,
    "created_at": "2025-05-12T09:49:11.103520+00:00",
    "updated_at": "2025-05-12T09:49:11.103520+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=31"
  },
  "doc-86568e8a42b3a9aaac660a1f649943de": {
    "status": "pending",
    "content": "44 \n \n透明性を確保することは、生成AIの利用に対する信頼性を向上させ、バイアスを抑制した運用に繋が\nります。企業はこの重要な側面を認識し、継続的な改善とモニタリングを通じて透明性を維持する努力\nを続けることが重要です。 \n \n確認すべき生成AIの透明性 \nここでは、生成AIを運用する上で確認すべき透明性を3つ紹介します。 \n \n 学習データの透明性 \n学習データにおいて透明性を有する状態とは、LLMがどのようなデータを元に学習を行ったのかが\n可視化された状態にあることです。主にデータの出所や内容、収集日時、品質等の内容が可視化されて\nいることを確認します。 \n \n 参照データの透明性 \n参照データにおいて透明性を有する状態とは、生成AIが回答に使用したデータが可視化された状態\nにあることです。例としてはWebのデータを参照した場合はそのURLを明示することや、RAGを使\n用している場合はベクトルDBで参照したデータのパスを明示することです。生成AIが参照元の情報\nに誤りがあると生成した回答にも誤りが含まれるため、どのようなデータが参照されたのか確認し正\n誤を判断することが重要です。 \n \n 回答生成プロセスの透明性 \n回答生成プロセスにおいて透明性を有する状態とは、生成AIがどのような論理やプロセスで回答を\n生成したのかが可視化された状態にあることです。 生成のプロセスを確認することにより、 回答が信用\nに足るかどうかの判断に役立たせることができます。 \n \n＜透明性のない生成AIの例＞ \n \n図 4-7: 透明性のない生成AIの例",
    "content_summary": "44 \n \n透明性を確保することは、生成AIの利用に対する信頼性を向上させ、バイアスを抑制した運用に繋が\nります。企業はこの重要な側面を認識し、継続的な改善とモニタリングを通じて透明性を維持する努力\nを続けることが重要です。 \n \n確認すべき生成AIの透明性 \nここでは、生成AIを運用する上で確認すべき透明性を3つ紹介します。 \n \n 学習データの透明性 \n学習データにおいて透明性を有する状態とは、LLMがどのようなデータを元に学習を行ったのかが\n可視化された状態にあることです。主にデータの出...",
    "content_length": 683,
    "created_at": "2025-05-12T09:49:11.103562+00:00",
    "updated_at": "2025-05-12T09:49:11.103563+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=46"
  },
  "doc-7b42edc337616b9261e157152f97e24f": {
    "status": "pending",
    "content": "43 \n \n4.2.2 ユーザへの教育方法 \n 利活用ガイドラインの普及 \neラーニングプラットフォームなどを活用して、利活用ガイドラインの内容を普及します。定期\n的に実施することで、生成AIの利用規範や安全な利用方法に対する意識付けを行うことができ、\n倫理観およびセキュリティ意識の醸成に寄与することができます。 \n \n 効果的なプロンプトの共有 \n生成AIの効果的な使用方法を示すプロンプトを共有します。具体的な例を通じて、ユーザがど\nのようにプロンプトを作成すればよいかを学び、実際の業務に応用できるようにすることで、業\n務効率の向上に寄与できます。 共有するプロンプトは運用担当者自身が考えても良いですが、4.1.2\nで述べたような公式ドキュメントに記載されているサンプルを検証した内容も有効です。 \n \n 生成AI活用文化の醸成 \n生成AIを日常的に活用する文化を醸成します。例えば、日報作成に生成AIを利用するなど、\n日常業務の一部として生成AIを取り入れることで、ユーザが自然に生成AIを使いこなせるよう\nにします。実際に利用することで、生成AIに対する認識誤りを自覚することによって倫理観の醸\n成や、利用に慣れることによる業務効率の向上が期待できます。 \nまた、有志の人を集めて、活用方法を探り、共有するためのチームを設立することも有効な手段\nとなります。 ユーザが実際に生成AIを利用しながらプロンプトを共有し合える環境を提供するこ\nとで、生成AIの使用促進につなげることができます。 \n \nこれらの方法を通じて、ユーザのスキル向上を図ることで、生成AIの効果的な活用と企業全体の生産\n性向上が期待できます。運用部門は、継続的に教育プログラムを提供し、ユーザが常に最新の知識とスキ\nルを持ち続けられるようサポートすることが重要です。これにより、生成AIの運用がより効果的かつ倫\n理的に行われ、組織全体の競争力強化に寄与します。 \n \n4.3 生成AIの更新管理 \n4.3.1 透明性の確保と維持 \n生成AIにおける透明性とは、生成AIが回答に使用した学習データや回答に至ったプロセスを可視化\nすることを指します。透明性を確保することには多くのメリットがあります。例えば、ユーザやステーク\nホルダからすると、生成AIがどのようにして回答を導き出したのかを理解することで、回答の正誤に対\nする判断能力が高まります。また、生成AIがバイアスを含んでいるかどうかを検出しやすくなり、不公\n平な結果や差別的な判断を排除することができます。",
    "content_summary": "43 \n \n4.2.2 ユーザへの教育方法 \n 利活用ガイドラインの普及 \neラーニングプラットフォームなどを活用して、利活用ガイドラインの内容を普及します。定期\n的に実施することで、生成AIの利用規範や安全な利用方法に対する意識付けを行うことができ、\n倫理観およびセキュリティ意識の醸成に寄与することができます。 \n \n 効果的なプロンプトの共有 \n生成AIの効果的な使用方法を示すプロンプトを共有します。具体的な例を通じて、ユーザがど\nのようにプロンプトを作成すればよいかを学び、実際の業務に...",
    "content_length": 1076,
    "created_at": "2025-05-12T09:49:11.103560+00:00",
    "updated_at": "2025-05-12T09:49:11.103560+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=45"
  },
  "doc-16130f9d7c144df1a6d55775f79f8397": {
    "status": "pending",
    "content": "90 \n \n \nSSRF（Server Side Request Forgery） Webサーバ等の公開サーバを通じ、通常アクセスできない\n内部のサーバや公開サーバを連携している別サーバなどへ攻\n撃を仕掛ける手法。 \nSaaS（Software as a Service） クラウド事業者が提供するソフトウェアをユーザが利用する\nサービス形態。 \nTransformer 系列変換のためのニューラルネットワーク。系列とは順序を\n持った並びのことであり、例えば文は単語の系列とみなすこ\nとができる。多くの大規模言語モデルがその中核として採用\nしている機構であり、BERTやGPT等多方面で利用されて\nいる。 \nVertex AI GCP のクラウドプラットフォーム上で提供される、Google\n社のAIサービス。 \nWeb UI ユーザがWebブラウザからアプリケーションやサーバの設\n定や操作を行うためのインターフェース。 \nWebクロール プログラムがWeb上を巡って、Webページのリンクをたど\nりながらWebサイトを巡回し、Webページにある情報を保\n存・収集すること。 \nXSS（Cross Site Scripting） ユーザの入力データを処理するWebアプリケーションや\nWebページを操作するJavaScriptなどに存在する脆弱性を\n悪用し、ユーザのPC上で不正なスクリプトを実行させる手\n法のこと。 \n反射型、格納型、DOMベース型の3種類に分類される。 \nアーリーアダプター イノベーター理論におけるユーザ層の5つの区分のうち、2\n番目に早く新製品・サービスを採用する層で、ユーザの約\n13.5%を占めている。商品やサービスを初期段階で購入する\n人々で、初期採用者とも呼ばれ、市場で商品やサービスを普\n及させるときに重要になる層。 \nアーリーマジョリティ イノベーター理論におけるユーザ層の5つの区分のうち、3\n番目に早く新製品・サービスを採用する層で、ユーザの約\n34%を占めている。アーリーアダプターに比べると慎重では\nあるものの、新しい商品やサービスなどに対しての関心が高\nい層。 \nアジャイル システム開発手法の一種。計画からリリースまでを1サイク\nルとして、サイクルを繰り返し開発する手法。 \nアルゴリズム コンピュータにおける計算処理を行う手順のこと。",
    "content_summary": "90 \n \n \nSSRF（Server Side Request Forgery） Webサーバ等の公開サーバを通じ、通常アクセスできない\n内部のサーバや公開サーバを連携している別サーバなどへ攻\n撃を仕掛ける手法。 \nSaaS（Software as a Service） クラウド事業者が提供するソフトウェアをユーザが利用する\nサービス形態。 \nTransformer 系列変換のためのニューラルネットワーク。系列とは順序を\n持った並びのことであり、例えば文は単語の系列とみなすこ\nとができる。多く...",
    "content_length": 993,
    "created_at": "2025-05-12T09:49:11.103673+00:00",
    "updated_at": "2025-05-12T09:49:11.103674+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=92"
  },
  "doc-14f28db8ee51f319f550f5ce321a2d5e": {
    "status": "pending",
    "content": "15 \n \n2.1.3 テキスト生成AIの回答精度向上のための技術 \nテキスト生成AIの課題の1つとして、LLMが学習していないデータに関する回答は精度が著しく低\n下することが挙げられます。例えばインターネットに掲載されていない社内ドキュメントのようなデー\nタや専門性の高いデータ、LLMが作成された時点では公開されていない最新のデータなどに関する質問\nに正確に回答することは困難です。この課題を克服するために技術開発が進められており、本項ではそ\nの技術の中でもファインチューニングとRAG （Retrieval-Augmented Generation、検索拡張生成）の2つ\nについて紹介します。 \n \n① ファインチューニング \nファインチューニングは、学習済みのモデルに対して新たなデータを膨大なリソースと時間を使\n用して追加で学習させる技術で、LLMに限らずディープラーニングで作成されたモデルには広く用\nいられています。この技術により汎用的なモデルを特定の分野に特化させることができ、ファイン\nチューニングしたLLMを使用することで新たに学習させたデータに関する回答精度を向上させる\nことができます。 \nファインチューニングを行うにあたり、学習させるデータの量と質が性能に大きく影響するため、\nノイズや重複の削除などを行ったデータを大量に用意することが重要になります。また、学習内容\nを特化させた分、汎用性が低下する可能性がある点にも注意が必要です。 \n \n \n図 2-3: ファインチューニングの概要",
    "content_summary": "15 \n \n2.1.3 テキスト生成AIの回答精度向上のための技術 \nテキスト生成AIの課題の1つとして、LLMが学習していないデータに関する回答は精度が著しく低\n下することが挙げられます。例えばインターネットに掲載されていない社内ドキュメントのようなデー\nタや専門性の高いデータ、LLMが作成された時点では公開されていない最新のデータなどに関する質問\nに正確に回答することは困難です。この課題を克服するために技術開発が進められており、本項ではそ\nの技術の中でもファインチューニングとRAG （Ret...",
    "content_length": 656,
    "created_at": "2025-05-12T09:49:11.103485+00:00",
    "updated_at": "2025-05-12T09:49:11.103486+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=17"
  },
  "doc-f5704e9dde1f632d6eaeda9bebf8fcce": {
    "status": "pending",
    "content": "98 \n \n[43] WIRED, “ディープフェイク・ポルノに勝てるのは、テイラー・スウィフトしかいない”, 2024-\n01-31, https://wired.jp/article/taylor-swift-deepfake-porn-artiﬁcial-intelligence-pushback/. [アク\nセス日: 2024-06]. \n[44] 総務省, “海外の動向及び国際的な議論の動向”, 2019-02, \nhttps://www.soumu.go.jp/main_content/000604970.pdf. [アクセス日: 2024-06]. \n[45] Pew Research Center, “Looking ahead to 2050, Americans are pessimistic about many aspects of \nlife in U.S.”, https://www.pewresearch.org/short-reads/2019/03/21/looking-ahead-to-2050-\namericans-are-pessimistic-about-many-aspects-of-life-in-u-s/. [アクセス日: 2024-06]. \n[46] Pew Research Center, “An update on our research into trust, facts and democracy”, 2019-06-05, \nhttps://www.pewresearch.org/2019/06/05/an-update-on-our-research-into-trust-facts-and-\ndemocracy/. [アクセス日: 2024-06]. \n[47] 内閣府, “米国の AI権利章典（AI Bill of Rights）について”, 2022-12, \nhttps://www8.cao.go.jp/cstp/ai/ningen/r4_2kai/siryo3.pdf. [アクセス日: 2024-06]. \n[48] NIST, “AI RISK MANAGEMENT FRAMEWORK”, https://www.nist.gov/itl/ai-risk-\nmanagement-framework. [アクセス日: 2024-06]. \n[49] 日本貿易振興機構, “バイデン米政権、AIの安全性に関する新基準などの大統領令公表”, 2023-\n11-01, https://www.jetro.go.jp/biznews/2023/11/495833ae70119dbf.html. [アクセス日: 2024-\n06]. \n[50] Homeland Security, “Promoting AI Safety and Security”, 2024-05-13, \nhttps://www.dhs.gov/ai/promoting-ai-safety-and-security. [アクセス日: 2024-06]. \n[51] NIST, “NIST Launches ARIA, a New Program to Advance Sociotechnical T esting and Evaluation \nfor AI”, 2024-05-28, https://www.nist.gov/news-events/news/2024/05/nist-launches-aria-new-\nprogram-advance-sociotechnical-testing-and. [アクセス日: 2024-06]. \n[52] 日本貿易振興機構, “EU 一般データ保護規則（GDPR）について”, \nhttps://www.jetro.go.jp/world/europe/eu/gdpr/. [アクセス日: 2024-06]. \n[53] 駐日欧州連合代表部, “欧州委員会、データと人工知能に関する戦略を発表”, 2020-02-19, \nhttps://www.eeas.europa.eu/delegations/japan/%E6%AC%A7%E5%B7%9E%E5%A7%94%E5%\n93%A1%E4%BC%9A%E3%80%81%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A8%E4\n%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%E3%81%AB%E9%96%A2%E3%81%99\n%E3%82%8B%E6%88%A6%E7%95%A5%E3%82%92%E7%99%BA%E8%A1%A8_ja. [アクセ\nス日: 2024-06]. \n[54] 日本貿易振興機構, “欧州委、AI倫理ガイドラインを発表”, 2019-04-15, \nhttps://www.jetro.go.jp/biznews/2019/04/17aa7120c9481135.html. [アクセス日: 2024-06]. \n[55] Ledge.ai, “AGIと超知能がもたらす未来を予見”, 2024-06-08, \nhttps://ledge.ai/articles/former_openai_member_warns_situational_awareness. [アクセス日:",
    "content_summary": "98 \n \n[43] WIRED, “ディープフェイク・ポルノに勝てるのは、テイラー・スウィフトしかいない”, 2024-\n01-31, https://wired.jp/article/taylor-swift-deepfake-porn-artiﬁcial-intelligence-pushback/. [アク\nセス日: 2024-06]. \n[44] 総務省, “海外の動向及び国際的な議論の動向”, 2019-02, \nhttps://www.soumu.go.jp/main_conten...",
    "content_length": 2277,
    "created_at": "2025-05-12T09:49:11.103693+00:00",
    "updated_at": "2025-05-12T09:49:11.103697+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=100"
  },
  "doc-53208226c0efe85c792e91280d51652f": {
    "status": "pending",
    "content": "13 \n \n第2章 本書を最大限に活用するために \n本章では、セキュアな生成AIを導入・運用するために読者が持っておくべき基礎的な知識を記載しま\nす。また、第3章～第5章の概要および各章の対象読者についても記載します。 \n \n2.1 生成AIとは \n2.1.1 生成AIの定義 \n「AI （Artiﬁcial Intelligence、人工知能） 」は、一般的に、コンピュータによる知的な振る舞いを実現す\nる技術全般を指します。AIを実現する技術の1つであり、現在のAIの中核技術となっているのが「機械\n学習」です。機械学習は、データの背景にある法則をコンピュータで自動的に見つける技術と言えます。\n学習用データを用いて計算モデルが規則性を見つけるプロセスが「学習」 （もしくは訓練）です。学習済\nみの計算モデル（学習済みモデル）を使うことで、未知のデータに対して予測や判断ができます。 \n機械学習の中でも 「ディープラーニング」は、従来の機械学習では困難であった複雑なデータパターン\nの分析に優れています。ディープラーニングは、入力データと出力データの間に多層にわたる中間層と\n呼ばれる構造を設け、各中間層で異なる特徴量を抽出し、データを学習・判断するアルゴリズムです。多\n層化した中間層を持つ、この構造がディープラーニングと呼ばれる所以です。このディープラーニング\nの技術を活用した学習モデルを利用することで、AIは複雑な予測・判断などを行うことができます。 \n「生成AI」は、従来型のAIが単なる入力データの予測・判断をするのに対し、入力データから新しい\n創造物（コンテンツなど）を生成する技術の総称を意味します。一般的に、生成AIにはディープラーニ\nングが利用されており、特に、自然言語処理や画像処理といった技術を組み合わせて利用されます。 \n \n \n図 2-1: AIにおける生成AIの位置付け",
    "content_summary": "13 \n \n第2章 本書を最大限に活用するために \n本章では、セキュアな生成AIを導入・運用するために読者が持っておくべき基礎的な知識を記載しま\nす。また、第3章～第5章の概要および各章の対象読者についても記載します。 \n \n2.1 生成AIとは \n2.1.1 生成AIの定義 \n「AI （Artiﬁcial Intelligence、人工知能） 」は、一般的に、コンピュータによる知的な振る舞いを実現す\nる技術全般を指します。AIを実現する技術の1つであり、現在のAIの中核技術となっているのが「機...",
    "content_length": 802,
    "created_at": "2025-05-12T09:49:11.103479+00:00",
    "updated_at": "2025-05-12T09:49:11.103480+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=15"
  },
  "doc-98135c535ca138ec6eeaf8216291dbbf": {
    "status": "pending",
    "content": "45 \n \n＜透明性のある生成AIの例＞ \n \n図 4-8: 透明性のある生成AIの例 \n \n透明性確保の手段 \n透明性を確保・維持することは生成AIを活用する上で極めて重要です。多くの生成AIシステムは複\n雑なアルゴリズムと大量のデータを用いており、そのプロセスを完全に可視化するのは容易ではありま\nせん。本項では透明性を確保するために実施可能な手段の例を3点紹介します。 \n \n 学習データの開示依頼 \n学習データを可能な範囲で開示するようAI提供者へ依頼し、 データの出どころや内容に関する\n情報が提供されることで、生成AIの基盤となるデータが適切であることを確認できるため、学習\nデータの透明性確保に有効です。クラウドサービスの生成AIを利用している場合は、通知なしで\n学習データがアップデートされる場合があるため、定期的な確認が必要です。なお、 学習データは\nLLMの性能に直結する重要な情報であることから、開示されない可能性が十分に考えられますが、\n責任分界点の明確化のために学習データを確認する行動そのものが重要になります。 \n \n マスタープロンプトの設定 \nマスタープロンプトとは、ユーザが入力したプロンプトに加えて自動で付与されるプロンプト\nです。マスタープロンプトを設定することで、参照されたデータのURL ・パスの表示や、回答生\n成プロセスの説明を自動で行えば、透明性の確保におけるユーザの負担を軽減することができま\nす。 \n \n 定期的な内部監査や外部評価 \n専門知識を持つ人材が、生成AIの回答を定期的に評価することで、生成AIの回答が信頼に値\nするものか、また、コンプライアンスを遵守しているかを確認します。",
    "content_summary": "45 \n \n＜透明性のある生成AIの例＞ \n \n図 4-8: 透明性のある生成AIの例 \n \n透明性確保の手段 \n透明性を確保・維持することは生成AIを活用する上で極めて重要です。多くの生成AIシステムは複\n雑なアルゴリズムと大量のデータを用いており、そのプロセスを完全に可視化するのは容易ではありま\nせん。本項では透明性を確保するために実施可能な手段の例を3点紹介します。 \n \n 学習データの開示依頼 \n学習データを可能な範囲で開示するようAI提供者へ依頼し、 データの出どころや内容に関する\n...",
    "content_length": 722,
    "created_at": "2025-05-12T09:49:11.103564+00:00",
    "updated_at": "2025-05-12T09:49:11.103565+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=47"
  },
  "doc-f66bed7a8bc0c7a2bf9d2f2603d04ba7": {
    "status": "pending",
    "content": "28 \n \n3.1.3 目的に応じたスコープの決定 \n導入目的に応じて、スコープ（対象ユーザ・実装機能）を決定することが重要です。ユーザの利用頻度\nや実装する機能によって、生成AIの構築・維持にかかるコストに大きな差が生まれます。そのため、ス\nコープを適切に設定することは、生成AI導入リスクの低減に繋がります。また、初期段階では、スコー\nプを絞り、スモールスタートとして導入することで、対象部署やユーザ数、ユーザ1 人当たりの利用頻\n度を検証し、導入コストを精査する機会にもなります。導入目的に応じたスコープを決定しましょう。 \n \n3.2 要件定義 \n3.2.1 実現可能性の検討 \n実現可能性の検討では、生成AIを導入することで目的が達成できるかを検証します。この際、いくつ\nかの観点から検証を行う必要があります。 \n \n 技術的な観点 \n 生成AIの設計および開発が技術的に実現可能であること。 \n システムが将来的な拡張や変更にも対応できる設計であること。 \n \n 経済的な観点 \n 生成AIの導入・運用にかかるコストが組織の予算内で収まること。 \n 費用対効果の分析を行い、投資に対するリターンが見込めること。 \n \n 組織的な観点 \n 生成AIの導入・運用に必要な人的リソースを確保できること。 \n 関係する部門間の協力体制が整っていること。 \n 生成AIが関連する社内ポリシーに準拠可能であること。 \n \n 法的な観点 \n 生成AIが関連する法規制に準拠しており、法的リスクが適切に管理されていること。 \n プライバシー保護やデータセキュリティに関する規制要件を満たしていること。 \n \n 倫理的な観点 \n 生成AIの回答が倫理的に許容可能であり、社会的に受け入れられるものであること。 \n バイアスや不公平な回答を最小限に抑えるための対策が組み込まれていること。",
    "content_summary": "28 \n \n3.1.3 目的に応じたスコープの決定 \n導入目的に応じて、スコープ（対象ユーザ・実装機能）を決定することが重要です。ユーザの利用頻度\nや実装する機能によって、生成AIの構築・維持にかかるコストに大きな差が生まれます。そのため、ス\nコープを適切に設定することは、生成AI導入リスクの低減に繋がります。また、初期段階では、スコー\nプを絞り、スモールスタートとして導入することで、対象部署やユーザ数、ユーザ1 人当たりの利用頻\n度を検証し、導入コストを精査する機会にもなります。導入目的に応じ...",
    "content_length": 806,
    "created_at": "2025-05-12T09:49:11.103517+00:00",
    "updated_at": "2025-05-12T09:49:11.103518+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=30"
  },
  "doc-1a2d35da32999cb77843ece930f0b5e8": {
    "status": "pending",
    "content": "50 \n \n第5章 生成 AI のリスク管理について \n本章では、組織において生成AIのセキュリティ担当者が考慮すべき事項を説明します。生成AIは、\n従来のシステムにおけるリスクに加えて、従来のシステムにはない特有のリスクを持ちます。組織は両\nリスクを特定・分析・評価し、対策を講じる必要があります。 \n \nここではまず、生成AIに関するセキュリティインシデント事例を紹介します。事例から、生成AIシ\nステムに適切なリスク対策を講じないと、 どのようなインシデントを招くのかを理解します。 その上で、\n具体的にリスク特定・分析・評価・対応の流れを説明します。特に、リスク特定では生成AIに特有のリ\nスクを、リスク対策では特有リスクの一部を取り上げ、それぞれどのような観点で対策を講じるべきな\nのか、という2点について記載していきます。 \n \n※リスク管理はセキュリティ担当者のみで実施するわけではありません。導入担当者・運用担当者も\n自身が担当する箇所におけるリスクを把握し、各担当者に連携することが重要です。 \n \n5.1 生成AIに関するセキュリティインシデント事例 \n生成AIに関連したセキュリティインシデントをご紹介します。前述の通り、生成AIが持つ特有のリ\nスクに対して十分な対策が取られない場合、過失または悪意により企業に大きな被害や損失をもたらす\n可能性があります。 \n \n サムスン電子社のChatGPTへの情報流出 [25] \n 背景 \nサムスン電子は、ChatGPTなどの生成AIに伴う機密情報の流出リスクを懸念し、従業員に\nよる使用を禁止しました。この決定の背景には、あるエンジニアが社内機密のソースコードを\nChatGPTに誤ってアップロードし、それが発覚したという事件があります。生成AIは、ユー\nザのデータをサーバに保存し、それを他のユーザに提供する可能性があるため、機密情報の漏\n洩リスクが高いと判断されたのです。また、ChatGPTはデフォルトでチャット履歴を保存し、\nモデルの訓練に使用するという設定になっていたことも要因の1つであったと考えられます。",
    "content_summary": "50 \n \n第5章 生成 AI のリスク管理について \n本章では、組織において生成AIのセキュリティ担当者が考慮すべき事項を説明します。生成AIは、\n従来のシステムにおけるリスクに加えて、従来のシステムにはない特有のリスクを持ちます。組織は両\nリスクを特定・分析・評価し、対策を講じる必要があります。 \n \nここではまず、生成AIに関するセキュリティインシデント事例を紹介します。事例から、生成AIシ\nステムに適切なリスク対策を講じないと、 どのようなインシデントを招くのかを理解します。 その上で、...",
    "content_length": 895,
    "created_at": "2025-05-12T09:49:11.103576+00:00",
    "updated_at": "2025-05-12T09:49:11.103577+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=52"
  },
  "doc-58f01f8aee77dda606d0ec3b8dd613bd": {
    "status": "pending",
    "content": "36 \n \n3.4.2 生成AIの性能評価 \n生成AIの性能評価は、そのシステムが期待通りのパフォーマンスを発揮するかどうかを確認するため\nに極めて重要です。しかし、一般的なシステムの性能評価と比べて、生成AIの性能評価は特に難しい場\n合が多いとされています。これは、生成AIの回答プロセスがブラックボックス化しており、評価基準を\n定義する必要があるためです。このような状況を踏まえて、性能評価フェーズでは生成AIの性能を総合\n的に評価することが求められます。 \n性能評価の主要な指標には、回答の正確性、応答時間、スケーラビリティなどが含まれます。より具\n体的な指標としては、ベンチマークテストの正答率や、生成されたコンテンツの品質、システムの応答\n時間、入出力トークン数、出力速度などが考えられます。性能評価を実施する際の主な注意点は以下の\n通りです。これらの指標や注意点を考慮し、生成AIの性能を総合的に評価することが必要です。 \n \n注意点 \n 回答の正確性や偏り（バイアス）などを検証する。 \n生成AIの性能を評価する上で重要な要素である、回答の正確性やバイアスについてテスト段階\nで検証を実施しておくことが重要です。 \n ベンチマークの結果を過信しないようにする。 \n一般的にベンチマークを利用した評価が行われることが多いとされていますが、その種類はさま\nざまであり、同じ生成AIを評価対象にしても、利用するベンチマークによって結果が大きく異な\nる場合があります。利用するベンチマークの種類やデータセットなど、前提条件をきちんと把握し\nた上で評価に活用することが重要です。 \n \n3.4.3 利活用ガイドラインの策定 \n生成AIを実装する前には、生成AIユーザのための利活用ガイドラインを策定することも重要です。\nユーザに生成AIを安全かつ効率的に利用してもらうため、利用する上での禁止事項や入出力内容の取扱\nいに関する注意点、目的の出力を生成するために考慮すべき点などを利活用ガイドラインに盛り込む必\n要があります（ガイドラインの具体的な内容については4.1を参照してください） 。 \nまた、ここで作成するガイドラインは導入担当者だけではなく、運用担当者と連携し、協力して作成す\nることが重要です。両担当者の視点から、自社の状況に合った運用可能なガイドラインを策定すること\nが求められます。",
    "content_summary": "36 \n \n3.4.2 生成AIの性能評価 \n生成AIの性能評価は、そのシステムが期待通りのパフォーマンスを発揮するかどうかを確認するため\nに極めて重要です。しかし、一般的なシステムの性能評価と比べて、生成AIの性能評価は特に難しい場\n合が多いとされています。これは、生成AIの回答プロセスがブラックボックス化しており、評価基準を\n定義する必要があるためです。このような状況を踏まえて、性能評価フェーズでは生成AIの性能を総合\n的に評価することが求められます。 \n性能評価の主要な指標には、回答の正確...",
    "content_length": 1003,
    "created_at": "2025-05-12T09:49:11.103536+00:00",
    "updated_at": "2025-05-12T09:49:11.103537+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=38"
  },
  "doc-0015c10066f953b828073d996a6b2f8c": {
    "status": "pending",
    "content": "79 \n \n \nAIモデルを開発するサーバスペックがAIモデル性能を直接示すわけではありませんが、AIモデルを\n開発するサーバスペックが向上することは、時間当たりの学習効率を高めるため、高性能なAIモデルの\n開発が可能になると言えます。同書 [32]にはAIモデルの学習コストに関しても、OpenAI社が提供する\nGPT-4には約7800万ドル、Google社が提供するGemini Ultraには約1.9億ドルの学習コストが掛かっ\nていると言及しています。 \n現在、世界の先駆的な役割を持つ汎用的な生成AIモデルは、クラウドベンダとしてトップシェアを誇\nる米国企業が多大な投資により支えています [33]。大規模なサーバを多数の顧客が利活用するクラウド\nサービスと高性能なサーバを必要とする生成AIの特性とは親和性が高く、投資に対して十分な効果を得\nられると見込んでいることが伺い知れます。 \nとはいえAI開発の命運を左右する要素は、 設備に対する投資だけではありません。AIモデルの大きさ\nは、かねてから問題点として挙げられ、開発・運用コストを抑制するために新たな手法の研究が盛んに行\nわれています。2024年2月にMicrosoft社からBitNet b1.58 （量子化に関する論文）が発表されるなど、\n1パラメータあたりのデータ量を圧縮した効率的なAIの開発、つまり大きいAIからスリムなAIに時代\nが変わりつつあります。 \n \n7.1.2 欧州の生成AI \n2022年11月30日にChatGPTが公開され、たった2ヶ月でユーザ数1億人を突破しました [35]。\n2017年頃から欧州内でもAIへの関心は高まり [36] [37]、2023年には新たなAIモデルを作成する欧州\nのスタートアップ企業に対してより多くの投資がされるようになりました [32]。これらのスタートアッ\nプ企業誕生の背景には、欧州における生成AIの規制 （後述）を考慮した 「欧州が開発する欧州向けの生\n成AI」のニーズが高まっていたと推測されます。 \n \nここでは、特に強い関心を集めているスタートアップ企業として、ドイツの「Aleph Alpha」とフラン\nスの「Mistral AI」を取り上げます。 \nAleph Alpha社の創業者ジョナス・アンドルリス氏は、元々Apple社でAIの研究を行っていました。\n彼を中心に多くの国際的な研究者や技術者が集まり、 「Attention Is All You Need」発表の2年後である\n2019年にAleph Alpha社は設立されました [38]。欧州の中では、早期に商業向け生成AIの開発に取り\n組み始めた企業の1つです。Aleph Alpha社は独自の大規模言語モデル「Luminous」を持ち、同モデル\nは欧州の公的機関の一部で利用が始められています [39]。その基本的な技術は「OpenAI社のChatGPT\nに比肩する」と評されました。直近では2023年11月に5億ドルの資金調達を成し、より高性能な生成\nAIモデル開発への期待が高まっています [38]。",
    "content_summary": "79 \n \n \nAIモデルを開発するサーバスペックがAIモデル性能を直接示すわけではありませんが、AIモデルを\n開発するサーバスペックが向上することは、時間当たりの学習効率を高めるため、高性能なAIモデルの\n開発が可能になると言えます。同書 [32]にはAIモデルの学習コストに関しても、OpenAI社が提供する\nGPT-4には約7800万ドル、Google社が提供するGemini Ultraには約1.9億ドルの学習コストが掛かっ\nていると言及しています。 \n現在、世界の先駆的な役割を持つ汎用的な...",
    "content_length": 1306,
    "created_at": "2025-05-12T09:49:11.103646+00:00",
    "updated_at": "2025-05-12T09:49:11.103646+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=81"
  },
  "doc-6245b04807f1c9b5135938c7cccf6a64": {
    "status": "pending",
    "content": "64 \n \n ログの保存 \n出力された回答を保存する。入口対策に記載した入力に関するログを一緒に保存することで、生成\n物に対する問題が発生した際には、確認を行うことができる。 \n \nここで挙げた多層防御の対策は、 あくまで一例であり、 これらの対策を全て実施すれば全ての脅威を防\nげるということを保証するものではありません。その他の対策も併せて検討し、総合的なセキュリティ\n対策を講じることが重要です。 \n \n5.4.2 チェックリストの作成 \n生成AIシステムのセキュリティに関する考慮事項をチェックリストとして一覧化しておくことで、抜\nけ漏れない対策に繋がります。また、一覧化することで、作成者も使用者も自組織の生成AIシステムへ\nの理解が深まるという学習面での副次効果も期待できます。 \nチェックリストには、ガバナンスの観点とシステムの観点という、大きく分けて2 つの観点を盛り込\nむ必要があります。生成AIはユーザの入力によってリスクが発生する可能性が高いため、システム的な\n観点だけでなく、ユーザの管理や社会情勢への考慮、いわゆるガバナンスの観点も必要です。 \n \nガバナンス面 \nガバナンスに関する項目は、主に生成AIを利用するユーザ向けを想定する事項です。チェックリスト\nの項目については、4.1.2、4.3.1を参照ください。また、組織内の既存のチェック項目と照らし合わせ、\n流用可能な項目や既にカバーされている内容についても別途確認することを推奨します。 \n \nシステム面 \nシステムに関する項目は、主に生成AIを社内に導入する担当者向けを想定する事項です。以下は、\nLLMを組み込んだシステム上で考慮する必要がある項目の一例です。これ以外にも組織内の既存のチェ\nックリストなどと併用して確認することを推奨します。 \n 入出力プロンプトを含めたログ管理 \n入力プロンプトと出力プロンプトのログを保存しておくことにより、迅速な事後対応ができます。 \n \n 入力の制限 \n敵対的プロンプトの入力を受け付けないようにする必要があります。敵対的プロンプトの入力が成\n功すると情報漏洩やシステム停止につながる恐れがあります。 \n \n オプトアウト可能なサービスの選定 \n入力したデータが学習されないようにオプトアウト可能なサービスを選定する必要があります。オ\nプトアウトが明記されていないサービスを利用した場合、ユーザが入力した内容が学習に使用され、\n情報漏洩に繋がる恐れがあります。",
    "content_summary": "64 \n \n ログの保存 \n出力された回答を保存する。入口対策に記載した入力に関するログを一緒に保存することで、生成\n物に対する問題が発生した際には、確認を行うことができる。 \n \nここで挙げた多層防御の対策は、 あくまで一例であり、 これらの対策を全て実施すれば全ての脅威を防\nげるということを保証するものではありません。その他の対策も併せて検討し、総合的なセキュリティ\n対策を講じることが重要です。 \n \n5.4.2 チェックリストの作成 \n生成AIシステムのセキュリティに関する考慮事項をチェ...",
    "content_length": 1050,
    "created_at": "2025-05-12T09:49:11.103609+00:00",
    "updated_at": "2025-05-12T09:49:11.103610+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=66"
  },
  "doc-d67ed97d6d824aca099b1101015eb2ce": {
    "status": "pending",
    "content": "63 \n \n 防御用プロンプトテンプレートの実装 \nLLM統合システムの内部で定義するプロンプトテンプレートに防御用のプロンプトを設定する （図 \n5-11）ことで、不正な操作や出力を減らすことができる。 \n \n \n図 5-11: 防御用プロンプトテンプレート例 \n \n出口対策 \n出口対策では、バックエンドにある統合ミドルウェアからフロントエンドにあるWeb UIにレスポン\nスを送る場所での対策とユーザへ情報が渡る場所での対策を考えます。図 5-5のシステム構成図におけ\nる入口対策の場所を、図 5-12に緑色の盾マークで示します。 \n \n \n図 5-12: 出口対策場所のイメージ \n \n具体的な出口対策の例を以下示します。 \n ユーザへの教育 \nLLMを使った生成物は著作権の侵害やハルシネーション、バイアスがかかっている可能性がある\nことを周知するなどの教育を行う。これにより、間違った情報を使用することによる事故を防ぐこ\nとができる。 \n ガードレールの設置 \nガードレールを設置することで、出力された内容が事前に設定したポリシーに違反しているか\nLLMを使用して検証する。これにより、不利益をもたらす内容や不適切な表現、バイアスの発生\nなどを軽減することができる。",
    "content_summary": "63 \n \n 防御用プロンプトテンプレートの実装 \nLLM統合システムの内部で定義するプロンプトテンプレートに防御用のプロンプトを設定する （図 \n5-11）ことで、不正な操作や出力を減らすことができる。 \n \n \n図 5-11: 防御用プロンプトテンプレート例 \n \n出口対策 \n出口対策では、バックエンドにある統合ミドルウェアからフロントエンドにあるWeb UIにレスポン\nスを送る場所での対策とユーザへ情報が渡る場所での対策を考えます。図 5-5のシステム構成図におけ\nる入口対策の場所を、図...",
    "content_length": 542,
    "created_at": "2025-05-12T09:49:11.103607+00:00",
    "updated_at": "2025-05-12T09:49:11.103608+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=65"
  },
  "doc-70d36fe96f92f9e5c23f7fa3340409f8": {
    "status": "pending",
    "content": "70 \n \n今回は、 ガードレールを使うことにより、 話題の制限や敵対的プロンプトを検知できることを紹介しま\nしたが、自組織でPaaS型製品の利用を検討している場合は、付属しているセキュリティ対策ソリューシ\nョンも併用することを推奨します。 \n \n5.5.2 RAGにおけるアクセス管理の実装 \n3.3.2ではRAGに関する課題について言及しました。ここでは、その課題への解決策の一例を紹介し\nます。 \nベクトルDBに格納されている情報の重要度毎に参照できるユーザを設定する（図 5-18）ことで、組\n織毎にベクトルDBを複数用意する必要がなくなり、コストを軽減することができます。 \n \n \n図 5-18: ユーザごとにアクセス権限を設定したイメージ \n \n実際、図 5-19のように、管理職社員と一般社員で、同一の質問に対して異なる回答を取得することが\nできます。 \n \n \n図 5-19: 権限によって異なる回答をするイメージ",
    "content_summary": "70 \n \n今回は、 ガードレールを使うことにより、 話題の制限や敵対的プロンプトを検知できることを紹介しま\nしたが、自組織でPaaS型製品の利用を検討している場合は、付属しているセキュリティ対策ソリューシ\nョンも併用することを推奨します。 \n \n5.5.2 RAGにおけるアクセス管理の実装 \n3.3.2ではRAGに関する課題について言及しました。ここでは、その課題への解決策の一例を紹介し\nます。 \nベクトルDBに格納されている情報の重要度毎に参照できるユーザを設定する（図 5-18）ことで、組...",
    "content_length": 416,
    "created_at": "2025-05-12T09:49:11.103625+00:00",
    "updated_at": "2025-05-12T09:49:11.103626+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=72"
  },
  "doc-157b1dec6e9555291dcc63f2db995d46": {
    "status": "pending",
    "content": "31 \n \nOWASPのLLM AI Cybersecurity & Governance Checklist v1.1では、モデルの利用方法の観点から、\n導入方法が6つのタイプで分類されています （図 3-2） [11] [14]。 本書では、OWASPの分類をもとに、\n以下6 つの利用方法を定義します。それぞれの利用方法の特徴を理解し、自組織の環境や目的に合った\n導入方法を選択することが重要です。 \n \n \n図 3-2: モデルの利用方法 \n \n生成AIシステムの構築環境の選択 \n3.2.5ではモデルの利用方法について説明しました。本項では選択したモデルの導入環境について説明\nします。組織にエンタープライズ向けの生成AIを導入する場合、導入環境は「オンプレミス型 （以下オ\nンプレと表記）」「クラウド型」「ハイブリッド型 （API利用） 」の3つに分類できます（図 3-3） 。各導入\n環境の特徴を理解し、導入目的に合った導入環境を選択することが重要です。 \n \n \n図 3-3: 生成AIの構築環境",
    "content_summary": "31 \n \nOWASPのLLM AI Cybersecurity & Governance Checklist v1.1では、モデルの利用方法の観点から、\n導入方法が6つのタイプで分類されています （図 3-2） [11] [14]。 本書では、OWASPの分類をもとに、\n以下6 つの利用方法を定義します。それぞれの利用方法の特徴を理解し、自組織の環境や目的に合った\n導入方法を選択することが重要です。 \n \n \n図 3-2: モデルの利用方法 \n \n生成AIシステムの構築環境の選択 \n3.2.5...",
    "content_length": 456,
    "created_at": "2025-05-12T09:49:11.103524+00:00",
    "updated_at": "2025-05-12T09:49:11.103525+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=33"
  },
  "doc-670d657cddafd9fe9a8bc2c7ed0011fb": {
    "status": "pending",
    "content": "11 \n \n1.5 本書の活用例 \n本書の構成は以下の通りとなっています。 \n第2章：セキュアな生成AIを導入・運用を行っていくために読者が持っておくべき基礎的な知識 \n第3～5章：それぞれの担当者（導入担当者、運用担当者、セキュリティ担当者）ごとの考慮事項 \n第6章：現在の日本企業における生成AI利活用の事例と実態調査結果 \n第7章：国内外のAIの法規制や今後の動向について \n \n本書を活用することで以下のような効果を見込むことできます（以下の例はあくまで一例です） 。 \n 第2章 \n 生成AIとはどのようなものか理解することができる \n 生成AIの回答精度向上のための手法を理解することができる \n 生成AIの組織的な活用事例を知ることができる \n 第3章 \n 生成AIの組織における製品選定の基準を理解することができる \n どのような導入プロセスを経るべきなのか理解することができる \n 第4章 \n 生成AIの組織の利活用におけるガイドラインに記載する内容を理解することができる \n 生成AIの運用における懸念事項や考慮事項を理解することができる \n 第5章 \n OWASP1が公表しているOWASP Top 10 for LLM（OWASPが発表したLLMに関する10大脅\n威）について理解することができる \n 生成AIにおけるセキュリティリスクアセスメント手法について理解することができる \n 生成AIにおける具体的なセキュリティ対応策について理解することができる \n 第6章 \n 生成AIにおける国内組織の活用の実態について知ることができる \n 実際に組織が直面した課題やその解決法を知ることができる \n 第7章 \n 米国の大統領令やEUのAI Actなど、海外のAI法案についての概要を知ることができる \n 日本の現状と各国の動向を考慮した日本企業が取るべき対応について私見を述べます \n  \n \n1 Open Worldwide Application Security Project。ソフトウェアのセキュリティを改善するオープンコミ\nュニティ。",
    "content_summary": "11 \n \n1.5 本書の活用例 \n本書の構成は以下の通りとなっています。 \n第2章：セキュアな生成AIを導入・運用を行っていくために読者が持っておくべき基礎的な知識 \n第3～5章：それぞれの担当者（導入担当者、運用担当者、セキュリティ担当者）ごとの考慮事項 \n第6章：現在の日本企業における生成AI利活用の事例と実態調査結果 \n第7章：国内外のAIの法規制や今後の動向について \n \n本書を活用することで以下のような効果を見込むことできます（以下の例はあくまで一例です） 。 \n 第2章 \n 生...",
    "content_length": 905,
    "created_at": "2025-05-12T09:49:11.103474+00:00",
    "updated_at": "2025-05-12T09:49:11.103475+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=13"
  },
  "doc-8468b62680bcb4b379d22f2dc9a24529": {
    "status": "pending",
    "content": "38 \n \n利活用ガイドラインが存在しない場合、生成AIの利用方法をユーザが自己判断せざるを得ず、個人情\n報を入力して漏洩してしまう、効果的な利用方法がわからず利用をやめてしまうなどの事態が発生する\n可能性が高くなってしまいます。 \nしたがって、生成AIを効果的かつ安全にユーザに利用してもらうため、利活用ガイドラインの策定は\n重要です。 \n \n4.1.2 利活用ガイドラインに記載すべき項目 \n利用制限に関する項目 \n生成AIの利用制限に関する項目を定めることは、組織の機密情報の漏洩やユーザによる意図しない違\n法行為への加担といったリスクの回避に有効です。生成AIのモデルを開発するAnthropic社やGoogle\n社、OpenAI社は利用規約等にて、主に以下の目的での使用を禁止しています [16] [17] [18]。 \n \n 違法行為、または違法行為を促進・助長するコンテンツの作成 \n 違法な物質、商品の製造 \n 犯罪行為 \n 児童ポルノ、性的暴力 \n 個人の精神・身体や、権利に危害をもたらすリスクのあるコンテンツの作成 \n 銃や爆弾、生物兵器や化学兵器の製造 \n 暴力、自傷行為、人身売買 \n 本人の同意を得ずに他者の情報を利用 \n 誤った情報の提供、個人を意図的に欺くことを目的としたコンテンツの作成 \n 詐欺行為 \n 別の個人へのなりすまし \n \nまた、組織の規定に反する内容や次項の「入力制限に関する項目」の内容に関する業務では、生成AI\nの利用制限を検討することが必要です。例えば、以下のような業務が考えられます。 \n 顧客情報や機密情報を取扱う業務 \n 外部公開前の情報を取扱う業務 \n 業務以外の目的での使用 \n \n生成AIへの入力について \n生成AIへのプロンプト入力にあたり、ユーザに意識してもらう内容として、 「プロンプトエンジニア\nリング」と「入力制限に関する項目」の2つが考えられます。 \n \n プロンプトエンジニアリング \n生成AIは、ユーザが求める回答を常に出力するとは限りません。効果的に活用するためには、適切\nなプロンプトの作成が重要です。",
    "content_summary": "38 \n \n利活用ガイドラインが存在しない場合、生成AIの利用方法をユーザが自己判断せざるを得ず、個人情\n報を入力して漏洩してしまう、効果的な利用方法がわからず利用をやめてしまうなどの事態が発生する\n可能性が高くなってしまいます。 \nしたがって、生成AIを効果的かつ安全にユーザに利用してもらうため、利活用ガイドラインの策定は\n重要です。 \n \n4.1.2 利活用ガイドラインに記載すべき項目 \n利用制限に関する項目 \n生成AIの利用制限に関する項目を定めることは、組織の機密情報の漏洩やユーザによる...",
    "content_length": 909,
    "created_at": "2025-05-12T09:49:11.103548+00:00",
    "updated_at": "2025-05-12T09:49:11.103548+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=40"
  },
  "doc-7b4d78dcf609902a3fdd9df9efc99522": {
    "status": "pending",
    "content": "85 \n \n \n図 7-2: 生成AIの特徴の相関 \n \n法規と安全な利用 \n各国で行ったAIに対するアンケート結果によると、 「AIを理解しているか」という質問に対し、 「理解\nしている」と回答したのは、日本では43％と、米国の67%や、最も高いインドネシアの84％を下回って\nいます。しかし、 「AIに不安を感じるか」という質問に対しても、不安を示す回答が、同じく日本が米国\nを下回りました（日本23％に対し米国63％） [32]。 \nつまり、 「日本はAIに対する深い理解はないが、楽観的に捉えている」という結果が得られたと言え\nます。この結果からは、AIに対し、先進的な技術であるというイメージが先行し、それに関するリスク\nが認識されていないことが危惧されます。リスクは例えば、AIが行う「推論」によって作られたハルシ\nネーションや潜在的思考への影響、過失によるもの （情報漏洩など）に加えて、悪意によるもの（ディー\nプフェイクによる個人の尊厳を汚す行為、フェイクニュースを作成し大衆を混乱に陥れる行為など）で\nす。 \nこのようなリスクに対し、 米国は法律による規制を行っていく可能性を示しており、 同盟国である日本\nに対しても足並みを揃えた規制が求めることが想定されます [62]。現在、日本におけるAIの法規制は\n議論が始まったばかりであり、継続的に注視していく必要があります。一方で、法規やガイドラインは安\n全な利用を促すために作られるものの、安全はそれだけでは担保されません。ユーザがAIの作り出すハ\nルシネーションや悪意のあるフェイクニュースなどに惑わされないためには、ユーザ自身が正しくAIを\n理解し、その危険性を回避する方法を学ぶ必要があります。具体的には、信頼のおける公的機関の情報を\n活用し、事実関係の確認を行うべきです。 \n組織において利用する際には継続的なAIの教育を行い、 “もっともらしいAIの出力の正しさ”を確認\nする習慣を根付かせることが重要です。情報の真偽性を確認する習慣を浸透させ、AIの持つ利便性や有\n効性を最大化し、業務効率と企業価値の最大化を図っていきましょう。",
    "content_summary": "85 \n \n \n図 7-2: 生成AIの特徴の相関 \n \n法規と安全な利用 \n各国で行ったAIに対するアンケート結果によると、 「AIを理解しているか」という質問に対し、 「理解\nしている」と回答したのは、日本では43％と、米国の67%や、最も高いインドネシアの84％を下回って\nいます。しかし、 「AIに不安を感じるか」という質問に対しても、不安を示す回答が、同じく日本が米国\nを下回りました（日本23％に対し米国63％） [32]。 \nつまり、 「日本はAIに対する深い理解はないが、楽観的に捉え...",
    "content_length": 905,
    "created_at": "2025-05-12T09:49:11.103661+00:00",
    "updated_at": "2025-05-12T09:49:11.103662+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=87"
  },
  "doc-4ce0fdf6821b9c17de7b321730df61ca": {
    "status": "pending",
    "content": "24 \n \n2.4.2 導入・運用の流れ（プロセス） \n本書における「生成AIの組織導入・運用プロセス」では、構想策定から改善までをPDCAサイクル\nの1サイクルと定めています。例えば、図 2-7のように1周目は「スモールスタート」 、2周目は「本\n番導入」 、3周目以降はRAG導入のような 「機能拡張」等、サイクルを何度も回し、改善を重ねる必要\nがあります。 \n \n \n図 2-7: 生成AIの導入・運用プロセス \n \nまた、この1サイクルは図 2-8に示す通り6つのフェーズとしても定めています。各フェーズでの実施\n事項は下記の通りです。 \n \n \n図 2-8: 生成AI導入・運用プロセスにおける1サイクルの内容 \n \nPlan \n 構想策定 \n生成AIの導入目的やスコープ（対象業務・対象ユーザ）を定めます。 \n \n 要件定義 \n策定した目的に基づいて導入目標を定め、生成AIシステムに必要な機能や条件を定義します。また、\n利用ポリシーとユーザへの教育内容、生成AIを導入する上で生じるリスクについて検討します。",
    "content_summary": "24 \n \n2.4.2 導入・運用の流れ（プロセス） \n本書における「生成AIの組織導入・運用プロセス」では、構想策定から改善までをPDCAサイクル\nの1サイクルと定めています。例えば、図 2-7のように1周目は「スモールスタート」 、2周目は「本\n番導入」 、3周目以降はRAG導入のような 「機能拡張」等、サイクルを何度も回し、改善を重ねる必要\nがあります。 \n \n \n図 2-7: 生成AIの導入・運用プロセス \n \nまた、この1サイクルは図 2-8に示す通り6つのフェーズとしても定めています...",
    "content_length": 463,
    "created_at": "2025-05-12T09:49:11.103508+00:00",
    "updated_at": "2025-05-12T09:49:11.103508+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=26"
  },
  "doc-ab7f31020586501f78ac5d18bcd7e71b": {
    "status": "pending",
    "content": "8 \n \n2024年3月にICT市場調査コンサルティング企業である株式会社MM総研がプレスリリースを行っ\nた 「生成AI／LLMの国内利活用動向調査2024」 [5]によると、 「導入にあたって課題を感じている企業\nは97％」 （図 1-4）と、生成AIを組織として導入するにはほぼ全ての組織で何かしらの課題感を抱えて\nいるといった結果が示されました。 \n \n \n図 1-4: 生成AIを導入する上での課題 \n（出典）MM総研 \n \n図 1-4より、突出している課題があるわけではなく、幅広い課題を抱えていることが分かります。これ\nは、生成AIへの理解不足が起因となって、漠然とした課題認識、不安感が生じていることが見て取れま\nす。 \n \n1.2 本書の作成目的 \n生成AI技術の急速な発展に伴い、国家主導で多くの組織にて生成AIの利用が推進されています。た\nとえば経済産業省（METI）は生成AIに関する開発支援や計算資源提供など、組織の生成AI利用推進に\n向けて、さまざまな取り組みを実施しています。我々のプロジェクトも、組織への生成AI利用を推進し\nていきたいという想いをもとに立ち上げました。 \nその一方で、生成AIを利用したいと考えている組織の中でも導入に踏み切れないといった場合や、導\n入したものの、現在の適切な運用ができているのかという懸念を持っている組織もあることが想定され\nます。我々はこれらの要因を「組織の生成AIに対する漠然とした不安感」と捉えています。組織からす\nると、1.1.4に記載した潜在的な課題の存在を認識できるものの、より具体的に“セキュリティリスク”\nや“リスク対策”に落とし込むことは難しく、その困難さが漠然とした不安感に繋がると推測していま\nす。",
    "content_summary": "8 \n \n2024年3月にICT市場調査コンサルティング企業である株式会社MM総研がプレスリリースを行っ\nた 「生成AI／LLMの国内利活用動向調査2024」 [5]によると、 「導入にあたって課題を感じている企業\nは97％」 （図 1-4）と、生成AIを組織として導入するにはほぼ全ての組織で何かしらの課題感を抱えて\nいるといった結果が示されました。 \n \n \n図 1-4: 生成AIを導入する上での課題 \n（出典）MM総研 \n \n図 1-4より、突出している課題があるわけではなく、幅広い課題を抱...",
    "content_length": 743,
    "created_at": "2025-05-12T09:49:11.103466+00:00",
    "updated_at": "2025-05-12T09:49:11.103467+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=10"
  },
  "doc-44257419acda078c62e0eeb0379297f6": {
    "status": "pending",
    "content": "39 \n \nプロンプトには以下の4つの要素が含まれています。 \n 命令： 「回答する」 「分類する」 「要約する」など生成AIに実行してもらうタスク \n 文脈： 「話題」 「目的」 「複数の例」など生成AIが正確にタスクを実行するための追加の情報 \n 入力： 「回答してほしい質問」 「要約してほしい文章」などタスクを実行する対象 \n 出力： 「文章の長さ」 「箇条書きの個数」 「プログラム形式」など回答の形式の指示 \n \n必ずしも4 つの要素全てが必要というわけではありませんが、これらを具体的に指示し適切に組み\n合わせることで、生成AIは目的の出力を生成しやすくなります。これをプロンプトエンジニアリング\nと呼びます [19]。以下に、プロンプトエンジニアリングの例を示します。 \n \n 「文章の長さ」と「回答してほしい質問」の要素を含むプロンプト（図 4-3） \n \n図 4-3: 「文章の長さ」と「回答してほしい質問」の要素を含むプロンプトの例",
    "content_summary": "39 \n \nプロンプトには以下の4つの要素が含まれています。 \n 命令： 「回答する」 「分類する」 「要約する」など生成AIに実行してもらうタスク \n 文脈： 「話題」 「目的」 「複数の例」など生成AIが正確にタスクを実行するための追加の情報 \n 入力： 「回答してほしい質問」 「要約してほしい文章」などタスクを実行する対象 \n 出力： 「文章の長さ」 「箇条書きの個数」 「プログラム形式」など回答の形式の指示 \n \n必ずしも4 つの要素全てが必要というわけではありませんが、これらを...",
    "content_length": 432,
    "created_at": "2025-05-12T09:49:11.103550+00:00",
    "updated_at": "2025-05-12T09:49:11.103551+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=41"
  },
  "doc-5319d270c45622bfe48567c9abdd93ff": {
    "status": "pending",
    "content": "25 \n \nDo \n 設計・開発 \n具体的なシステム構成や利用するLLMについて検討し、システム構築を行います。 \n \n テスト・デプロイ \n構築した生成AIシステムに対するテストを実施し、 実環境へのAIシステムの導入可否を判断します。 \n \nCheck \n 運用・評価 \nデプロイされた生成AIシステムの保守・運用作業を実施します。また、導入効果やセキュリティ等の\n評価を実施します。 \n \nAct \n 改善 \n評価結果を生成AIシステムや利用ポリシーに反映し、改善を行います。 \n \n2.4.3 導入・運用における担当者 \n本書では生成AIの組織活用における担当者を、以下のように3つに分類します。 \n \n 導入担当者 \n組織において生成AIの導入を担当する従業員を指します。 \n具体的には、生成AI導入時における導入プロセス（構想策定・要件定義・設計開発・テスト・デプ\nロイ）を牽引し、組織における生成AI導入を促進します。 \n \n 運用担当者 \n組織において生成AIの維持・運用を担当する従業員を指します。 \n具体的には、組織における生成AIの安全な利活用のためのガイドライン・利用ポリシー・規定など\nを制定し、ユーザに周知を行います。 \n \n セキュリティ担当者 \n組織におけるセキュリティやリスクマネジメントを担当する従業員を指します。 \n具体的には、組織における生成AIの安全な利活用のためのリスクアセスメントを実施した上で対策\nを講じます。",
    "content_summary": "25 \n \nDo \n 設計・開発 \n具体的なシステム構成や利用するLLMについて検討し、システム構築を行います。 \n \n テスト・デプロイ \n構築した生成AIシステムに対するテストを実施し、 実環境へのAIシステムの導入可否を判断します。 \n \nCheck \n 運用・評価 \nデプロイされた生成AIシステムの保守・運用作業を実施します。また、導入効果やセキュリティ等の\n評価を実施します。 \n \nAct \n 改善 \n評価結果を生成AIシステムや利用ポリシーに反映し、改善を行います。 \n \n2...",
    "content_length": 636,
    "created_at": "2025-05-12T09:49:11.103510+00:00",
    "updated_at": "2025-05-12T09:49:11.103511+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=27"
  },
  "doc-12a873d5ffe8c15a7a2a8337654a6b65": {
    "status": "pending",
    "content": "94 \n \n学習データ 機械学習モデルを学習させる上で必要となる情報のこと。 \n一般的な機械学習では、回答精度を高める上で重要な役割を\n担う。特に生成AIに関しては、学習データの品質が回答精\n度に大きく影響を与える。 \n間接プロンプトインジェクション 攻撃者が事前にウェブサイトや画像といったデータに悪意の\nある指示文を紛れ込ませ、Webクロールを行う生成AIに学\n習あるいは一般ユーザに悪意のあるプロンプト入力を誘導す\nるという手法。 \n機械学習 コンピュータがデータを自動で学習し、データの背景にある\nルールやパターンを発見する方法。 \n個人情報保護法 個人情報の有用性に配慮しながら、個人の権利や利益を守る\nことを目的とした法律。 \n（正式名称：個人情報の保護に関する法律） \n自然言語処理 コンピュータが、人間が使う日常の言葉の解釈を1つに絞り\nながら、できるだけ自然に意味を把握するための技術。 \n情報抽出攻撃（プライバシー攻撃） LLMや学習データに関する情報を再構築し盗むことを目的\nとした攻撃。 \n多層防御（Defense in Depth） 単一の防御策に頼るのではなく、複数の異なる防御策を実施\nすることでセキュリティを強化する手法。 \n大規模集積回路 半導体集積回路（IC）の中でも素子数が1000以上のもの。 \nLSI（Large Scale Integrated circuit）とも呼ばれる。 \n段階的導入（スモールスタート） サービスやソフトウェアを部署や業務単位など小規模な範囲\nでの導入を開始し、順次導入範囲を広げていく導入手法。 \n透明性 AIシステムにおける意思決定および回答のプロセスや使用\nした学習データを第三者が確認できる状態。 \n特権の昇格 システムなどで管理者権限などの本来割り当てられていない\n権限を不正に取得する攻撃手法。",
    "content_summary": "94 \n \n学習データ 機械学習モデルを学習させる上で必要となる情報のこと。 \n一般的な機械学習では、回答精度を高める上で重要な役割を\n担う。特に生成AIに関しては、学習データの品質が回答精\n度に大きく影響を与える。 \n間接プロンプトインジェクション 攻撃者が事前にウェブサイトや画像といったデータに悪意の\nある指示文を紛れ込ませ、Webクロールを行う生成AIに学\n習あるいは一般ユーザに悪意のあるプロンプト入力を誘導す\nるという手法。 \n機械学習 コンピュータがデータを自動で学習し、データの背景に...",
    "content_length": 787,
    "created_at": "2025-05-12T09:49:11.103683+00:00",
    "updated_at": "2025-05-12T09:49:11.103684+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=96"
  },
  "doc-a08c8eaf1f79d16ae4a223a576b75bbf": {
    "status": "pending",
    "content": "4 \n \n第1章 はじめに \n1.1 背景 \n1.1.1 AIの組織での普及について \n近年、AI （Artiﬁcial Intelligence、人工知能）は目覚ましい速度で普及が進んでいます。AIの市場規模\n（売上高）は加速度的な成長が予測され、世界市場では、2021年を基準に、2025年には約4.4倍、2030\n年には約19.3倍に成長する見込みであることが公表されています（図 1-1） [1]。また、国内において\nも、国内AIシステム市場支出額の予測も海外市場と同等速度での成長が予想されており、2022年から\n2027年までで約2.5倍まで成長することが見込まれています（図 1-2） [2]。 \n \n人工知能（AI）はさまざまな業界に革命をもたらし、昨今の市場で競争力を維持したい企業にとって、\nもはや不可欠なツールとなりつつあります。技術の進歩により、AIは組織に幅広いメリットと成長機会\nをもたらします。業務においては、タスクの自動化やデータに基づいた意思決定のサポート、リアルタイ\nムデータ分析などを通じて企業の生産性向上に寄与し、市場競争上の優位性をもたらします。AIを導入\nしない企業は、AIを活用している企業と比較して作業効率の向上が見込めないことなどによる競争力の\n低下が懸念されます。そのため、今後、国内企業がAI投資を怠ることは、事業成長の妨げとなる可能性\nがあります。 \n  \n \n図 1-1: AIの世界市場規模システム世界市場規模 \nstatia 「2021年 人工知能（AI）の世界市場規模および2030年\nまでの予測値（単位：100万米ドル） 」より作成 \n \n図 1-2: 国内AIシステム市場支出額予測 \nIDC「2023年 国内AIシステム市場予測を発表」より作成",
    "content_summary": "4 \n \n第1章 はじめに \n1.1 背景 \n1.1.1 AIの組織での普及について \n近年、AI （Artiﬁcial Intelligence、人工知能）は目覚ましい速度で普及が進んでいます。AIの市場規模\n（売上高）は加速度的な成長が予測され、世界市場では、2021年を基準に、2025年には約4.4倍、2030\n年には約19.3倍に成長する見込みであることが公表されています（図 1-1） [1]。また、国内において\nも、国内AIシステム市場支出額の予測も海外市場と同等速度での成長が予想され...",
    "content_length": 757,
    "created_at": "2025-05-12T09:49:11.103454+00:00",
    "updated_at": "2025-05-12T09:49:11.103455+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=6"
  },
  "doc-619bec77351ab9bf9fc56bf2b44a4d0e": {
    "status": "pending",
    "content": "49 \n \nユーザから得るべき情報 \n 生成AIの導入効果（業務改善効果など） \nユーザが生成AIを利用した結果で得た業務改善効果を把握するため、 アンケートやユーザインタ\nビューを行い、具体的な効果や成果を定量的および定性的に収集することが重要です。 \n \n 改善点 \n生成AIの運用において、 ユーザが実際に使用して感じた課題をフィードバックとして受け取るこ\nとで、改善点を把握することができます。把握した改善点をシステムアップデートの際に反映させ\nることで、よりユーザが使いやすいシステムとすることができます。 \n \n 質問事項 \nユーザが生成AIを実際に使用する中で感じた使用方法や運用に関する疑問、 知りたい情報を把握\nして、必要な情報を提供することで、ユーザが生成AIをさらに活用しやすい環境を整えることがで\nきます。また、 質問の中には改善点に繋がる内容もあるため、 質問対応に留めずフィードバック情報\nとして活用するべきです。 \n \n4.4.3 評価結果を踏まえた各種改善 \n導入効果を評価した上で、評価結果から得られるフィードバックを基に各種改善を図ることで、生成\nAIをより効果的に活用することができます。主な改善に繋がる要素を以下に示します。 \n \n 利活用ガイドライン \nユーザから得たフィードバックを基に内容を更新することで、利便性と安全性を考慮した利活用\nガイドラインを整備することができます。 \n \n 運用担当者の実施項目 \n改善点や質問事項を参考に、上記で紹介した教育内容やメンテナンスの項目などを見直すことで、\n実態に即した運用ができます。実務事例に則った運用手順やルールを明確にすることで、さらなる\n有効活用に繋げることが期待できます。 \n \n 生成AIのシステム改善 \nシステム更新やアップデートの際に、フィードバック内容を考慮した内容を盛り込むことで、生\n成AIのシステム改善を行い、導入効果を高めることが期待できます。 \n \n以上のように、 運用担当者とユーザの間で密に情報交換を行い、 得られた情報を適切に反映させること\nで、生成AIの運用を効果的に改善していくことが可能となります。改善への取り組みは一過性の取り組\nみにせず、継続的に実施することで、生成AIの導入効果の最大化が期待できます。",
    "content_summary": "49 \n \nユーザから得るべき情報 \n 生成AIの導入効果（業務改善効果など） \nユーザが生成AIを利用した結果で得た業務改善効果を把握するため、 アンケートやユーザインタ\nビューを行い、具体的な効果や成果を定量的および定性的に収集することが重要です。 \n \n 改善点 \n生成AIの運用において、 ユーザが実際に使用して感じた課題をフィードバックとして受け取るこ\nとで、改善点を把握することができます。把握した改善点をシステムアップデートの際に反映させ\nることで、よりユーザが使いやすいシステムと...",
    "content_length": 975,
    "created_at": "2025-05-12T09:49:11.103574+00:00",
    "updated_at": "2025-05-12T09:49:11.103574+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=51"
  },
  "doc-f63bb846f3bdf89c5a110414d7188886": {
    "status": "pending",
    "content": "81 \n \n7.2.1 米国の場合 \nTransformerモデルに関する論文の発表、ChatGPTサービスの開始、その他の主だった生成AIサービ\nスを提供するなど米国のAI市場が急速な発展するなかで米国民は不安を感じています。 \n2019年2月、トランプ前大統領は、米国がAI技術の開発と利用においてグローバルリーダーの地位\nを維持し強化する「人工知能における米国のリーダーシップ維持のための大統領命令」に署名しました \n[44]。Pew Research Centerが2019年に公表した結果では、米国民のうち82%が、AIやロボットを用い\nた業務の自動化によって、37％が雇用を奪われるという認識をもっていることが示されました [45]。加\nえて、その後実施された大統領選でも相手陣営を貶めるためにAIを使い作られたディープフェイクがソ\nーシャルネットワークを中心に拡散され、AIに対する不信感が高まりました [46]。米国民が、生成AI\nの発展がもたらしたこれらの弊害に対して不安を抱いているという状況を踏まえ、2021年1月に就任し\nたバイデン大統領は、プライバシーの原則を含む公民権や民主主義的価値をより強く守る方針を打ち出\nし、国民が持つ権利の保護を示しました [47]。 \n米国科学技術政策局（OSTP）は、バイデン大統領の方針を基に、2021年10月から「AI権利章典の\n青写真」の作成を開始し、翌2022年10月に公表しました [47]。また、新技術である生成AIの有用性\nと裏に潜む危険性のバランスを取るべく、2023年1月に米国商務省国立標準技術研究所（NIST）はAI \nRMFを発行し、法規制による明示的な産業活動の締め付けを避け、ガイドラインを公表することで企業\nに社会的責任を果たすことを求める市場に働きかけを促す選択をしました [48]。 \nこれらに続き、バイデン大統領は2023年10月に「人工知能（AI）の安心、安全で信頼できる開発と\n利用に関する大統領令」に署名を行い、これまでのAIにおける米国のリーダーシップの強化やAIエコ\nシステムへの支援などAI市場の支援を継続しながら、安全性とセキュリティ基準の策定やプライバシー\nの保護、公平性や市民権の推進、責任あるAIについて言及しました [49]。加えて、2024年4月にAIの\n安全とセキュリティに関する諮問委員会 （AISSB）を設置し、AIに対する、もしくはAIを用いた攻撃な\nどに対して安全を確保するための推奨事項を示していく方針を打ち出しました [50]。 \n2024年5月にAIの能力や影響などのリスクを評価するプログラムを開始し、常に変化し続けるAIの\nリスクに対して継続的かつ流動的に対応できる体制を構築しています [51]。また、2023年に議会に提出\nされたAI関連法案は181本に上るなど諸外国と足並みを揃えるために米国も法規制を行う機運が高ま\nっています [32]。 \n \n7.2.2 EU の場合 \n現時点で高度な生成AIサービスを十全に活用するためには、クラウドサービスを利用することが主流\nといえます。クラウドと関連性の強い欧州の法規といえば、2018年に施行されたGDPR（EU一般デー\nタ保護規則）が連想されます。GDPRは、利用に関する事前通知、データの処理、利活用、移転のほか、\nデータの取扱いについて詳細な要件を定義し、違反した場合には多額の罰金が課されます。この法規に\nより、EU市民の個人データおよび基本的人権を保護することができます [52]。",
    "content_summary": "81 \n \n7.2.1 米国の場合 \nTransformerモデルに関する論文の発表、ChatGPTサービスの開始、その他の主だった生成AIサービ\nスを提供するなど米国のAI市場が急速な発展するなかで米国民は不安を感じています。 \n2019年2月、トランプ前大統領は、米国がAI技術の開発と利用においてグローバルリーダーの地位\nを維持し強化する「人工知能における米国のリーダーシップ維持のための大統領命令」に署名しました \n[44]。Pew Research Centerが2019年に公表した結果で...",
    "content_length": 1492,
    "created_at": "2025-05-12T09:49:11.103651+00:00",
    "updated_at": "2025-05-12T09:49:11.103651+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=83"
  },
  "doc-8cbff54c080d3d76c6382655769c9a73": {
    "status": "pending",
    "content": "95 \n \n参照文献 \n \n[1]  statista, “2021年 人工知能（AI）の世界市場規模および2030年までの予測値（単位：100万\n米ドル） ”, 2023-01, https://jp.statista.com/statistics/1357441/artiﬁcial-intelligence-market-size. \n[アクセス日: 2024-06]. \n[2]  IDC Research, “2023年 国内AIシステム市場予測を発表”, 2023-04-27, \nhttps://www.idc.com/getdoc.jsp?containerId=prJPJ50603323. [アクセス日: 2024-06]. \n[3]  総務省, “人工知能（AI）研究の歴史”, 2016, \nhttps://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h28/html/nc142120.html. [アクセス日: \n2024-06]. \n[4]  JIPDEC, “ 「企業IT利活用動向調査2024」集計結果”, 2024-03-15, \nhttps://www.jipdec.or.jp/library/report/m0p0h60000000x1m-att/20240315_s03.pdf. [アクセス\n日: 2024-06]. \n[5]  MM総研, “本番迎える生成AI／LLM市場、国内ベンダーに期待集まる”, 2024-03, \nhttps://www.m2ri.jp/release/detail.html?id=618. [アクセス日: 2024-06]. \n[6]  総務省, 経済産業省, “AI事業者ガイドライン（第 1.0 版） ”, 2024-04-19, \nhttps://www.meti.go.jp/press/2024/04/20240419004/20240419004-1.pdf. [アクセス日: 2024-\n06]. \n[7]  NIST, “Artiﬁcial Intelligence Risk Management Framework (AI RMF 1.0)”, 2023. [アクセス日: \n2024-06]. \n[8]  NIST, “Artiﬁcial Intelligence Risk Management Framework: Generative Artiﬁcial Intelligence \nProﬁle” 2024-04, https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Proﬁle.ipd.pdf. [アクセス日: \n2024-06]. \n[9]  ISO, IEC, ISO/IEC 42001:2023 Information technology — Artiﬁcial intelligence — Management \nsystem, 2023. [アクセス日: 2024-06]. \n[10] 日本ディープラーニング協会, “生成AIの利用ガイドライン【簡易解説付】( 第1.1版, 2023年\n10月公開)”, 2023-10, https://www.jdla.org/document/#ai-guideline. [アクセス日: 2024-06]. \n[11] OWASP, “LLM AI サイバーセキュリティとガバナンスのチェックリスト 〜失敗しない大規模\n言語モデル導入のために〜”, 2024-04-10, https://genai.owasp.org/wp-\ncontent/uploads/2024/05/LLM_AI_Security_and_Governance_Checklist-v1_1_JP.pdf. [アクセス\n日: 2024-6]. \n[12] S. Barnett, S. Kurniawan , S. Thudumu, “Seven Failure Points When Engineering a Retrieval \nAugmented”, Association for Computing Machinery, 2024. [アクセス日: 2024-06].",
    "content_summary": "95 \n \n参照文献 \n \n[1]  statista, “2021年 人工知能（AI）の世界市場規模および2030年までの予測値（単位：100万\n米ドル） ”, 2023-01, https://jp.statista.com/statistics/1357441/artiﬁcial-intelligence-market-size. \n[アクセス日: 2024-06]. \n[2]  IDC Research, “2023年 国内AIシステム市場予測を発表”, 2023-04-27, \nhtt...",
    "content_length": 1811,
    "created_at": "2025-05-12T09:49:11.103686+00:00",
    "updated_at": "2025-05-12T09:49:11.103687+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=97"
  },
  "doc-e4c9ca5b726b1d4968d140f9d849ad49": {
    "status": "pending",
    "content": "56 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1）表 5-1が10大脅威の概要です（説明の都合上、一部内\n容を修正） 。表中の「影響範囲」は、生成AIシステムのどこでそのリスクが顕現するかを表します（図 \n5-5のアルファベットa～iおよび数字I～VIで、システム内の箇所を示します） 。 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1） [11] \n \nNo リスク 概要 影響範囲\n001プロンプト・インジェクション巧妙な入力によって大規模な言語モデル（LLM）を操作し、LLMが意図しない動作を引き起こします。システムのプロンプトを直接、上書きする手法、外部ソースからの入力を操作し、間接的に行う手法があります。a,b,g\n002安全が確認されていない出力ハンドリングLLMの出力を細かくチェックせずに連携システムに送った場合、システムの脆弱性をつかれ、意図しない結果を引き起こすことです。悪用されると、XSS、CSRF、SSRF、特権の昇格、リモート・コードの実行といった深刻な結果につながる可能性があります。d,h \n003 訓練データの汚染LLMの訓練データが改ざんされ、セキュリティ、有効性、倫理的行動を損なう脆弱性やバイアスなどが入り込むことです。訓練データの情報源として、CommonCrawl、WebText、OpenWebText、書籍などが使われます。今回のシステム上には該当しない\n004 モデルのDoSLLMが計算リソースを大量に消費するようにしむけ、LLMを使ったサービスの品質低下や高コストを狙ったものです。b,g\n005サプライチェーンの脆弱性LLMアプリケーションが使用するコンポーネントやサービスの脆弱性によって引き起こされる攻撃です。サードパーティのデータセット、事前に訓練されたモデル、およびプラグインを使用することで脆弱性が増す可能性があります。 Ⅱ,Ⅲ,Ⅳ,Ⅴ,Ⅵ\n006 機微情報の漏えいLLMはその応答の中に意図せず機密データを含めてしまう可能性があり、不正なデータアクセス、プライバシー侵害、セキュリティ侵害につながります。これを軽減するためには、データの浄化と厳格なユーザー・ポリシーを導入することが極めて重要です。b,d,h\n007安全が確認されていないプラグイン設計LLMプラグインにおいて、入力の安全性が確認されておらず、あるいはアクセスコントロールが不十分な場合、悪意のあるリモート・コード実行のような結果をもたらす可能性があります。Ⅲ\n008 過剰な代理行為この問題は、LLMベースのシステムに与えられた過剰な機能、権限、または自律性に起因し、意図しない結果を招くことがあります。Ⅱ,Ⅲ,Ⅴ,Ⅵ\n009 過度の信頼十分監督されていないLLMに過度に依存したシステムやユーザーは、LLMが生成したコンテンツが不正確または不適切なものであることに気づかず、誤った情報、誤ったコミュニケーション、法的問題、セキュリティの脆弱性に直面する可能性があります。i\n010 モデルの盗難独自のLLMモデルへの不正アクセス、モデルのコピー、または流出が含まれます。その影響は、経済的損失、競争上の優位性の低下、機密情報へのアクセスの可能性などです。a,Ⅳ",
    "content_summary": "56 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1）表 5-1が10大脅威の概要です（説明の都合上、一部内\n容を修正） 。表中の「影響範囲」は、生成AIシステムのどこでそのリスクが顕現するかを表します（図 \n5-5のアルファベットa～iおよび数字I～VIで、システム内の箇所を示します） 。 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1） [11] \n \nNo リスク 概要 影響範囲\n001プロンプト・インジェクション巧妙な入...",
    "content_length": 1387,
    "created_at": "2025-05-12T09:49:11.103590+00:00",
    "updated_at": "2025-05-12T09:49:11.103591+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=58"
  },
  "doc-f14ed0d99279b402e6f116c836744b87": {
    "status": "pending",
    "content": "80 \n \n一方、Mistral AI社は、Alphabet社とMeta社の元研究者によって2023年4月に設立されました。設\n立当初から世界の注目を浴び、 設立の5か月後には 「Mistral 7B」 という独自モデルの発表を行いました。\nその3か月後には「Mistral 8x7B」を発表するなど、進歩の著しい企業です [40]。2024年3月には、こ\nれら2 つのモデルが大手クラウドで利用可能になり、同社が大手クラウドサービスとの連携も強めてい\nることがわかります [41]。そんな中、新たな開発資金調達が、2024年3月で5億ドルに達し、5月時点\nでは調達額が6億ドルに達する見込みと報道されました [40]。 \n \n繰り返しとなりますが、高性能な生成AIモデルの構築するための学習には、多額のコストが必要とな\nります。裏返せば、多額のコストを費やすことができれば、生成AIモデルの性能を向上させる可能性が\n高まります。 多額の生成AI開発資金の調達を成したAleph Alpha社とMistral社が今後提供するAIモデ\nルについても注視していく必要があると言えます。投資以外にも公的機関の支援もAI開発を加速させま\nす。EU政府は前述のスタートアップ企業以外からも強いAIを生み出すために、AI関連のスタートアッ\nプ企業に対して支援を開始しました。欧州委員会と欧州高性能コンピューティング共同事業が共同で設\n置したスーパーコンピュータを、AIを開発するスタートアップ企業に開放し、モデルの構築を促してい\nます。これらの背景からEUからより多くのAIモデルが構築される可能性が高まっています。 \n \n7.2 法規制について \n過去の歴史を振り返ると、新しい技術が産まれる際には、社会や国民生活の間に軋轢が生じてきまし\nた。生成AIもその例に漏れず、今現在いくつかの社会的な課題を抱えています。多くは、学習データに\n起因する課題や新たな概念に適合できていない法規制に関する課題です。例えば学習データの収集に焦\n点を当てると、ウェブクローリングを行い無差別にWebページや書籍、雑誌、論文、ニュース記事を収\n集することが問題視されています [42]。 つまり、 インターネット上に存在する個人情報や著作物をAIモ\nデルの学習データとして利用することの是非が争点となっています。個人情報や著作物が利用者の同意\nを得ないまま利用されることが、プライバシーや経済的な権利や表現を奪われることになります。加え\nて、ポルノや犯罪行為をはじめとする非倫理的なデータの利用により犯罪を増長する恐れもあります \n[43]。 ほかにも出力データの信頼性などを問題視する声があがるなど多くの課題が存在するため、 関連し\nて多くの規制やガイドラインが発行されています。ここでは、各国の法規制やガイドラインの発行につ\nいて触れます。",
    "content_summary": "80 \n \n一方、Mistral AI社は、Alphabet社とMeta社の元研究者によって2023年4月に設立されました。設\n立当初から世界の注目を浴び、 設立の5か月後には 「Mistral 7B」 という独自モデルの発表を行いました。\nその3か月後には「Mistral 8x7B」を発表するなど、進歩の著しい企業です [40]。2024年3月には、こ\nれら2 つのモデルが大手クラウドで利用可能になり、同社が大手クラウドサービスとの連携も強めてい\nることがわかります [41]。そんな中、新たな...",
    "content_length": 1208,
    "created_at": "2025-05-12T09:49:11.103648+00:00",
    "updated_at": "2025-05-12T09:49:11.103649+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=82"
  },
  "doc-f9c08f986bed928a572f645e381e97b0": {
    "status": "pending",
    "content": "75 \n \n 既存の規程やガイドラインとの兼ね合い \n組織内にはさまざまな規定やポリシーが存在しますが、ヒアリングで、特に生成AIシステムに関\n連が深いものとして挙げられたのは、クラウドにおける規定・ポリシー（以降、クラウド規定と呼\n称） 、輸出管理規定などです。組織によってはそのほかにも、情報セキュリティ規定や社内システム\n規定等、さまざまな規定・ポリシーが関連する可能性があります。ゆえに、生成AI導入 ・運用者に\nとって、関連する担当部門（例えば、IT部門、法務部門、セキュリティ部門）との連携が不可欠に\nなります。連携をすれば、生成AIシステムの導入が円滑に進むとともに、コンプライアンス違反の\nリスクを最小限に抑えられます。特にクラウド規定に関しては、組織の生成AIシステムとしてクラ\nウドサービス（主にPaaS）を活用したものが主流であることから、サービス選定時にSLAやデータ\n保管場所等を追加で考慮する必要があったという声が多く存在しました。 \n生成AIシステムはAIを活用した特別なサービスだと思われがちですが、 生成AIの社内システム\n導入は、他のクラウドを活用した社内システムの導入と大差ないことに注意しましょう。 \n \n システム利用率の低さ \n生成AIシステムや他のクラウドベースの社内システムを導入した際に、利用率が低いという課題\nはしばしば発生します。このような課題の発生原因としては以下が考えられます。 \n ユーザの教育不足 \nユーザが新しいシステムの使い方を十分に理解していない など \n \n システムが使いづらい \nWeb UIが直感的でない、操作が複雑である など \n \n 必要性の認識不足 \nユーザが新しいシステムの導入目的や利点を理解していない など \n \n 既存の業務プロセスとの不整合 \n新しいシステムが既存の業務プロセスと十分に統合されておらず、利用用途がわからない \nなど \n \n 技術的な問題 \nシステムのパフォーマンスが低い、頻繁にエラーが発生するなどの技術的な問題がある な\nど \n \n セキュリティの不安 \nユーザ自身が情報漏洩をしてしまうといったリスクを抱えるため、利用をためらう など \n \n上述の原因を解決するためにそれぞれの組織ではさまざまなアプローチをとられていました。こ\nこではその中でも効果的であると考えられる対策例についてご紹介します。",
    "content_summary": "75 \n \n 既存の規程やガイドラインとの兼ね合い \n組織内にはさまざまな規定やポリシーが存在しますが、ヒアリングで、特に生成AIシステムに関\n連が深いものとして挙げられたのは、クラウドにおける規定・ポリシー（以降、クラウド規定と呼\n称） 、輸出管理規定などです。組織によってはそのほかにも、情報セキュリティ規定や社内システム\n規定等、さまざまな規定・ポリシーが関連する可能性があります。ゆえに、生成AI導入 ・運用者に\nとって、関連する担当部門（例えば、IT部門、法務部門、セキュリティ部門）との...",
    "content_length": 1014,
    "created_at": "2025-05-12T09:49:11.103636+00:00",
    "updated_at": "2025-05-12T09:49:11.103637+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=77"
  },
  "doc-5777173261722e28136fe2c7956cdff3": {
    "status": "pending",
    "content": "89 \n \n \nDoS（Deny of Service）攻撃 サービス拒否攻撃とも呼ばれ、大量のパケットを送りつけて\nネットワークやシステム資源（CPU、メモリ、ディスク）\nを過負荷にしてシステムダウン、サービス停止に陥らせるこ\nとを目的とする攻撃手法 \nGDPR \n（General Data Protection \nRegulation） \n欧州経済領域（EEA）における個人データ保護やその取り扱\nいについて定めた規約。 \nEU域内にある組織だけでなく、EUと取引のある全ての組\n織が対象となる。 \nGPT \n（Generative Pre-trained \nTransformer） \nOpenAIが開発した自然言語処理のためのディープラーニン\nグモデル。与えられた文脈に基づいて自然な文章を生成する\nことに特化しており、ユーザとの対話を通じて、文脈に応じ\nた適切な応答を生成することができる。 \nGemini Google 社が提供している生成AIサービス。2024年6月時\n点での最高性能モデルはGemini1.5Proである。 \nISO \n（International Organization for \nStandardization） \nスイスのジュネーブに本部を置く国際標準化機構と当該組織\nが制定した国際規格。何らかの製品やサービスに関して世界\nで同じ品質、同じレベルのものを提供できるようにするため\nの国際的な基準が定められている。 \nIoT機器 インターネットに接続して使用する機器。これまでインター\nネットに接続する機能がなかった機器についても昨今はイン\nターネットに接続できる機器が増加している。 \n例）センサー、カメラ、リモート操作可能な家電や空調機器\n等。 \nLangChain LLM を用いたアプリケーション開発を効率的に行うための\n開発ライブラリ。LLMと外部リソースを組み合わせ、RAG\nやLLM連携システムなどの高度なアプリケーションやサー\nビス開発を目的としている。 \nPDCA サイクル Plan （計画） 、Do（実行） 、Check（測定・評価） 、Action\n（対策・改善）の仮説・検証型プロセスを循環させ、マネジ\nメントの品質を高めようという概念。 \nPaaS（Platform as a Service） クラウド事業者がソフトウェアを除くサーバやOSなどの利\n用環境を提供する形態。 \nRAG \n（Retrieval-Augmented Generation） \nLLMによるテキスト生成に、外部情報の検索を組み合わせ\nることで、回答精度を向上させる技術。 \nSLA（Service Level Agreement） サービス提供者とユーザとの間の契約において、サービスが\n提供される基準を定義したもの。",
    "content_summary": "89 \n \n \nDoS（Deny of Service）攻撃 サービス拒否攻撃とも呼ばれ、大量のパケットを送りつけて\nネットワークやシステム資源（CPU、メモリ、ディスク）\nを過負荷にしてシステムダウン、サービス停止に陥らせるこ\nとを目的とする攻撃手法 \nGDPR \n（General Data Protection \nRegulation） \n欧州経済領域（EEA）における個人データ保護やその取り扱\nいについて定めた規約。 \nEU域内にある組織だけでなく、EUと取引のある全ての組\n織が対象となる...",
    "content_length": 1183,
    "created_at": "2025-05-12T09:49:11.103670+00:00",
    "updated_at": "2025-05-12T09:49:11.103671+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=91"
  },
  "doc-ed0dad81cceaa799ecbec2130083b538": {
    "status": "pending",
    "content": "52 \n \n \n図 5-2: さまざまな生成AIを用いて悪意あるプログラムを作成してしまうイメージ（一部DALL·E 3を用いて作成） \n \n上述の例以外にも架空の判例を生成AIが作り出し、それを元に作成した資料を事実確認が取れないま\nま裁判所に提出した結果、5000ドルの罰金が科されたといった事例 [27] [28] [29]も存在します。これ\nは生成AIにおけるハルシネーションに起因して発生したインシデントであり、ユーザが生成AIの出力\nした内容を精査していれば避けることが出来た事例です。 \n2024年6月時点では、生成AIの技術は発展途上です。そのため、今後もセキュリティインシデント\n事例は増加していくことが予想されます。 \n \n5.2 リスク管理全体の概観 \n5.1に記載したセキュリティインシデント事例の影響度や発生可能性を低減するため、組織はリスク管\n理を実施する必要があります。生成AIの場合も、基本的に従来システムと同様のリスク管理を行うこと\nが重要であると考えて間違いはありません。また、生成AIシステムはクラウドなどの既存技術を利用し\nて構築されている場合も多く、既存技術に対するリスク管理手法が組織に存在すれば、それを参考とし\nて活用できます。ただし、リスクには生成AI特有のものも多く存在するため、注意深く検討する必要が\nあります。 \n \nリスク管理とは \nリスク管理は、大まかに次の4工程を伴います。 \n リスク特定 \n導入検討中の生成AIシステムにどんなリスクが存在するかを洗い出す工程。より詳細には、組\n織の所有する資産とそれに紐づくリスクを順に特定します。",
    "content_summary": "52 \n \n \n図 5-2: さまざまな生成AIを用いて悪意あるプログラムを作成してしまうイメージ（一部DALL·E 3を用いて作成） \n \n上述の例以外にも架空の判例を生成AIが作り出し、それを元に作成した資料を事実確認が取れないま\nま裁判所に提出した結果、5000ドルの罰金が科されたといった事例 [27] [28] [29]も存在します。これ\nは生成AIにおけるハルシネーションに起因して発生したインシデントであり、ユーザが生成AIの出力\nした内容を精査していれば避けることが出来た事例です。 ...",
    "content_length": 699,
    "created_at": "2025-05-12T09:49:11.103581+00:00",
    "updated_at": "2025-05-12T09:49:11.103581+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=54"
  },
  "doc-19bd16c5ff4b08b1adcc243132548e75": {
    "status": "pending",
    "content": "18 \n \n2.2.2 組織活用における実態 \n前項に記載の通り、テキスト生成AIは業務効率化を行う上で強力なツールとなり、多くの組織におい\nて導入を進める動きが始まっています。しかし組織におけるテキスト生成AIの活用において、さまざま\nな制約や過剰な期待による認識誤りがあります。このリスクはOWASP Top 10 for LLMにおいても\n「LLM09: 過度な信頼」 としてLLMに関する10大脅威の一つとして数えられています [11]。ユーザは\nその制約や実態を正しく認識することで、より安全かつ効果的な生成AI活用につながると考えます。 \n \nここでは生成AIの利用において、ユーザが感じた技術的な制約や過剰な期待による実態とのギャップ\nについて、一問一答形式でいくつかの事例を紹介します。 \n \n誤解例① 生成AIは万能であり、どのような質問に対しても回答内容に誤りはない。 \nテキスト生成AIはあくまで、保有している学習データをもとに回答を作成しています。そのため学習\nデータが古いもしくは誤りがある場合は、誤った回答を出力する可能性があります。また、ファインチュ\nーニングを利用した生成AIにおいても同様に、追加学習に使用するデータに古いデータや誤りがある場\n合は、誤った回答を出力する可能性があるため注意が必要です。 \n \n誤解例② 生成AIを利用すれば、どのようなドキュメントも作成できる。 \nテキスト生成AIを利用することで、 テキストの作成やドキュメントの作成を実施することは可能です。\nしかし、複雑な意思決定や学習データに含まれていない情報を用いた生成物の作成は困難です。 \n \n誤解例③ 生成AIを導入することですぐに業務効率化の効果が表れる。 \nテキスト生成AIを導入することで即座に業務改善につながるとは言い切れません。仮にテキスト生成\nAIを導入した場合においても、利用するユーザがどのようにテキスト生成AIを活用するかのイメージ\nを持っているか。また即座に業務に取り込んでいく柔軟な対応力を持っているか等、ユーザ側にテキス\nト生成AIを活用する下地ができていない場合、効果が思うように表れずに、業務効率化が進まない可能\n性があります。 \n \n誤解例④ 生成AIは正確な学習データを用いれば、学習データの範囲内では正確に回答できる。 \nテキスト生成AIは必ずしも正確な回答ができるとはいえません。テキスト生成AIはあくまでもユー\nザの入力したプロンプトに基づいて出力を生成します。入力プロンプト処理時に、テキスト生成AIがユ\nーザの意図と乖離した解釈をした場合、ユーザが期待する適切な出力内容は見込めません。さらに、テキ\nスト生成AIは文脈を正確に推定して回答を出力するわけではないため、出力に矛盾や非論理的内容が含\nまれるリスクもあります。また、ファインチューニングを利用したテキスト生成AIにおいても同様に、\n追加学習に使用したデータが正しかったとしても、誤った回答を出力する可能性があります。",
    "content_summary": "18 \n \n2.2.2 組織活用における実態 \n前項に記載の通り、テキスト生成AIは業務効率化を行う上で強力なツールとなり、多くの組織におい\nて導入を進める動きが始まっています。しかし組織におけるテキスト生成AIの活用において、さまざま\nな制約や過剰な期待による認識誤りがあります。このリスクはOWASP Top 10 for LLMにおいても\n「LLM09: 過度な信頼」 としてLLMに関する10大脅威の一つとして数えられています [11]。ユーザは\nその制約や実態を正しく認識することで、より安...",
    "content_length": 1267,
    "created_at": "2025-05-12T09:49:11.103493+00:00",
    "updated_at": "2025-05-12T09:49:11.103494+00:00",
    "file_path": "f55m8k0000003svn.pdf#page=20"
  },
  "[20]": {
    "status": "pending",
    "content": "18 \n \n2.2.2 組織活用における実態 \n前項に記載の通り、テキスト生成AIは業務効率化を行う上で強力なツールとなり、多くの組織におい\nて導入を進める動きが始まっています。しかし組織におけるテキスト生成AIの活用において、さまざま\nな制約や過剰な期待による認識誤りがあります。このリスクはOWASP Top 10 for LLMにおいても\n「LLM09: 過度な信頼」 としてLLMに関する10大脅威の一つとして数えられています [11]。ユーザは\nその制約や実態を正しく認識することで、より安全かつ効果的な生成AI活用につながると考えます。 \n \nここでは生成AIの利用において、ユーザが感じた技術的な制約や過剰な期待による実態とのギャップ\nについて、一問一答形式でいくつかの事例を紹介します。 \n \n誤解例① 生成AIは万能であり、どのような質問に対しても回答内容に誤りはない。 \nテキスト生成AIはあくまで、保有している学習データをもとに回答を作成しています。そのため学習\nデータが古いもしくは誤りがある場合は、誤った回答を出力する可能性があります。また、ファインチュ\nーニングを利用した生成AIにおいても同様に、追加学習に使用するデータに古いデータや誤りがある場\n合は、誤った回答を出力する可能性があるため注意が必要です。 \n \n誤解例② 生成AIを利用すれば、どのようなドキュメントも作成できる。 \nテキスト生成AIを利用することで、 テキストの作成やドキュメントの作成を実施することは可能です。\nしかし、複雑な意思決定や学習データに含まれていない情報を用いた生成物の作成は困難です。 \n \n誤解例③ 生成AIを導入することですぐに業務効率化の効果が表れる。 \nテキスト生成AIを導入することで即座に業務改善につながるとは言い切れません。仮にテキスト生成\nAIを導入した場合においても、利用するユーザがどのようにテキスト生成AIを活用するかのイメージ\nを持っているか。また即座に業務に取り込んでいく柔軟な対応力を持っているか等、ユーザ側にテキス\nト生成AIを活用する下地ができていない場合、効果が思うように表れずに、業務効率化が進まない可能\n性があります。 \n \n誤解例④ 生成AIは正確な学習データを用いれば、学習データの範囲内では正確に回答できる。 \nテキスト生成AIは必ずしも正確な回答ができるとはいえません。テキスト生成AIはあくまでもユー\nザの入力したプロンプトに基づいて出力を生成します。入力プロンプト処理時に、テキスト生成AIがユ\nーザの意図と乖離した解釈をした場合、ユーザが期待する適切な出力内容は見込めません。さらに、テキ\nスト生成AIは文脈を正確に推定して回答を出力するわけではないため、出力に矛盾や非論理的内容が含\nまれるリスクもあります。また、ファインチューニングを利用したテキスト生成AIにおいても同様に、\n追加学習に使用したデータが正しかったとしても、誤った回答を出力する可能性があります。",
    "content_summary": "18 \n \n2.2.2 組織活用における実態 \n前項に記載の通り、テキスト生成AIは業務効率化を行う上で強力なツールとなり、多くの組織におい\nて導入を進める動きが始まっています。しかし組織におけるテキスト生成AIの活用において、さまざま\nな制約や過剰な期待による認識誤りがあります。このリスクはOWASP Top 10 for LLMにおいても\n「LLM09: 過度な信頼」 としてLLMに関する10大脅威の一つとして数えられています [11]。ユーザは\nその制約や実態を正しく認識することで、より安...",
    "content_length": 1267,
    "created_at": "2025-05-12T10:04:28.769494+00:00",
    "updated_at": "2025-05-12T10:04:28.769495+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[64]": {
    "status": "pending",
    "content": "62 \n \n具体的な入口対策の例を以下に示します。 \n プロンプト文の検証 \n拒否する文字列（コードの実行などを促すものなど）を事前に登録し、プロンプト文に該当の文字\n列が含まれていないかを確認する。これにより、システムへの侵害を事前に防ぐことができる。 \n ガードレールの設置 \nガードレールを設置することで、入力されたプロンプト文が事前に設定したポリシーに違反してい\nるかLLMを使用して検証する。これにより、表現の違いによる攻撃の軽減することができる。 \n ログの保存 \nユーザが入力したプロンプト文を保存する。後に「出口対策」に記載する出力に関するログを一緒\nに保存することで、生成物に対する問題が発生した際には、確認を行うことができる。 \n \n内部対策 \n内部対策では、 バックエンドにある統合ミドルウェアやLLMと連携システムとの処理を行う場所での\n対策を考えます。図 5-5のシステム構成図における入口対策の場所を、図 5-10に緑色の盾マークで示\nします。 \n \n図 5-10: 内部対策場所のイメージ \n \n具体的な内部対策の例を以下に示します。 \n 権限管理 \n統合ミドルウェアなどのバックエンドで実行されているソフトウェアを管理者権限ではなく、必要\n最小限の権限で実行する。これにより、LLMによって生成されたコマンドによる被害を軽減するこ\nとができる。",
    "content_summary": "62 \n \n具体的な入口対策の例を以下に示します。 \n プロンプト文の検証 \n拒否する文字列（コードの実行などを促すものなど）を事前に登録し、プロンプト文に該当の文字\n列が含まれていないかを確認する。これにより、システムへの侵害を事前に防ぐことができる。 \n ガードレールの設置 \nガードレールを設置することで、入力されたプロンプト文が事前に設定したポリシーに違反してい\nるかLLMを使用して検証する。これにより、表現の違いによる攻撃の軽減することができる。 \n ログの保存 \nユーザが入力した...",
    "content_length": 592,
    "created_at": "2025-05-12T10:04:28.769600+00:00",
    "updated_at": "2025-05-12T10:04:28.769600+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[52]": {
    "status": "pending",
    "content": "50 \n \n第5章 生成 AI のリスク管理について \n本章では、組織において生成AIのセキュリティ担当者が考慮すべき事項を説明します。生成AIは、\n従来のシステムにおけるリスクに加えて、従来のシステムにはない特有のリスクを持ちます。組織は両\nリスクを特定・分析・評価し、対策を講じる必要があります。 \n \nここではまず、生成AIに関するセキュリティインシデント事例を紹介します。事例から、生成AIシ\nステムに適切なリスク対策を講じないと、 どのようなインシデントを招くのかを理解します。 その上で、\n具体的にリスク特定・分析・評価・対応の流れを説明します。特に、リスク特定では生成AIに特有のリ\nスクを、リスク対策では特有リスクの一部を取り上げ、それぞれどのような観点で対策を講じるべきな\nのか、という2点について記載していきます。 \n \n※リスク管理はセキュリティ担当者のみで実施するわけではありません。導入担当者・運用担当者も\n自身が担当する箇所におけるリスクを把握し、各担当者に連携することが重要です。 \n \n5.1 生成AIに関するセキュリティインシデント事例 \n生成AIに関連したセキュリティインシデントをご紹介します。前述の通り、生成AIが持つ特有のリ\nスクに対して十分な対策が取られない場合、過失または悪意により企業に大きな被害や損失をもたらす\n可能性があります。 \n \n サムスン電子社のChatGPTへの情報流出 [25] \n 背景 \nサムスン電子は、ChatGPTなどの生成AIに伴う機密情報の流出リスクを懸念し、従業員に\nよる使用を禁止しました。この決定の背景には、あるエンジニアが社内機密のソースコードを\nChatGPTに誤ってアップロードし、それが発覚したという事件があります。生成AIは、ユー\nザのデータをサーバに保存し、それを他のユーザに提供する可能性があるため、機密情報の漏\n洩リスクが高いと判断されたのです。また、ChatGPTはデフォルトでチャット履歴を保存し、\nモデルの訓練に使用するという設定になっていたことも要因の1つであったと考えられます。",
    "content_summary": "50 \n \n第5章 生成 AI のリスク管理について \n本章では、組織において生成AIのセキュリティ担当者が考慮すべき事項を説明します。生成AIは、\n従来のシステムにおけるリスクに加えて、従来のシステムにはない特有のリスクを持ちます。組織は両\nリスクを特定・分析・評価し、対策を講じる必要があります。 \n \nここではまず、生成AIに関するセキュリティインシデント事例を紹介します。事例から、生成AIシ\nステムに適切なリスク対策を講じないと、 どのようなインシデントを招くのかを理解します。 その上で、...",
    "content_length": 895,
    "created_at": "2025-05-12T10:04:28.769571+00:00",
    "updated_at": "2025-05-12T10:04:28.769572+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[86]": {
    "status": "pending",
    "content": "84 \n \nAIは未完成な技術であり、今後追い付ける可能性があると考えます。その一つが学習データの枯渇に\n関する問題です。AI Index Reportでは、 「信頼のおけるテキストデータは2024年に、中程度信頼のおけ\nるデータは2030年代に、画像データは2040年代までに枯渇する」可能性について触れています。つま\nり、 信頼のおけるデータが枯渇する2024年を境目にAIの性能向上が鈍化する可能性を示唆しています。\n2つ目は、よりスマートなAIの開発です。生成AIを開発するには大規模なスーパーコンピュータを使\nう必要があり、大きな電力を消費しています [59]。運用についても同様です。そこで、より小さい処理\n量で演算を行う省エネルギーなAIの開発が求められています。このスリムなAIの開発はただの投資額\nの競争ではありませんし、省エネルギーなスリムなAIの開発は世界的に成長の余地があります。スリム\nなAIが、AI開発における日本の存在感を高める契機となることを期待しています。 \n \nまた日本政府も、経済安全保障においてAIの重要性を強く認識しており、国内企業がAI開発を行う\nスーパーコンピュータの整備を後押しするなど、開発支援に力を入れていく方針を打ち出しています \n[60]。日本が日本独自の価値観に合うAIを開発していくことは、AIがより高度化し信頼を獲得した際\nに、日本独自の価値観を維持 ・保護することに繋がります。価値観の違いは発想の違いを生み出し、発想\nの違いは他国と異なるビジネスに繋がる可能性があります。そもそも世界中で多様な文化が保たれるた\nめに、各国が各々のAIを開発していくことは重要です。 \n日本企業がAIを活用したビジネスの差別化を実現するためには、AIの目的、 利用範囲の設定が重要で\nす。そもそも現在普及している生成AIは「どんなことでも解決すること」を目的とした開発を行ってい\nるため、より広く多くの学習データと高性能なスーパーコンピュータを必要とします。しかし、ビジネス\nにおいて「どんなことでも解決すること」は、必ずしも求められているわけではありません。 \nビジネスにおいて重要な要素は自社と他社と間で違いを生むこと、つまり差別化です。 \n他社との差別化を可能とするAIを開発するには、学習データの広さよりも深い専門性や秘匿性、つま\nり他社が活用できない情報が重要となります。そのため、今後ビジネスにおける生成AIの活用について\nは、 “業界や会社に特化した生成AI”が鍵を握ると考えます [61]。各企業で業界に特化した生成AIを導\n入するには、自社が所属する業界の特性を分析し、学習させる自社のデータを分類するなどの準備が必\n要です。現時点のデータを整理することは、 “将来的に業界に特化した生成AIの構築をスムーズに行う\nことに繋がる”と見込まれます。この事前準備を念入りに行うことが業界に特化したAIを用いて業務効\n率化を図るための第一歩となるため、今一度、自社が持つデータの利活用について検討をすることをお\n勧めします。",
    "content_summary": "84 \n \nAIは未完成な技術であり、今後追い付ける可能性があると考えます。その一つが学習データの枯渇に\n関する問題です。AI Index Reportでは、 「信頼のおけるテキストデータは2024年に、中程度信頼のおけ\nるデータは2030年代に、画像データは2040年代までに枯渇する」可能性について触れています。つま\nり、 信頼のおけるデータが枯渇する2024年を境目にAIの性能向上が鈍化する可能性を示唆しています。\n2つ目は、よりスマートなAIの開発です。生成AIを開発するには大規模なスーパ...",
    "content_length": 1292,
    "created_at": "2025-05-12T10:04:28.769660+00:00",
    "updated_at": "2025-05-12T10:04:28.769661+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[60]": {
    "status": "pending",
    "content": "58 \n \n今回は、例示することが目的であるため、簡易的に生成AI特有のリスクのみを考えます。 \n 「a) 資産の特定」では、今回の資産は、図 5-5の構成に存在する資産のみを考えまし\nた。 \n 「b) リスクの特定」では、OWASP T op 10 for LLMの中から選出5した5つのリスクのみ\nを考え、その5つのリスクが図 5-5の構成図内の資産に存在するかを考えました。 \nその結果が表 5-2です。 \n \n表 5-2: リスクとアセットの対応表 \n \n \n5.3.3 分析の例 \nリスク特定の結果を基に、リスク分析を行いましょう。分析は以下の手順で実施します（この手順は一\n例であり、実際の手順は組織で決定すればよいです） 。 \na) 前節で特定したリスク毎に、影響度を3ランク（High、Medium、Low）に分類。同じ\nく、リスクの発生可能性を3ランクに分類。 \nb) 上記ランクから、リスクマトリクスを作成。 \n \n手順a) 影響度と発生可能性の決定 \n影響度の決定では、そのリスクが顕在化した場合に想定される影響度や、影響範囲（連携しているシス\nテムまで影響するか等）を基準とします。今回は、次の観点でランク分けを行いました。 \n 生成AIシステム以外の組織内システムへの被害拡大の可能性 \n 組織の機密情報漏洩に繋がる可能性 \n  \n \n5 現時点で、組織としての対応優先度が比較的高いと思われるリスクを選出した。",
    "content_summary": "58 \n \n今回は、例示することが目的であるため、簡易的に生成AI特有のリスクのみを考えます。 \n 「a) 資産の特定」では、今回の資産は、図 5-5の構成に存在する資産のみを考えまし\nた。 \n 「b) リスクの特定」では、OWASP T op 10 for LLMの中から選出5した5つのリスクのみ\nを考え、その5つのリスクが図 5-5の構成図内の資産に存在するかを考えました。 \nその結果が表 5-2です。 \n \n表 5-2: リスクとアセットの対応表 \n \n \n5.3.3 分析の例 \nリス...",
    "content_length": 623,
    "created_at": "2025-05-12T10:04:28.769590+00:00",
    "updated_at": "2025-05-12T10:04:28.769591+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[51]": {
    "status": "pending",
    "content": "49 \n \nユーザから得るべき情報 \n 生成AIの導入効果（業務改善効果など） \nユーザが生成AIを利用した結果で得た業務改善効果を把握するため、 アンケートやユーザインタ\nビューを行い、具体的な効果や成果を定量的および定性的に収集することが重要です。 \n \n 改善点 \n生成AIの運用において、 ユーザが実際に使用して感じた課題をフィードバックとして受け取るこ\nとで、改善点を把握することができます。把握した改善点をシステムアップデートの際に反映させ\nることで、よりユーザが使いやすいシステムとすることができます。 \n \n 質問事項 \nユーザが生成AIを実際に使用する中で感じた使用方法や運用に関する疑問、 知りたい情報を把握\nして、必要な情報を提供することで、ユーザが生成AIをさらに活用しやすい環境を整えることがで\nきます。また、 質問の中には改善点に繋がる内容もあるため、 質問対応に留めずフィードバック情報\nとして活用するべきです。 \n \n4.4.3 評価結果を踏まえた各種改善 \n導入効果を評価した上で、評価結果から得られるフィードバックを基に各種改善を図ることで、生成\nAIをより効果的に活用することができます。主な改善に繋がる要素を以下に示します。 \n \n 利活用ガイドライン \nユーザから得たフィードバックを基に内容を更新することで、利便性と安全性を考慮した利活用\nガイドラインを整備することができます。 \n \n 運用担当者の実施項目 \n改善点や質問事項を参考に、上記で紹介した教育内容やメンテナンスの項目などを見直すことで、\n実態に即した運用ができます。実務事例に則った運用手順やルールを明確にすることで、さらなる\n有効活用に繋げることが期待できます。 \n \n 生成AIのシステム改善 \nシステム更新やアップデートの際に、フィードバック内容を考慮した内容を盛り込むことで、生\n成AIのシステム改善を行い、導入効果を高めることが期待できます。 \n \n以上のように、 運用担当者とユーザの間で密に情報交換を行い、 得られた情報を適切に反映させること\nで、生成AIの運用を効果的に改善していくことが可能となります。改善への取り組みは一過性の取り組\nみにせず、継続的に実施することで、生成AIの導入効果の最大化が期待できます。",
    "content_summary": "49 \n \nユーザから得るべき情報 \n 生成AIの導入効果（業務改善効果など） \nユーザが生成AIを利用した結果で得た業務改善効果を把握するため、 アンケートやユーザインタ\nビューを行い、具体的な効果や成果を定量的および定性的に収集することが重要です。 \n \n 改善点 \n生成AIの運用において、 ユーザが実際に使用して感じた課題をフィードバックとして受け取るこ\nとで、改善点を把握することができます。把握した改善点をシステムアップデートの際に反映させ\nることで、よりユーザが使いやすいシステムと...",
    "content_length": 975,
    "created_at": "2025-05-12T10:04:28.769569+00:00",
    "updated_at": "2025-05-12T10:04:28.769570+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[42]": {
    "status": "pending",
    "content": "40 \n \n 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプト（図 \n4-4） \n \n図 4-4: 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプトの例 \n \nまた、Anthropic社やGoogle社、OpenAI社などが公式ドキュメントとして公開している、用途に\n応じたプロンプトのサンプルを参考にすることも、ユーザが望む内容の出力に有効な手段となります。 \n[20] \n \n以上のようなプロンプトのサンプルや参考サイトを利活用ガイドラインに記載することで、ユーザ\nは効果的なプロンプトの書き方を把握し、自身の業務に活用できるプロンプトの書き方の参考とする\nことができます。 \n \n 入力制限に関する項目 \n生成AIに入力したプロンプトが学習データとして利用されると、第三者によるプロンプトの生成物\nにそれらの情報が含まれる可能性があります。 以下に示す情報は、 ユーザによる入力を制限することが\n推奨されます。 \n 著作権保護情報 \n生成物に著作権で保護された内容と類似した内容が含まれる可能性があります。そのような生\n成物の利用は著作権侵害となり、法的トラブルや組織の信用失墜を引き起こします。 \n 個人情報 \n氏名や住所、 電話番号といった情報が学習し生成されると、 プライバシーの侵害に繋がります。 \n 組織の機密情報 \n組織の内部文書や秘密保持契約を締結した情報がプロンプトに含まれると、組織の機密情報が\n漏洩するリスクがあります。",
    "content_summary": "40 \n \n 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプト（図 \n4-4） \n \n図 4-4: 「要約してほしい文章」と「文章の長さ」と「箇条書きの個数」の要素を含むプロンプトの例 \n \nまた、Anthropic社やGoogle社、OpenAI社などが公式ドキュメントとして公開している、用途に\n応じたプロンプトのサンプルを参考にすることも、ユーザが望む内容の出力に有効な手段となります。 \n[20] \n \n以上のようなプロンプトのサンプルや参考サイトを利活用ガ...",
    "content_length": 660,
    "created_at": "2025-05-12T10:04:28.769547+00:00",
    "updated_at": "2025-05-12T10:04:28.769547+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[4]": {
    "status": "pending",
    "content": "3.2.1 実現可能性の検討 ........................................................................................... 28 \n3.2.2 目標の設定 ...................................................................................................... 29 \n3.2.3 利害関係者の整理 ........................................................................................... 29 \n3.2.4 リスクアセスメント ....................................................................................... 30 \n3.2.5 システムの選定............................................................................................... 30 \n3.2.6 回答精度向上における選択肢 ......................................................................... 34 \n3.3 設計・開発 ............................................................................................................. 34 \n3.3.1 導入ベンダへのフィードバック ..................................................................... 34 \n3.3.2 RAG利用に関する留意点 .............................................................................. 35 \n3.4 テスト・実装 .......................................................................................................... 35 \n3.4.1 システムテスト............................................................................................... 35 \n3.4.2 生成AIの性能評価 ......................................................................................... 36 \n3.4.3 利活用ガイドラインの策定 ............................................................................ 36 \n第4章 生成AIの運用について ......................................................................................... 37 \n4.1 利活用ガイドラインの策定 .................................................................................... 37 \n4.1.1 利活用ガイドライン策定の重要性 ................................................................. 37 \n4.1.2 利活用ガイドラインに記載すべき項目 .......................................................... 38 \n4.2 ユーザへの教育 ...................................................................................................... 42 \n4.2.1 教育によって期待される効果 ......................................................................... 42 \n4.2.2 ユーザへの教育方法 ....................................................................................... 43 \n4.3 生成AIの更新管理 ................................................................................................ 43 \n4.3.1 透明性の確保と維持 ....................................................................................... 43 \n4.3.2 RAGを利用する場合の注意 ........................................................................... 46 \n4.4 評価とフィードバック ........................................................................................... 46 \n4.4.1 評価項目の策定............................................................................................... 46 \n4.4.2 ユーザとの情報共有 ....................................................................................... 48 \n4.4.3 評価結果を踏まえた各種改善 ......................................................................... 49 \n第5章 生成AIのリスク管理について .............................................................................. 50 \n5.1 生成AIに関するセキュリティインシデント事例 ................................................. 50 \n5.2 リスク管理全体の概観 ........................................................................................... 52 \n5.3 生成AIにおけるリスクアセスメントの例 ............................................................ 55 \n5.3.1 特定・分析に向けた一般的な生成AIリスクの把握 ...................................... 55 \n5.3.2 特定の例 ......................................................................................................... 57 \n5.3.3 分析の例 ......................................................................................................... 58 \n5.3.4 評価の例 ......................................................................................................... 60 \n5.4 リスク対応 ............................................................................................................. 60",
    "content_summary": "3.2.1 実現可能性の検討 ........................................................................................... 28 \n3.2.2 目標の設定 ...................................................................................................... 29 \n3.2.3 利害関係者の整理 ........",
    "content_length": 3840,
    "created_at": "2025-05-12T10:04:28.769454+00:00",
    "updated_at": "2025-05-12T10:04:28.769455+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[69]": {
    "status": "pending",
    "content": "67 \n \n5.5 実機検証 \n5.5.1 ガードレールの実装 \n本ガイドラインではガードレール6の実装として、Apache License, Version 2.0.として公開されている\nNVIDIAのNeMo GuardrailsというOSSで検証しています。 \nまた、検証に使用したオンプレ環境を表 5-4に示します。 \n \n表 5-4: オンプレ検証環境の構成の一部 \n \n \n本ツールは、特定の話題に応答しないように制限する機能や敵対的プロンプトを防ぐことができます。\n設定ファイルに制限したい事象と関連がある文字列やその応答文、入出力ポリシーを設定することがで\nきます。 \n  \n \n6 ユーザの入力やLLMの出力を評価しフィルタリングする手法。有害なコンテンツ（特定の話題を制\n限する）や敵対的なプロンプト文を制限することができる。",
    "content_summary": "67 \n \n5.5 実機検証 \n5.5.1 ガードレールの実装 \n本ガイドラインではガードレール6の実装として、Apache License, Version 2.0.として公開されている\nNVIDIAのNeMo GuardrailsというOSSで検証しています。 \nまた、検証に使用したオンプレ環境を表 5-4に示します。 \n \n表 5-4: オンプレ検証環境の構成の一部 \n \n \n本ツールは、特定の話題に応答しないように制限する機能や敵対的プロンプトを防ぐことができます。\n設定ファイルに制限し...",
    "content_length": 373,
    "created_at": "2025-05-12T10:04:28.769612+00:00",
    "updated_at": "2025-05-12T10:04:28.769612+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[35]": {
    "status": "pending",
    "content": "33 \n \nしかし、海外リージョンを利用する場合、データベースが海外に設置されていることから、デ\nータの格納が安全保障貿易管理（輸出管理）の対象となる可能性があるため注意が必要です。ま\nた、セキュリティについても、サービス提供側で実施されている対策は必ずしも完璧なものでは\nないという点にも注意が必要です。利用するサービスや設定によっては自社のデータが外部に漏\n洩するリスクも存在するため、利用する際には適切なセキュリティ設定が求められます。 \n \nサービスの例： \n- Amazon Bedrock （AWS） \n- Azure OpenAI （Azure） \n- Vertex AI （GCP） \n \n SaaS型 \nSaaS型は、 各社が構築した生成AIのサービスをネットワーク経由で利用する方式のことです。\nSaaS型のサービスを利用することで、組織への生成AI導入や運用にかかる手間を大幅に軽減で\nきます。生成AIのサービスをインターネット経由で即座に利用開始でき、サービスの管理やセキ\nュリティ対策も提供者側が行うため、ユーザ側の管理負荷を抑えながら、常に最新の機能を利用\nできます。一方、SaaS型のサービスは標準化された機能セットを提供するため、一般的には自社\nのニーズに合わせたカスタマイズが難しいとされています。また、利用するサービスやその設定\n内容によっては入出力データがサービス提供者側の生成AIに学習される可能性があり、PaaS型\nのセキュリティリスクやリージョンの問題と併せて注意が必要です。 \n \nサービスの例： \n- ChatGPT Enterprise （Open AI） \n- Claude 3 Opus（Anthropic） \n- Copilot for Microsoft 365 （Microsoft）  \n- Gemini Advanced（Google） \n \n ハイブリッド型 \nハイブリッド型とは、AI提供者が提供しているAPIを利用して、組織に生成AIシステムを導入する\n方法です。自社のシステムからAPIを経由して生成AI機能を呼び出して利用することで、自社システム\nとの連携が容易となる点が特徴です。しかし、クラウド型と同様、入出力データが外部サーバに保存され\nる場合があるなどのセキュリティリスクもあり、利用する際には適切なセキュリティ設定が必要です。\n利用するモデルやAPIごとにサービスの仕様や制限をしっかりと確認することが重要です。",
    "content_summary": "33 \n \nしかし、海外リージョンを利用する場合、データベースが海外に設置されていることから、デ\nータの格納が安全保障貿易管理（輸出管理）の対象となる可能性があるため注意が必要です。ま\nた、セキュリティについても、サービス提供側で実施されている対策は必ずしも完璧なものでは\nないという点にも注意が必要です。利用するサービスや設定によっては自社のデータが外部に漏\n洩するリスクも存在するため、利用する際には適切なセキュリティ設定が求められます。 \n \nサービスの例： \n- Amazon Bedrock...",
    "content_length": 1050,
    "created_at": "2025-05-12T10:04:28.769530+00:00",
    "updated_at": "2025-05-12T10:04:28.769531+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[76]": {
    "status": "pending",
    "content": "74 \n \n6.1.4 RAGを業務に活用する上での課題 \n ヒアリング内容 \nRAG （Retrieval-Augmented Generation） を既に導入済み、 または現在導入を検討中の組織に対し、\n「どのような運用をしているのか」 、 「RAGの導入に伴い新たに発生したリスクや課題は何か」につ\nいてヒアリングを実施しました。 \n \n ヒアリング結果 \nRAGはまだ比較的新しい技術であるため、既に導入が完了している組織は一部に限られていまし\nた。運用体系としては、RAG導入時から全社のデータをベクトルDBに格納するわけではなく、部\n門単位やプロジェクト単位で利用申請を行い、ドキュメントを単位毎に領域を分けてベクトルDB\nに格納し、その中で検索を実行するという運用を行う組織が多く見られました。 \nまた、現在はRAG未導入の組織でも、導入検討が進められており、今後のRAG活用は増加して\nいくと感じました。 \n一方、RAGを活用する組織の課題としては、回答精度に関するものが多く挙げられました。本課\n題においてはシステムに関する課題とユーザに関する課題の2つが存在すると考えられます。 \nまずシステムに関する課題では、RAGという技術は、第2章にも記載したように、ベクトルDB\nに格納したドキュメントを元に回答を作成するため、通常の生成AIよりも、特定分野における回答\n精度を向上させることができます。しかし、第4章にも記載したように、RAGを活用したとしても\nハルシネーションのリスクをなくすことはできません。そのため、RAGを活用したシステムであっ\nたとしてもユーザが求める回答を得ることができず、回答精度を高める手法を模索している段階と\nいう印象を受けました。 \nユーザに関する課題としては、ユーザがRAG活用に期待する効果と、現実的にRAGでできるこ\nとの間にある認識のギャップが大きいことが挙げられます。このギャップを埋めるため、各組織は\nガイドラインや定期的な情報周知で対応しようとしていましたが、このギャップを完全に埋めるこ\nとは難しい状況にあるようです。 \n \n6.2 生成AIシステム導入に際した懸念事項 \nヒアリングでは、どの組織も共通して生成AI導入後に2つの懸念事項を抱えていました。1つ目はサ\nービス利用における既存の規程やガイドラインとの兼ね合い、2つ目は導入したシステムの利用率の低さ\nです。以下でそれぞれの懸念について詳しく解説します。",
    "content_summary": "74 \n \n6.1.4 RAGを業務に活用する上での課題 \n ヒアリング内容 \nRAG （Retrieval-Augmented Generation） を既に導入済み、 または現在導入を検討中の組織に対し、\n「どのような運用をしているのか」 、 「RAGの導入に伴い新たに発生したリスクや課題は何か」につ\nいてヒアリングを実施しました。 \n \n ヒアリング結果 \nRAGはまだ比較的新しい技術であるため、既に導入が完了している組織は一部に限られていまし\nた。運用体系としては、RAG導入時から全...",
    "content_length": 1044,
    "created_at": "2025-05-12T10:04:28.769636+00:00",
    "updated_at": "2025-05-12T10:04:28.769637+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[13]": {
    "status": "pending",
    "content": "11 \n \n1.5 本書の活用例 \n本書の構成は以下の通りとなっています。 \n第2章：セキュアな生成AIを導入・運用を行っていくために読者が持っておくべき基礎的な知識 \n第3～5章：それぞれの担当者（導入担当者、運用担当者、セキュリティ担当者）ごとの考慮事項 \n第6章：現在の日本企業における生成AI利活用の事例と実態調査結果 \n第7章：国内外のAIの法規制や今後の動向について \n \n本書を活用することで以下のような効果を見込むことできます（以下の例はあくまで一例です） 。 \n 第2章 \n 生成AIとはどのようなものか理解することができる \n 生成AIの回答精度向上のための手法を理解することができる \n 生成AIの組織的な活用事例を知ることができる \n 第3章 \n 生成AIの組織における製品選定の基準を理解することができる \n どのような導入プロセスを経るべきなのか理解することができる \n 第4章 \n 生成AIの組織の利活用におけるガイドラインに記載する内容を理解することができる \n 生成AIの運用における懸念事項や考慮事項を理解することができる \n 第5章 \n OWASP1が公表しているOWASP Top 10 for LLM（OWASPが発表したLLMに関する10大脅\n威）について理解することができる \n 生成AIにおけるセキュリティリスクアセスメント手法について理解することができる \n 生成AIにおける具体的なセキュリティ対応策について理解することができる \n 第6章 \n 生成AIにおける国内組織の活用の実態について知ることができる \n 実際に組織が直面した課題やその解決法を知ることができる \n 第7章 \n 米国の大統領令やEUのAI Actなど、海外のAI法案についての概要を知ることができる \n 日本の現状と各国の動向を考慮した日本企業が取るべき対応について私見を述べます \n  \n \n1 Open Worldwide Application Security Project。ソフトウェアのセキュリティを改善するオープンコミ\nュニティ。",
    "content_summary": "11 \n \n1.5 本書の活用例 \n本書の構成は以下の通りとなっています。 \n第2章：セキュアな生成AIを導入・運用を行っていくために読者が持っておくべき基礎的な知識 \n第3～5章：それぞれの担当者（導入担当者、運用担当者、セキュリティ担当者）ごとの考慮事項 \n第6章：現在の日本企業における生成AI利活用の事例と実態調査結果 \n第7章：国内外のAIの法規制や今後の動向について \n \n本書を活用することで以下のような効果を見込むことできます（以下の例はあくまで一例です） 。 \n 第2章 \n 生...",
    "content_length": 905,
    "created_at": "2025-05-12T10:04:28.769478+00:00",
    "updated_at": "2025-05-12T10:04:28.769478+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[101]": {
    "status": "pending",
    "content": "99 \n \n2024-06]. \n[56] T. M. Stryker, “人工超知能とは”, 2023-12-18, https://www.ibm.com/jp-ja/topics/artiﬁcial-\nsuperintelligence. [アクセス日: 2024-06]. \n[57] Amazon Web Services, “AGI とは何ですか?”, https://aws.amazon.com/jp/what-is/artiﬁcial-\ngeneral-intelligence/. [アクセス日: 2024-06]. \n[58] 日経XTECH, “人間同等以上の処理が可能な汎用人工知能「AGI」 、専門家の多くは登場に肯定\n的”, 2024-01-22, https://xtech.nikkei.com/atcl/nxt/column/18/01679/113000143/. [アクセス\n日: 2024-06]. \n[59] 日本放送協会, “生成AI普及で電力需要に異変？”, 2024-05-21, \nhttps://www3.nhk.or.jp/news/html/20240521/k10014455901000.html. [アクセス日: 2024-06]. \n[60] 日本放送協会, “AI開発のスーパーコンピューター 国内整備に最大725億円補助へ”, 2024-04-\n19, https://www3.nhk.or.jp/news/html/20240419/k10014426711000.html. [アクセス日: 2024-6]. \n[61] 株式会社マクニカ, “ビジネスに最適なAI～汎用AIを超える垂直型AIとは～”, 2021-12-21, \nhttps://www.macnica.co.jp/business/ai/blog/142033/. [アクセス日: 2024-06]. \n[62] 三部 裕幸, “EUのAI規則案に対する欧州での反応の続報と米国の動向について”, 2022-04-27, \nhttps://www.soumu.go.jp/main_content/000811790.pdf. [アクセス日: 2024-06].",
    "content_summary": "99 \n \n2024-06]. \n[56] T. M. Stryker, “人工超知能とは”, 2023-12-18, https://www.ibm.com/jp-ja/topics/artiﬁcial-\nsuperintelligence. [アクセス日: 2024-06]. \n[57] Amazon Web Services, “AGI とは何ですか?”, https://aws.amazon.com/jp/what-is/artiﬁcial-\ngeneral-intelligence/....",
    "content_length": 953,
    "created_at": "2025-05-12T10:04:28.769701+00:00",
    "updated_at": "2025-05-12T10:04:28.769702+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[89]": {
    "status": "pending",
    "content": "87 \n \n8.2 謝辞 \n本書の作成にあたり、ヒアリングにご協力いただきました自治体、企業の皆様には多大なるご支援・ご\n尽力を賜りました。この場を借りて心より御礼申し上げます。 \n \nまた、独立行政法人情報処理推進機構 産業サイバーセキュリティセンター 中核人材育成プログラム\n講師の、満永 拓邦先生、門林 雄基先生には、本書の元となるプロジェクトのメンター・講師として、ご\n指導・ご助言、ご支援を賜りました。改めて御礼申し上げます。加えて、本プロジェクトにご協力いただ\nいた、東洋大学学部生のお二人にも感謝いたします。 \n \nなお、有識者として、三井物産セキュアディレクション株式会社の高江洲 勲様にも有益なご助言をい\nただきました。改めて御礼申し上げます。 \n \nそして、 本書の作成や本プロジェクトを共に実施した、 以下メンバーの皆様にも感謝を伝えたいと思い\nます。 \n \n \n \n<生成AIにおけるセキュリティリスクと対策プロジェクトメンバー> \n（総勢13名） \n【リーダー】 \n辻村 凱 \n \n【サブリーダー】 \n櫻井 健太 下川部 一真 長谷川 奨 \n \n【メンバー】 \n井上 裕斗 斎藤 雅俊 安田 卓磨 \n兼子 翔伍 高橋 直人 山崎 禎章 \n小松 文彦  簱野 公嗣 横道 太志",
    "content_summary": "87 \n \n8.2 謝辞 \n本書の作成にあたり、ヒアリングにご協力いただきました自治体、企業の皆様には多大なるご支援・ご\n尽力を賜りました。この場を借りて心より御礼申し上げます。 \n \nまた、独立行政法人情報処理推進機構 産業サイバーセキュリティセンター 中核人材育成プログラム\n講師の、満永 拓邦先生、門林 雄基先生には、本書の元となるプロジェクトのメンター・講師として、ご\n指導・ご助言、ご支援を賜りました。改めて御礼申し上げます。加えて、本プロジェクトにご協力いただ\nいた、東洋大学学部生のお二...",
    "content_length": 550,
    "created_at": "2025-05-12T10:04:28.769673+00:00",
    "updated_at": "2025-05-12T10:04:28.769674+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[41]": {
    "status": "pending",
    "content": "39 \n \nプロンプトには以下の4つの要素が含まれています。 \n 命令： 「回答する」 「分類する」 「要約する」など生成AIに実行してもらうタスク \n 文脈： 「話題」 「目的」 「複数の例」など生成AIが正確にタスクを実行するための追加の情報 \n 入力： 「回答してほしい質問」 「要約してほしい文章」などタスクを実行する対象 \n 出力： 「文章の長さ」 「箇条書きの個数」 「プログラム形式」など回答の形式の指示 \n \n必ずしも4 つの要素全てが必要というわけではありませんが、これらを具体的に指示し適切に組み\n合わせることで、生成AIは目的の出力を生成しやすくなります。これをプロンプトエンジニアリング\nと呼びます [19]。以下に、プロンプトエンジニアリングの例を示します。 \n \n 「文章の長さ」と「回答してほしい質問」の要素を含むプロンプト（図 4-3） \n \n図 4-3: 「文章の長さ」と「回答してほしい質問」の要素を含むプロンプトの例",
    "content_summary": "39 \n \nプロンプトには以下の4つの要素が含まれています。 \n 命令： 「回答する」 「分類する」 「要約する」など生成AIに実行してもらうタスク \n 文脈： 「話題」 「目的」 「複数の例」など生成AIが正確にタスクを実行するための追加の情報 \n 入力： 「回答してほしい質問」 「要約してほしい文章」などタスクを実行する対象 \n 出力： 「文章の長さ」 「箇条書きの個数」 「プログラム形式」など回答の形式の指示 \n \n必ずしも4 つの要素全てが必要というわけではありませんが、これらを...",
    "content_length": 432,
    "created_at": "2025-05-12T10:04:28.769544+00:00",
    "updated_at": "2025-05-12T10:04:28.769545+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[16]": {
    "status": "pending",
    "content": "14 \n \n2.1.2 テキスト生成AIと大規模言語モデル（LLM） \n生成AIでは、テキスト、画像、動画、音声など、出力したいコンテンツによって異なるモデルが使用\nされます。ここでは、本書のスコープであるテキスト生成AIに関して少し掘り下げて紹介します。 \n \nテキスト生成AIは自然言語処理技術を利用した文章生成を行います。自然言語処理を行うモデルとし\nて、近年では、大規模言語モデル（Large Language Models、以下LLMと呼称）が使用されます。 \n言語モデルとは文章や単語の出現確率をモデル化したもので、直前の文章や単語に続く確率が最も高\nい単語を出力することができ、テキスト生成に利用されます。その中でもLLMは、大量のテキストデー\nタを学習した大規模な言語モデルを指します。LLMは従来の言語モデルと比較すると、 「計算量（コンピ\nュータが処理可能な計算量） 」 「データ量（入力した文章データの情報量） 」 「パラメータ数（ディープラー\nニング特有の確率演算を行うために必要な係数の数） 」の3点が大幅に増加し、精度が格段に向上してい\nます。 そのため単なるテキスト生成だけでなく、 チャットボットや文章要約などにも応用されます。2024\n年6月時点の代表的なLLMには、Anthropic社の 「Claude3」 、Google社の 「Gemini」 、Meta社の 「Llama3」 、\nOpenAI社の 「GPT-4」 等があります。 端的に言えば、 テキスト生成AIは広範なカテゴリーであり、LLM\nはテキスト生成AIを構成する要素の一つであると言えます。 \n \n \n図 2-2: テキスト生成AIとLLMの位置付け",
    "content_summary": "14 \n \n2.1.2 テキスト生成AIと大規模言語モデル（LLM） \n生成AIでは、テキスト、画像、動画、音声など、出力したいコンテンツによって異なるモデルが使用\nされます。ここでは、本書のスコープであるテキスト生成AIに関して少し掘り下げて紹介します。 \n \nテキスト生成AIは自然言語処理技術を利用した文章生成を行います。自然言語処理を行うモデルとし\nて、近年では、大規模言語モデル（Large Language Models、以下LLMと呼称）が使用されます。 \n言語モデルとは文章や単語の出...",
    "content_length": 727,
    "created_at": "2025-05-12T10:04:28.769485+00:00",
    "updated_at": "2025-05-12T10:04:28.769485+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[32]": {
    "status": "pending",
    "content": "30 \n \n 経営層 \n経営層が生成AIの導入を推進する強い意向を示すことは、組織全体に生成AI活用の重要性を広める\nことや生成AIを積極的に使う文化の構築に大きく影響します。また既存の組織内のシステムに対する影\n響の発生も考慮されるため、生成AIの積極的な導入には経営層の協力は不可欠であると考えます。 \n \n 現場担当者 \n生成AIの導入および運用において、現場担当者の意見は重要です。導入時にはユーザが生成AIに求\nめるニーズやRAG、 ファインチューニング時の学習データの調整、 運用においては導入された生成AIの\n使用感や改善点のフィードバックなど、継続運用において現場担当者の協力は重要です。 \n \n本項で述べた関係者は、あくまで一例となります。実際の要件定義時には、各担当者も含む関係者の整\n理および責任範囲の明確化の協議が重要です。 \n \n3.2.4 リスクアセスメント \n導入時にはリスクアセスメントとして、リスクの特定・分析・評価を実施することが重要です。リスク\nアセスメントを実施する際には、セキュリティ担当者も含めて検討を進める必要があり、主体とする部\n署は組織によって異なります。本書ではセキュリティ担当者が実施することとします。具体的なリスク\n管理について詳細は5.2を参照してください。 \n \n3.2.5 システムの選定 \n生成AIにおけるモデル利用方法の選定 \n生成AIの導入方法は幅広く、一般ユーザ向けにAI提供者が提供するサービスを活用する方法や、独\n自モデルの開発、既存のモデルをトレーニングして活用する方法など多岐にわたります。そのため、利用\n方法に適した導入方法を選定することが重要です。",
    "content_summary": "30 \n \n 経営層 \n経営層が生成AIの導入を推進する強い意向を示すことは、組織全体に生成AI活用の重要性を広める\nことや生成AIを積極的に使う文化の構築に大きく影響します。また既存の組織内のシステムに対する影\n響の発生も考慮されるため、生成AIの積極的な導入には経営層の協力は不可欠であると考えます。 \n \n 現場担当者 \n生成AIの導入および運用において、現場担当者の意見は重要です。導入時にはユーザが生成AIに求\nめるニーズやRAG、 ファインチューニング時の学習データの調整、 運用にお...",
    "content_length": 717,
    "created_at": "2025-05-12T10:04:28.769523+00:00",
    "updated_at": "2025-05-12T10:04:28.769523+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[77]": {
    "status": "pending",
    "content": "75 \n \n 既存の規程やガイドラインとの兼ね合い \n組織内にはさまざまな規定やポリシーが存在しますが、ヒアリングで、特に生成AIシステムに関\n連が深いものとして挙げられたのは、クラウドにおける規定・ポリシー（以降、クラウド規定と呼\n称） 、輸出管理規定などです。組織によってはそのほかにも、情報セキュリティ規定や社内システム\n規定等、さまざまな規定・ポリシーが関連する可能性があります。ゆえに、生成AI導入 ・運用者に\nとって、関連する担当部門（例えば、IT部門、法務部門、セキュリティ部門）との連携が不可欠に\nなります。連携をすれば、生成AIシステムの導入が円滑に進むとともに、コンプライアンス違反の\nリスクを最小限に抑えられます。特にクラウド規定に関しては、組織の生成AIシステムとしてクラ\nウドサービス（主にPaaS）を活用したものが主流であることから、サービス選定時にSLAやデータ\n保管場所等を追加で考慮する必要があったという声が多く存在しました。 \n生成AIシステムはAIを活用した特別なサービスだと思われがちですが、 生成AIの社内システム\n導入は、他のクラウドを活用した社内システムの導入と大差ないことに注意しましょう。 \n \n システム利用率の低さ \n生成AIシステムや他のクラウドベースの社内システムを導入した際に、利用率が低いという課題\nはしばしば発生します。このような課題の発生原因としては以下が考えられます。 \n ユーザの教育不足 \nユーザが新しいシステムの使い方を十分に理解していない など \n \n システムが使いづらい \nWeb UIが直感的でない、操作が複雑である など \n \n 必要性の認識不足 \nユーザが新しいシステムの導入目的や利点を理解していない など \n \n 既存の業務プロセスとの不整合 \n新しいシステムが既存の業務プロセスと十分に統合されておらず、利用用途がわからない \nなど \n \n 技術的な問題 \nシステムのパフォーマンスが低い、頻繁にエラーが発生するなどの技術的な問題がある な\nど \n \n セキュリティの不安 \nユーザ自身が情報漏洩をしてしまうといったリスクを抱えるため、利用をためらう など \n \n上述の原因を解決するためにそれぞれの組織ではさまざまなアプローチをとられていました。こ\nこではその中でも効果的であると考えられる対策例についてご紹介します。",
    "content_summary": "75 \n \n 既存の規程やガイドラインとの兼ね合い \n組織内にはさまざまな規定やポリシーが存在しますが、ヒアリングで、特に生成AIシステムに関\n連が深いものとして挙げられたのは、クラウドにおける規定・ポリシー（以降、クラウド規定と呼\n称） 、輸出管理規定などです。組織によってはそのほかにも、情報セキュリティ規定や社内システム\n規定等、さまざまな規定・ポリシーが関連する可能性があります。ゆえに、生成AI導入 ・運用者に\nとって、関連する担当部門（例えば、IT部門、法務部門、セキュリティ部門）との...",
    "content_length": 1014,
    "created_at": "2025-05-12T10:04:28.769639+00:00",
    "updated_at": "2025-05-12T10:04:28.769639+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[21]": {
    "status": "pending",
    "content": "19 \n \nまた、 テキスト生成AIの回答精度向上を目的にRAGを導入した場合にも同様にギャップが存在します。 \n \n誤解例⑤ RAGを利用するとどのような質問に対しても正しく回答できる \nRAGを利用して回答精度が向上するのはベクトルDBに格納された情報についてのみであり、ベクト\nルDBに格納されていない情報については回答精度が向上しません。そのため、RAGを利用したテキス\nト生成AIをユーザに活用してもらう場合には、どのような情報について回答できるのか周知しておく必\n要があります。 \n \n誤解例⑥ ベクトルDBに格納した情報であれば正確に回答できる \n必ずしも正確な回答ができるとはいえません。RAGを使用していたとしてもテキスト生成AIの根幹\nであるLLMによる回答を生成する仕組みは変わらないため、 前述したとおり誤った回答を出力する可能\n性があります。 \n \n上記の事例以外にも多くの制約や過剰な期待による認識誤りがあると考えられ、関連する学術論文も\n発表されています [12]。そのためテキスト生成AIの効果的な活用には、ユーザがテキスト生成AIに対\nして認識を誤りやすい事象について十分に理解しておく必要があります。テキスト生成AIは強力なツー\nルではありますが、決して万能ではないため、利用には人間の判断と組み合わせることが重要です。ユー\nザは出力内容を単純に鵜呑みにせず、常に批判的に検証した上で利用すべきです。 \n \n2.3 テキスト生成AIの組織導入に向けて \n2.3.1 テキスト生成AI導入と課題 \nテキスト生成AIを組織に導入する上では、課題やリスクを正しく認識し対策を講じることがポイント\nとなります。本項では、1.1.4でも触れた組織が感じているさまざまな課題を改めて整理していきます。 \n組織が感じている課題には、利用時のプロンプトエンジニアリングに関するサポートやユーザの過剰\nな期待、機密情報の流出や意図しない著作権侵害などのリスクも含まれています。 \n課題やリスクへの対応に関する1つの指針として、NISTのAI RMFでは信頼できるAIシステムの特\n徴という形で提唱されています。この指針を認識した上で、組織導入におけるテキスト生成AIの考慮す\nべきリスクについて述べていきます。",
    "content_summary": "19 \n \nまた、 テキスト生成AIの回答精度向上を目的にRAGを導入した場合にも同様にギャップが存在します。 \n \n誤解例⑤ RAGを利用するとどのような質問に対しても正しく回答できる \nRAGを利用して回答精度が向上するのはベクトルDBに格納された情報についてのみであり、ベクト\nルDBに格納されていない情報については回答精度が向上しません。そのため、RAGを利用したテキス\nト生成AIをユーザに活用してもらう場合には、どのような情報について回答できるのか周知しておく必\n要があります。 \n \n誤...",
    "content_length": 964,
    "created_at": "2025-05-12T10:04:28.769497+00:00",
    "updated_at": "2025-05-12T10:04:28.769497+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[2]": {
    "status": "pending",
    "content": "",
    "content_summary": "",
    "content_length": 0,
    "created_at": "2025-05-12T10:04:28.769446+00:00",
    "updated_at": "2025-05-12T10:04:28.769447+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[26]": {
    "status": "pending",
    "content": "24 \n \n2.4.2 導入・運用の流れ（プロセス） \n本書における「生成AIの組織導入・運用プロセス」では、構想策定から改善までをPDCAサイクル\nの1サイクルと定めています。例えば、図 2-7のように1周目は「スモールスタート」 、2周目は「本\n番導入」 、3周目以降はRAG導入のような 「機能拡張」等、サイクルを何度も回し、改善を重ねる必要\nがあります。 \n \n \n図 2-7: 生成AIの導入・運用プロセス \n \nまた、この1サイクルは図 2-8に示す通り6つのフェーズとしても定めています。各フェーズでの実施\n事項は下記の通りです。 \n \n \n図 2-8: 生成AI導入・運用プロセスにおける1サイクルの内容 \n \nPlan \n 構想策定 \n生成AIの導入目的やスコープ（対象業務・対象ユーザ）を定めます。 \n \n 要件定義 \n策定した目的に基づいて導入目標を定め、生成AIシステムに必要な機能や条件を定義します。また、\n利用ポリシーとユーザへの教育内容、生成AIを導入する上で生じるリスクについて検討します。",
    "content_summary": "24 \n \n2.4.2 導入・運用の流れ（プロセス） \n本書における「生成AIの組織導入・運用プロセス」では、構想策定から改善までをPDCAサイクル\nの1サイクルと定めています。例えば、図 2-7のように1周目は「スモールスタート」 、2周目は「本\n番導入」 、3周目以降はRAG導入のような 「機能拡張」等、サイクルを何度も回し、改善を重ねる必要\nがあります。 \n \n \n図 2-7: 生成AIの導入・運用プロセス \n \nまた、この1サイクルは図 2-8に示す通り6つのフェーズとしても定めています...",
    "content_length": 463,
    "created_at": "2025-05-12T10:04:28.769508+00:00",
    "updated_at": "2025-05-12T10:04:28.769509+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[6]": {
    "status": "pending",
    "content": "4 \n \n第1章 はじめに \n1.1 背景 \n1.1.1 AIの組織での普及について \n近年、AI （Artiﬁcial Intelligence、人工知能）は目覚ましい速度で普及が進んでいます。AIの市場規模\n（売上高）は加速度的な成長が予測され、世界市場では、2021年を基準に、2025年には約4.4倍、2030\n年には約19.3倍に成長する見込みであることが公表されています（図 1-1） [1]。また、国内において\nも、国内AIシステム市場支出額の予測も海外市場と同等速度での成長が予想されており、2022年から\n2027年までで約2.5倍まで成長することが見込まれています（図 1-2） [2]。 \n \n人工知能（AI）はさまざまな業界に革命をもたらし、昨今の市場で競争力を維持したい企業にとって、\nもはや不可欠なツールとなりつつあります。技術の進歩により、AIは組織に幅広いメリットと成長機会\nをもたらします。業務においては、タスクの自動化やデータに基づいた意思決定のサポート、リアルタイ\nムデータ分析などを通じて企業の生産性向上に寄与し、市場競争上の優位性をもたらします。AIを導入\nしない企業は、AIを活用している企業と比較して作業効率の向上が見込めないことなどによる競争力の\n低下が懸念されます。そのため、今後、国内企業がAI投資を怠ることは、事業成長の妨げとなる可能性\nがあります。 \n  \n \n図 1-1: AIの世界市場規模システム世界市場規模 \nstatia 「2021年 人工知能（AI）の世界市場規模および2030年\nまでの予測値（単位：100万米ドル） 」より作成 \n \n図 1-2: 国内AIシステム市場支出額予測 \nIDC「2023年 国内AIシステム市場予測を発表」より作成",
    "content_summary": "4 \n \n第1章 はじめに \n1.1 背景 \n1.1.1 AIの組織での普及について \n近年、AI （Artiﬁcial Intelligence、人工知能）は目覚ましい速度で普及が進んでいます。AIの市場規模\n（売上高）は加速度的な成長が予測され、世界市場では、2021年を基準に、2025年には約4.4倍、2030\n年には約19.3倍に成長する見込みであることが公表されています（図 1-1） [1]。また、国内において\nも、国内AIシステム市場支出額の予測も海外市場と同等速度での成長が予想され...",
    "content_length": 757,
    "created_at": "2025-05-12T10:04:28.769460+00:00",
    "updated_at": "2025-05-12T10:04:28.769461+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[97]": {
    "status": "pending",
    "content": "95 \n \n参照文献 \n \n[1]  statista, “2021年 人工知能（AI）の世界市場規模および2030年までの予測値（単位：100万\n米ドル） ”, 2023-01, https://jp.statista.com/statistics/1357441/artiﬁcial-intelligence-market-size. \n[アクセス日: 2024-06]. \n[2]  IDC Research, “2023年 国内AIシステム市場予測を発表”, 2023-04-27, \nhttps://www.idc.com/getdoc.jsp?containerId=prJPJ50603323. [アクセス日: 2024-06]. \n[3]  総務省, “人工知能（AI）研究の歴史”, 2016, \nhttps://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h28/html/nc142120.html. [アクセス日: \n2024-06]. \n[4]  JIPDEC, “ 「企業IT利活用動向調査2024」集計結果”, 2024-03-15, \nhttps://www.jipdec.or.jp/library/report/m0p0h60000000x1m-att/20240315_s03.pdf. [アクセス\n日: 2024-06]. \n[5]  MM総研, “本番迎える生成AI／LLM市場、国内ベンダーに期待集まる”, 2024-03, \nhttps://www.m2ri.jp/release/detail.html?id=618. [アクセス日: 2024-06]. \n[6]  総務省, 経済産業省, “AI事業者ガイドライン（第 1.0 版） ”, 2024-04-19, \nhttps://www.meti.go.jp/press/2024/04/20240419004/20240419004-1.pdf. [アクセス日: 2024-\n06]. \n[7]  NIST, “Artiﬁcial Intelligence Risk Management Framework (AI RMF 1.0)”, 2023. [アクセス日: \n2024-06]. \n[8]  NIST, “Artiﬁcial Intelligence Risk Management Framework: Generative Artiﬁcial Intelligence \nProﬁle” 2024-04, https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Proﬁle.ipd.pdf. [アクセス日: \n2024-06]. \n[9]  ISO, IEC, ISO/IEC 42001:2023 Information technology — Artiﬁcial intelligence — Management \nsystem, 2023. [アクセス日: 2024-06]. \n[10] 日本ディープラーニング協会, “生成AIの利用ガイドライン【簡易解説付】( 第1.1版, 2023年\n10月公開)”, 2023-10, https://www.jdla.org/document/#ai-guideline. [アクセス日: 2024-06]. \n[11] OWASP, “LLM AI サイバーセキュリティとガバナンスのチェックリスト 〜失敗しない大規模\n言語モデル導入のために〜”, 2024-04-10, https://genai.owasp.org/wp-\ncontent/uploads/2024/05/LLM_AI_Security_and_Governance_Checklist-v1_1_JP.pdf. [アクセス\n日: 2024-6]. \n[12] S. Barnett, S. Kurniawan , S. Thudumu, “Seven Failure Points When Engineering a Retrieval \nAugmented”, Association for Computing Machinery, 2024. [アクセス日: 2024-06].",
    "content_summary": "95 \n \n参照文献 \n \n[1]  statista, “2021年 人工知能（AI）の世界市場規模および2030年までの予測値（単位：100万\n米ドル） ”, 2023-01, https://jp.statista.com/statistics/1357441/artiﬁcial-intelligence-market-size. \n[アクセス日: 2024-06]. \n[2]  IDC Research, “2023年 国内AIシステム市場予測を発表”, 2023-04-27, \nhtt...",
    "content_length": 1811,
    "created_at": "2025-05-12T10:04:28.769692+00:00",
    "updated_at": "2025-05-12T10:04:28.769693+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[72]": {
    "status": "pending",
    "content": "70 \n \n今回は、 ガードレールを使うことにより、 話題の制限や敵対的プロンプトを検知できることを紹介しま\nしたが、自組織でPaaS型製品の利用を検討している場合は、付属しているセキュリティ対策ソリューシ\nョンも併用することを推奨します。 \n \n5.5.2 RAGにおけるアクセス管理の実装 \n3.3.2ではRAGに関する課題について言及しました。ここでは、その課題への解決策の一例を紹介し\nます。 \nベクトルDBに格納されている情報の重要度毎に参照できるユーザを設定する（図 5-18）ことで、組\n織毎にベクトルDBを複数用意する必要がなくなり、コストを軽減することができます。 \n \n \n図 5-18: ユーザごとにアクセス権限を設定したイメージ \n \n実際、図 5-19のように、管理職社員と一般社員で、同一の質問に対して異なる回答を取得することが\nできます。 \n \n \n図 5-19: 権限によって異なる回答をするイメージ",
    "content_summary": "70 \n \n今回は、 ガードレールを使うことにより、 話題の制限や敵対的プロンプトを検知できることを紹介しま\nしたが、自組織でPaaS型製品の利用を検討している場合は、付属しているセキュリティ対策ソリューシ\nョンも併用することを推奨します。 \n \n5.5.2 RAGにおけるアクセス管理の実装 \n3.3.2ではRAGに関する課題について言及しました。ここでは、その課題への解決策の一例を紹介し\nます。 \nベクトルDBに格納されている情報の重要度毎に参照できるユーザを設定する（図 5-18）ことで、組...",
    "content_length": 416,
    "created_at": "2025-05-12T10:04:28.769619+00:00",
    "updated_at": "2025-05-12T10:04:28.769619+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[29]": {
    "status": "pending",
    "content": "27 \n \n第3章 生成 AI の導入について \n本章では、組織に生成AIを導入する担当者 （導入担当者）の主な考慮事項を説明します。2.4.3で説明\nした通り、導入担当者が主に担当するのは「構想策定」 「要件定義」 「設計・開発」 「テスト・デプロイ」\nの4つのフェーズです。各フェーズの考慮事項を明確化することで、効果的かつセキュアな生成AIの導\n入を目指します。 \n \n \n図 3-1: 導入プロセスと導入担当者の該当フェーズ \n \n3.1 構想策定 \n3.1.1 利用ニーズの調査 \n構想策定において、従業員に対する生成AI利用のニーズ調査は導入目的を明確にするために重要な要\n素となるため、早期に実施することを推奨します。生成AIは汎用性が高く、多彩な用途に利用可能な技\n術です。ただし、現場のニーズを正しく理解できていない場合、適切な導入目的の設定ができず、生成AI\nを導入しても従業員による活用が進まず、期待した効果が得られない原因になります。そのため、従業員\nが生成AI導入でどのような効果を求めているのかをアンケートや有識者のヒアリング等で調査し、従業\n員のニーズに基づいた適切な導入目的の設定が求められます。 \n \n3.1.2 導入目的の決定 \n利用ニーズの調査後、生成AIの導入目的を明確に定めることが重要です。生成AIは多様な用途に適\n用可能で技術進化が非常に早いため、明確な目的がなければ、生成AIを既存の業務プロセスでどのよう\nに活用すべきかの判断が困難です。また、導入目的は生成AI導入の効果測定においても重要です。 「生\n成AIを導入している企業が増えているから」などの曖昧な目的ではなく、明確な目的を設定した上で、\n生成AIの導入を推進するようにしましょう。 \n \n導入目的の例 \n 全社員を対象とした社内業務（文章作成・要約、プログラミング、アイデア出しなど）の効率化 \n チャットボットを利用した問い合せ窓口業務の効率化 \n RAGを活用した社内情報検索の効率化",
    "content_summary": "27 \n \n第3章 生成 AI の導入について \n本章では、組織に生成AIを導入する担当者 （導入担当者）の主な考慮事項を説明します。2.4.3で説明\nした通り、導入担当者が主に担当するのは「構想策定」 「要件定義」 「設計・開発」 「テスト・デプロイ」\nの4つのフェーズです。各フェーズの考慮事項を明確化することで、効果的かつセキュアな生成AIの導\n入を目指します。 \n \n \n図 3-1: 導入プロセスと導入担当者の該当フェーズ \n \n3.1 構想策定 \n3.1.1 利用ニーズの調査 \n構想策定...",
    "content_length": 853,
    "created_at": "2025-05-12T10:04:28.769516+00:00",
    "updated_at": "2025-05-12T10:04:28.769516+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[25]": {
    "status": "pending",
    "content": "23 \n \n段階的導入（スモールスタート） \n本書における生成AI導入では、 「スモールスタート」を意識しています。スモールスタートとは、少な\nいコストや時間で小さな規模から技術導入等を開始することです。 \n生成AIは技術革新のスピードが著しく速いため、他のシステム開発と比較してスモールスタートの重\n要性が高くなります。実際、ヒアリングした多くの組織では、 \n 「導入工数削減のため、担当者が生成AIについて学習しつつ導入検討する」 \n 「導入失敗・手戻り発生を防ぐため、事前に試しの導入を実施して、効果・安全性を確認したい」  \nという理由から、対象ユーザを社員全員とし、実装した機能を全て盛り込んだ状態でいきなり導入する\nよりも、機能や利用範囲を制限した状態で一度試験導入・運用を実施していました。 \n \nドキュメンテーション \n生成AIの導入において、システムの設定内容やその設定を行った経緯について文書化して記録するこ\nとが重要です。スモールスタートの状態から必要に応じてシステム更新を実施する必要がありますが、\nこの文書化によって組織が意思決定を円滑に進めることができます。 \nまた、運用面においてもユーザが適切にシステムを利用できるように利活用ガイドラインやマニュア\nルなどを文書化して記録を残すことにより、業務効率の向上やリスクの軽減に寄与することができます。  \n \n継続的改善 \n生成 AI をはじめとしたシステムの導入・運用においては、システムそのものや利活用ガイドラインな\nどに対して継続的に改善を行うことで、より効果的な運用に繋げられます。特に生成AIは研究が盛んに\n行われており技術的な進歩や社会情勢の変化が激しい分野であるため、継続的な改善が求められます。 \nまた、システム全体に対してだけではなく、導入・運用プロセス内の各フェーズにおいてもPDCAサ\nイクルを回し、より良いシステムの導入を目指すことが重要です。",
    "content_summary": "23 \n \n段階的導入（スモールスタート） \n本書における生成AI導入では、 「スモールスタート」を意識しています。スモールスタートとは、少な\nいコストや時間で小さな規模から技術導入等を開始することです。 \n生成AIは技術革新のスピードが著しく速いため、他のシステム開発と比較してスモールスタートの重\n要性が高くなります。実際、ヒアリングした多くの組織では、 \n 「導入工数削減のため、担当者が生成AIについて学習しつつ導入検討する」 \n 「導入失敗・手戻り発生を防ぐため、事前に試しの導入を実施...",
    "content_length": 824,
    "created_at": "2025-05-12T10:04:28.769506+00:00",
    "updated_at": "2025-05-12T10:04:28.769507+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[81]": {
    "status": "pending",
    "content": "79 \n \n \nAIモデルを開発するサーバスペックがAIモデル性能を直接示すわけではありませんが、AIモデルを\n開発するサーバスペックが向上することは、時間当たりの学習効率を高めるため、高性能なAIモデルの\n開発が可能になると言えます。同書 [32]にはAIモデルの学習コストに関しても、OpenAI社が提供する\nGPT-4には約7800万ドル、Google社が提供するGemini Ultraには約1.9億ドルの学習コストが掛かっ\nていると言及しています。 \n現在、世界の先駆的な役割を持つ汎用的な生成AIモデルは、クラウドベンダとしてトップシェアを誇\nる米国企業が多大な投資により支えています [33]。大規模なサーバを多数の顧客が利活用するクラウド\nサービスと高性能なサーバを必要とする生成AIの特性とは親和性が高く、投資に対して十分な効果を得\nられると見込んでいることが伺い知れます。 \nとはいえAI開発の命運を左右する要素は、 設備に対する投資だけではありません。AIモデルの大きさ\nは、かねてから問題点として挙げられ、開発・運用コストを抑制するために新たな手法の研究が盛んに行\nわれています。2024年2月にMicrosoft社からBitNet b1.58 （量子化に関する論文）が発表されるなど、\n1パラメータあたりのデータ量を圧縮した効率的なAIの開発、つまり大きいAIからスリムなAIに時代\nが変わりつつあります。 \n \n7.1.2 欧州の生成AI \n2022年11月30日にChatGPTが公開され、たった2ヶ月でユーザ数1億人を突破しました [35]。\n2017年頃から欧州内でもAIへの関心は高まり [36] [37]、2023年には新たなAIモデルを作成する欧州\nのスタートアップ企業に対してより多くの投資がされるようになりました [32]。これらのスタートアッ\nプ企業誕生の背景には、欧州における生成AIの規制 （後述）を考慮した 「欧州が開発する欧州向けの生\n成AI」のニーズが高まっていたと推測されます。 \n \nここでは、特に強い関心を集めているスタートアップ企業として、ドイツの「Aleph Alpha」とフラン\nスの「Mistral AI」を取り上げます。 \nAleph Alpha社の創業者ジョナス・アンドルリス氏は、元々Apple社でAIの研究を行っていました。\n彼を中心に多くの国際的な研究者や技術者が集まり、 「Attention Is All You Need」発表の2年後である\n2019年にAleph Alpha社は設立されました [38]。欧州の中では、早期に商業向け生成AIの開発に取り\n組み始めた企業の1つです。Aleph Alpha社は独自の大規模言語モデル「Luminous」を持ち、同モデル\nは欧州の公的機関の一部で利用が始められています [39]。その基本的な技術は「OpenAI社のChatGPT\nに比肩する」と評されました。直近では2023年11月に5億ドルの資金調達を成し、より高性能な生成\nAIモデル開発への期待が高まっています [38]。",
    "content_summary": "79 \n \n \nAIモデルを開発するサーバスペックがAIモデル性能を直接示すわけではありませんが、AIモデルを\n開発するサーバスペックが向上することは、時間当たりの学習効率を高めるため、高性能なAIモデルの\n開発が可能になると言えます。同書 [32]にはAIモデルの学習コストに関しても、OpenAI社が提供する\nGPT-4には約7800万ドル、Google社が提供するGemini Ultraには約1.9億ドルの学習コストが掛かっ\nていると言及しています。 \n現在、世界の先駆的な役割を持つ汎用的な...",
    "content_length": 1306,
    "created_at": "2025-05-12T10:04:28.769648+00:00",
    "updated_at": "2025-05-12T10:04:28.769649+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[46]": {
    "status": "pending",
    "content": "44 \n \n透明性を確保することは、生成AIの利用に対する信頼性を向上させ、バイアスを抑制した運用に繋が\nります。企業はこの重要な側面を認識し、継続的な改善とモニタリングを通じて透明性を維持する努力\nを続けることが重要です。 \n \n確認すべき生成AIの透明性 \nここでは、生成AIを運用する上で確認すべき透明性を3つ紹介します。 \n \n 学習データの透明性 \n学習データにおいて透明性を有する状態とは、LLMがどのようなデータを元に学習を行ったのかが\n可視化された状態にあることです。主にデータの出所や内容、収集日時、品質等の内容が可視化されて\nいることを確認します。 \n \n 参照データの透明性 \n参照データにおいて透明性を有する状態とは、生成AIが回答に使用したデータが可視化された状態\nにあることです。例としてはWebのデータを参照した場合はそのURLを明示することや、RAGを使\n用している場合はベクトルDBで参照したデータのパスを明示することです。生成AIが参照元の情報\nに誤りがあると生成した回答にも誤りが含まれるため、どのようなデータが参照されたのか確認し正\n誤を判断することが重要です。 \n \n 回答生成プロセスの透明性 \n回答生成プロセスにおいて透明性を有する状態とは、生成AIがどのような論理やプロセスで回答を\n生成したのかが可視化された状態にあることです。 生成のプロセスを確認することにより、 回答が信用\nに足るかどうかの判断に役立たせることができます。 \n \n＜透明性のない生成AIの例＞ \n \n図 4-7: 透明性のない生成AIの例",
    "content_summary": "44 \n \n透明性を確保することは、生成AIの利用に対する信頼性を向上させ、バイアスを抑制した運用に繋が\nります。企業はこの重要な側面を認識し、継続的な改善とモニタリングを通じて透明性を維持する努力\nを続けることが重要です。 \n \n確認すべき生成AIの透明性 \nここでは、生成AIを運用する上で確認すべき透明性を3つ紹介します。 \n \n 学習データの透明性 \n学習データにおいて透明性を有する状態とは、LLMがどのようなデータを元に学習を行ったのかが\n可視化された状態にあることです。主にデータの出...",
    "content_length": 683,
    "created_at": "2025-05-12T10:04:28.769557+00:00",
    "updated_at": "2025-05-12T10:04:28.769557+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[18]": {
    "status": "pending",
    "content": "16 \n \n② RAG（Retrieval-Augmented Generation） \nRAGは、生成AIへ入力した質問に関連するデータを外部のデータベース（ベクトルDB）から検\n索し、元の質問に追加情報として付与した上でLLMに回答を生成させる技術です。回答にはベクト\nルDBから検索されたデータが利用されるため、LLMに学習されていない内容でも関連するデータ\nをベクトルDBに格納しておくことで回答精度を向上させることができます。 \nRAGを使用するにあたって、ベクトルDBの検索を正確に行うためにはファインチューニングと\n同様に格納するデータの質を確保することが重要です。また、ベクトルDBの検索を行う分、RAG\nを使用しない場合と比較して回答までに時間がかかる点にも注意が必要です。 \n \n \n図 2-4: RAGの概要 \n \n2.1.4 テキスト生成AIの入力から回答までの流れ \n図 2-5に示す簡易的なテキスト生成AIシステムの構成を例に、 入力から回答までに行われる処理につ\nいて紹介します。 \n \n \n図 2-5: テキスト生成AIシステムの構成例",
    "content_summary": "16 \n \n② RAG（Retrieval-Augmented Generation） \nRAGは、生成AIへ入力した質問に関連するデータを外部のデータベース（ベクトルDB）から検\n索し、元の質問に追加情報として付与した上でLLMに回答を生成させる技術です。回答にはベクト\nルDBから検索されたデータが利用されるため、LLMに学習されていない内容でも関連するデータ\nをベクトルDBに格納しておくことで回答精度を向上させることができます。 \nRAGを使用するにあたって、ベクトルDBの検索を正確に行うた...",
    "content_length": 484,
    "created_at": "2025-05-12T10:04:28.769489+00:00",
    "updated_at": "2025-05-12T10:04:28.769490+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[3]": {
    "status": "pending",
    "content": "目次 \n第1章 はじめに ................................................................................................................... 4 \n1.1 背景 .......................................................................................................................... 4 \n1.1.1 AIの組織での普及について ............................................................................. 4 \n1.1.2 AI発展の歴史 ................................................................................................... 5 \n1.1.3 ディープラーニングの発展 .............................................................................. 6 \n1.1.4 課題 ................................................................................................................... 7 \n1.2 本書の作成目的 ........................................................................................................ 8 \n1.3 本書のスコープ ........................................................................................................ 9 \n1.4 本書の特徴 ............................................................................................................. 10 \n1.5 本書の活用例 .......................................................................................................... 11 \n1.6 免責事項 ................................................................................................................. 12 \n第2章 本書を最大限に活用するために ............................................................................. 13 \n2.1 生成AIとは ........................................................................................................... 13 \n2.1.1 生成AIの定義 ................................................................................................ 13 \n2.1.2 テキスト生成AIと大規模言語モデル（LLM） ............................................ 14 \n2.1.3 テキスト生成AIの回答精度向上のための技術 ............................................. 15 \n2.1.4 テキスト生成AIの入力から回答までの流れ ................................................. 16 \n2.2 テキスト生成AIの組織活用 .................................................................................. 17 \n2.2.1 組織活用可能な場面 ....................................................................................... 17 \n2.2.2 組織活用における実態 .................................................................................... 18 \n2.3 テキスト生成AIの組織導入に向けて ................................................................... 19 \n2.3.1 テキスト生成AI導入と課題 .......................................................................... 19 \n2.3.2 AIシステムの組織導入における信頼性 ......................................................... 20 \n2.3.3 テキスト生成AIの組織導入におけるリスク ................................................. 21 \n2.4 テキスト生成AIの組織導入・運用プロセスと担当者 .......................................... 22 \n2.4.1 導入・運用の前提事項 .................................................................................... 22 \n2.4.2 導入・運用の流れ（プロセス） ..................................................................... 24 \n2.4.3 導入・運用における担当者 ............................................................................ 25 \n第3章 生成AIの導入について ......................................................................................... 27 \n3.1 構想策定 ................................................................................................................. 27 \n3.1.1 利用ニーズの調査 ........................................................................................... 27 \n3.1.2 導入目的の決定............................................................................................... 27 \n3.1.3 目的に応じたスコープの決定 ......................................................................... 28 \n3.2 要件定義 ................................................................................................................. 28",
    "content_summary": "目次 \n第1章 はじめに ................................................................................................................... 4 \n1.1 背景 ..................................................................................................................",
    "content_length": 3642,
    "created_at": "2025-05-12T10:04:28.769451+00:00",
    "updated_at": "2025-05-12T10:04:28.769452+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[30]": {
    "status": "pending",
    "content": "28 \n \n3.1.3 目的に応じたスコープの決定 \n導入目的に応じて、スコープ（対象ユーザ・実装機能）を決定することが重要です。ユーザの利用頻度\nや実装する機能によって、生成AIの構築・維持にかかるコストに大きな差が生まれます。そのため、ス\nコープを適切に設定することは、生成AI導入リスクの低減に繋がります。また、初期段階では、スコー\nプを絞り、スモールスタートとして導入することで、対象部署やユーザ数、ユーザ1 人当たりの利用頻\n度を検証し、導入コストを精査する機会にもなります。導入目的に応じたスコープを決定しましょう。 \n \n3.2 要件定義 \n3.2.1 実現可能性の検討 \n実現可能性の検討では、生成AIを導入することで目的が達成できるかを検証します。この際、いくつ\nかの観点から検証を行う必要があります。 \n \n 技術的な観点 \n 生成AIの設計および開発が技術的に実現可能であること。 \n システムが将来的な拡張や変更にも対応できる設計であること。 \n \n 経済的な観点 \n 生成AIの導入・運用にかかるコストが組織の予算内で収まること。 \n 費用対効果の分析を行い、投資に対するリターンが見込めること。 \n \n 組織的な観点 \n 生成AIの導入・運用に必要な人的リソースを確保できること。 \n 関係する部門間の協力体制が整っていること。 \n 生成AIが関連する社内ポリシーに準拠可能であること。 \n \n 法的な観点 \n 生成AIが関連する法規制に準拠しており、法的リスクが適切に管理されていること。 \n プライバシー保護やデータセキュリティに関する規制要件を満たしていること。 \n \n 倫理的な観点 \n 生成AIの回答が倫理的に許容可能であり、社会的に受け入れられるものであること。 \n バイアスや不公平な回答を最小限に抑えるための対策が組み込まれていること。",
    "content_summary": "28 \n \n3.1.3 目的に応じたスコープの決定 \n導入目的に応じて、スコープ（対象ユーザ・実装機能）を決定することが重要です。ユーザの利用頻度\nや実装する機能によって、生成AIの構築・維持にかかるコストに大きな差が生まれます。そのため、ス\nコープを適切に設定することは、生成AI導入リスクの低減に繋がります。また、初期段階では、スコー\nプを絞り、スモールスタートとして導入することで、対象部署やユーザ数、ユーザ1 人当たりの利用頻\n度を検証し、導入コストを精査する機会にもなります。導入目的に応じ...",
    "content_length": 806,
    "created_at": "2025-05-12T10:04:28.769518+00:00",
    "updated_at": "2025-05-12T10:04:28.769519+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[67]": {
    "status": "pending",
    "content": "65 \n \n ベクトルDBに格納するデータ \nデータの正確性を精査してベクトルDBに格納する際に確認する必要があります。間違ったデータ\nを格納してしまった場合、誤った回答を返答するようになる恐れがあります。 \n \n注意事項 \n 生成AIに関する情報は常に変化するため、最新の情報や外部の知見、および社会情勢を考慮し、チェ\nックリストを更新することを推奨します。",
    "content_summary": "65 \n \n ベクトルDBに格納するデータ \nデータの正確性を精査してベクトルDBに格納する際に確認する必要があります。間違ったデータ\nを格納してしまった場合、誤った回答を返答するようになる恐れがあります。 \n \n注意事項 \n 生成AIに関する情報は常に変化するため、最新の情報や外部の知見、および社会情勢を考慮し、チェ\nックリストを更新することを推奨します。",
    "content_length": 181,
    "created_at": "2025-05-12T10:04:28.769606+00:00",
    "updated_at": "2025-05-12T10:04:28.769607+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[88]": {
    "status": "pending",
    "content": "86 \n \n第8章 終わりに \n8.1 あとがき \nここまで本書を読んでいただき、誠にありがとうございました。 \n本書は、日本の産業界における生成AIの利活用を促進したいという強い思いから作成されました。 \n生成AIに限らず、セキュリティという言葉には、面倒くさい、利便性が下がるといったマイナスなイ\nメージがつきまといがちです。特に、セキュリティに直接関係のない業務に携わっている方々には、その\n傾向が強いのではないでしょうか。 \n生成AIの技術進歩は非常に早く、日々新しいサービスが展開されています。その中で、セキュリティ\nを後回しにしてしまうこともあるかもしれません。しかし、生成AIには特有の脆弱性があり、世界中で\nこれらの課題と対策について活発な議論が行われています。セキュリティインシデントが発生すれば、\n生成AIの利用が制限される可能性もあります。だからこそ、生成AIのセキュリティを考えることが重\n要だと考えます。 \nさて、本書は独立行政法人情報処理推進機構 産業サイバーセキュリティセンター 中核人材育成プロ\nグラムにおける卒業プロジェクトの成果物として、日本の産業界におけるさまざまなメンバーが議論を\n重ねて作成されました。現在、日本の多くの組織では、機械学習やディープラーニングに詳しい人材が少\nなく、 導入に対する不安を抱えていることでしょう。 我々も最初から知見があったわけではありません。\n多くのドキュメントを読み、オンプレ・クラウド環境での検証を行い、メンバー間で意見をぶつけ合う、\nこのサイクルを繰り返すことで、本書の内容をまとめることができました。このような環境を与えてく\nださった全ての方に感謝申し上げます。 \n2024年6月現在、生成AIは日々進化しています。新しい技術やサービスが次々と登場し、情報収集\nを怠ると取り残されてしまいます。本書を作成する期間中にも、EUのAI規制法の成立、日本のスーパ\nーコンピュータ「富岳」で学習した「Fugaku-LLM」の登場、高校生が開発した日本語性能世界一のLLM\nモデル （7Bモデル、2024年5月9日時点）など、大きな出来事がありました。これらの進展は今後も加\n速することが予想されます。現状、日本は生成AIの分野において後発の立場にありますが、これらの事\n例を見れば、日本も確実に進歩していることがわかります。このような技術革新が続く中で、日本が生成\nAIの分野でリーダーシップを発揮する可能性も十分にあると考えています。 \nまた、本書を手に取っていただいた皆様が、生成AIの新しい技術やサービスを活用し、組織の発展に\n貢献されることを期待しています。生成AIの導入には挑戦も伴いますが、それを乗り越えるための知識\nを提供することが、本書の目的です。本書が皆様の成功と成長に繋がることを心より願っております。 \n生成AIの未来は明るく、その可能性は無限大です。共に学び、成長し続けていきましょう。",
    "content_summary": "86 \n \n第8章 終わりに \n8.1 あとがき \nここまで本書を読んでいただき、誠にありがとうございました。 \n本書は、日本の産業界における生成AIの利活用を促進したいという強い思いから作成されました。 \n生成AIに限らず、セキュリティという言葉には、面倒くさい、利便性が下がるといったマイナスなイ\nメージがつきまといがちです。特に、セキュリティに直接関係のない業務に携わっている方々には、その\n傾向が強いのではないでしょうか。 \n生成AIの技術進歩は非常に早く、日々新しいサービスが展開されていま...",
    "content_length": 1242,
    "created_at": "2025-05-12T10:04:28.769667+00:00",
    "updated_at": "2025-05-12T10:04:28.769668+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[71]": {
    "status": "pending",
    "content": "69 \n \nこの機能は特定の話題を制限するだけではなく、API経由でLLMを利用する環境（ハイブリッド型）\nにおいては、業務と関係ないリクエストを減らし、コストを削減することにも繋がります。 \n \n敵対的プロンプトを防ぐ機能 \n本ツールは、敵対的プロンプトを防ぐこともできます。設定ファイルに入力ポリシーを記載する（図 \n5-16）ことで、プロンプトに入力された文章が入力ポリシーに違反していないかをLLMを使用して確認\nします。 \n \n図 5-16: 入力ポリシー設定画面（yml 形式） \n \n実際に図 5-16では、以下の3点を確認するように設定しています。 \n 日本語と英語以外を使っている。 \n 敵対的プロンプトが含まれている。 \n プログラムやコードの実行を促している。 \n図 5-17では、上記に違反する場合に、入力ポリシーに違反した旨の回答が返ることがわかります。 \n \n図 5-17: 入力ポリシーに反した場合のイメージ",
    "content_summary": "69 \n \nこの機能は特定の話題を制限するだけではなく、API経由でLLMを利用する環境（ハイブリッド型）\nにおいては、業務と関係ないリクエストを減らし、コストを削減することにも繋がります。 \n \n敵対的プロンプトを防ぐ機能 \n本ツールは、敵対的プロンプトを防ぐこともできます。設定ファイルに入力ポリシーを記載する（図 \n5-16）ことで、プロンプトに入力された文章が入力ポリシーに違反していないかをLLMを使用して確認\nします。 \n \n図 5-16: 入力ポリシー設定画面（yml 形式） \n \n実...",
    "content_length": 422,
    "created_at": "2025-05-12T10:04:28.769616+00:00",
    "updated_at": "2025-05-12T10:04:28.769617+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[91]": {
    "status": "pending",
    "content": "89 \n \n \nDoS（Deny of Service）攻撃 サービス拒否攻撃とも呼ばれ、大量のパケットを送りつけて\nネットワークやシステム資源（CPU、メモリ、ディスク）\nを過負荷にしてシステムダウン、サービス停止に陥らせるこ\nとを目的とする攻撃手法 \nGDPR \n（General Data Protection \nRegulation） \n欧州経済領域（EEA）における個人データ保護やその取り扱\nいについて定めた規約。 \nEU域内にある組織だけでなく、EUと取引のある全ての組\n織が対象となる。 \nGPT \n（Generative Pre-trained \nTransformer） \nOpenAIが開発した自然言語処理のためのディープラーニン\nグモデル。与えられた文脈に基づいて自然な文章を生成する\nことに特化しており、ユーザとの対話を通じて、文脈に応じ\nた適切な応答を生成することができる。 \nGemini Google 社が提供している生成AIサービス。2024年6月時\n点での最高性能モデルはGemini1.5Proである。 \nISO \n（International Organization for \nStandardization） \nスイスのジュネーブに本部を置く国際標準化機構と当該組織\nが制定した国際規格。何らかの製品やサービスに関して世界\nで同じ品質、同じレベルのものを提供できるようにするため\nの国際的な基準が定められている。 \nIoT機器 インターネットに接続して使用する機器。これまでインター\nネットに接続する機能がなかった機器についても昨今はイン\nターネットに接続できる機器が増加している。 \n例）センサー、カメラ、リモート操作可能な家電や空調機器\n等。 \nLangChain LLM を用いたアプリケーション開発を効率的に行うための\n開発ライブラリ。LLMと外部リソースを組み合わせ、RAG\nやLLM連携システムなどの高度なアプリケーションやサー\nビス開発を目的としている。 \nPDCA サイクル Plan （計画） 、Do（実行） 、Check（測定・評価） 、Action\n（対策・改善）の仮説・検証型プロセスを循環させ、マネジ\nメントの品質を高めようという概念。 \nPaaS（Platform as a Service） クラウド事業者がソフトウェアを除くサーバやOSなどの利\n用環境を提供する形態。 \nRAG \n（Retrieval-Augmented Generation） \nLLMによるテキスト生成に、外部情報の検索を組み合わせ\nることで、回答精度を向上させる技術。 \nSLA（Service Level Agreement） サービス提供者とユーザとの間の契約において、サービスが\n提供される基準を定義したもの。",
    "content_summary": "89 \n \n \nDoS（Deny of Service）攻撃 サービス拒否攻撃とも呼ばれ、大量のパケットを送りつけて\nネットワークやシステム資源（CPU、メモリ、ディスク）\nを過負荷にしてシステムダウン、サービス停止に陥らせるこ\nとを目的とする攻撃手法 \nGDPR \n（General Data Protection \nRegulation） \n欧州経済領域（EEA）における個人データ保護やその取り扱\nいについて定めた規約。 \nEU域内にある組織だけでなく、EUと取引のある全ての組\n織が対象となる...",
    "content_length": 1183,
    "created_at": "2025-05-12T10:04:28.769678+00:00",
    "updated_at": "2025-05-12T10:04:28.769679+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[99]": {
    "status": "pending",
    "content": "97 \n \n[29] W. R. Owen, S. Eddy , A. Jamie, “Update on the ChatGPT Case: Counsel Who Submitted Fake \nCases Are Sanctioned”, 2023.  \n[30] Ashish Vaswani, Noam Shazeer他, “Attention Is All You Need”, 2017. \n[31] docusign, “ビジネスパーソン1,000人に聞く！生成AIの利用実態と意向”, 2024. \n[32] Stanford University, “Artiﬁcial Intelligence Index Report 2024”, 2024. \n[33] 総務省, “情報通信白書令和5年版”, 2023. \n[34] M. Shuming, W. Hongyu, M. Lingxiao, W. Lei, W. Wenhui, H. Shaohan , D. Li, W. Ruiping, X. \nJilong , W. Furu, “The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits”, 2024. \n[35] 野村総合研究所, “日本のChatGPT利用動向（2023年4月時点） ”, 2023-05-26, \nhttps://www.nri.com/jp/knowledge/report/lst/2023/cc/0526_1. \n[36] 日本貿易振興機構, “2017年のAIスタートアップ企業への投資額は前年比4倍に（フラン\nス） ”, 2019-05-17, \nhttps://www.jetro.go.jp/biz/areareports/special/2019/0502/b6e994afcb842a70.html. [アクセス\n日: 2024-06]. \n[37] 日本貿易振興機構, “連邦政府はAI戦略を発表、中堅・中小企業への浸透を狙う（ドイツ） ”, \n2019-05-17, https://www.jetro.go.jp/biz/areareports/special/2019/0502/9d342ﬀ5304e10e0.html. \n[アクセス日: 2024-06]. \n[38] 日本貿易振興機構, “ドイツ生成AIスタートアップのアレフ・アルファ、欧州最大規模の資金調\n達”, 2023-11-14, https://www.jetro.go.jp/biznews/2023/11/591d6a87c5c7bf7c.html. [アクセス\n日: 2024-06]. \n[39] WIRED, “ドイツのスタートアップAleph Alphaは“欧州のOpenAI”になれるの”, 2023-10-\n02, https://wired.jp/article/aleph-alpha-europe-openai/. [アクセス日: 2024-06]. \n[40] AT PERTNERS, “パリのAIスタートアップである\"Mistral AI\"が$6Bの評価額で$600Mを調達\n交渉中との報道”, 2024-05-10, https://www.atpartners.co.jp/news/2024-05-10-paris-based-ai-\nstartup-mistral-ai-in-talks-to-raise-600m-at-6b-valuation. [アクセス日: 2024-06]. \n[41] Amazon Web Services ブログ, “Mistral AI モデルが Amazon Bedrock で間もなく利用可能\nに”, 2024-03-02, https://aws.amazon.com/jp/blogs/news/mistral-ai-models-coming-soon-to-\namazon-bedrock/. [アクセス日: 2024-06]. \n[42] 日本放送協会, “米 NYタイムズ 著作権侵害でオープンAIとマイクロソフトを提訴”, 2023-\n12-28, https://www3.nhk.or.jp/news/html/20231228/k10014302081000.html. [アクセス日: \n2024-06].",
    "content_summary": "97 \n \n[29] W. R. Owen, S. Eddy , A. Jamie, “Update on the ChatGPT Case: Counsel Who Submitted Fake \nCases Are Sanctioned”, 2023.  \n[30] Ashish Vaswani, Noam Shazeer他, “Attention Is All You Need”, 2017. \n[31] docusign, “ビジネスパーソン1,000人に聞く！生成AIの利用実態と意向”...",
    "content_length": 1865,
    "created_at": "2025-05-12T10:04:28.769697+00:00",
    "updated_at": "2025-05-12T10:04:28.769697+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[37]": {
    "status": "pending",
    "content": "35 \n \n3.3.2 RAG利用に関する留意点 \n生成AIの利用において、社内情報を検索するためにRAGを利用する場合、ベクトルDBに格納する\n情報の精査が重要です。以下のような情報が格納された場合、ハルシネーションや誤った回答の出力が\n発生し、回答精度の低下につながります。 \n \n回答精度を低下させる情報の例： \n ノイズが含まれる情報 \n 重複した情報 \n 最新版ではない古い情報 \n \nまた、RAGの利用に関しては、 現在さまざまな課題が存在しています。 以下の課題を認識した上でRAG\nの利用を検討する必要があります。 \n \nRAG利用時の課題の例： \n ベクトルDBに機密情報を含むデータを格納した場合、全てのユーザが機密情報を参照できる。 \n ユーザや部門ごとにRAGに格納するデータを分けることや、 参照するデータに閲覧権限を設定する\nことができない。 \n 従来の方法で上述の課題を解決するためにはRAGの環境を複数構築する必要があり、 コストが高く\nなる。 \n \nこれらの課題については、2024年6月現在も研究が進められているため、組織として最新の動向を確\n認していくことを推奨します。 \n \n3.4 テスト・実装 \nテスト・実装フェーズでは、構築した生成AIシステムの品質を保証するためのテストおよび生成AI\nの実装を行います。本章ではその中でも実装に先立って行われるテストフェーズでの考慮事項について\n記載します。 \n3.4.1 システムテスト \n一般的な新システムを導入する際と同様に、生成AIの導入する際にもシステムテストを行うことは重\n要です。通常のシステムテストの流れに沿って、システムが設計通りに動作しているかどうかを確認す\nる必要があります。",
    "content_summary": "35 \n \n3.3.2 RAG利用に関する留意点 \n生成AIの利用において、社内情報を検索するためにRAGを利用する場合、ベクトルDBに格納する\n情報の精査が重要です。以下のような情報が格納された場合、ハルシネーションや誤った回答の出力が\n発生し、回答精度の低下につながります。 \n \n回答精度を低下させる情報の例： \n ノイズが含まれる情報 \n 重複した情報 \n 最新版ではない古い情報 \n \nまた、RAGの利用に関しては、 現在さまざまな課題が存在しています。 以下の課題を認識した上でRA...",
    "content_length": 746,
    "created_at": "2025-05-12T10:04:28.769535+00:00",
    "updated_at": "2025-05-12T10:04:28.769536+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[31]": {
    "status": "pending",
    "content": "29 \n \n3.2.2 目標の設定 \n生成AI導入に関する達成目標の設定を行います。適切な達成目標を設定してはじめて、その後の効果\n的な意思決定が可能となります。 \n目標設定にあたり、 「定性的目標」と「定量的目標」をそれぞれ検討することが重要です。生成AIの導\n入や活用が組織やプロジェクトに与える影響について、業務品質の改善や目標を定める 「定性的目標」と\n具体的な数値で測定できる 「定量的目標」の観点での検討がそれぞれ必要となります。特に定量的目標に\nついては、生成AIの効果測定において指標の1つとなることから、現実的な目標値を設定することを推\n奨します。 \n \n目標の例 \n定量的目標 \n 生産性の向上（例：特定のタスク（レポート作成/データ分析）の完了時間を30％短縮） \n ユーザ利用率（例：生成AI利用申請が従業員の40％） \n \n定性的目標 \n 生成AIを利用して、リスクの特定やコンプライアンスの維持を支援する。 \n 組織やチームが新しいアイデアやソリューションを生み出す能力を向上させる。 \n \n3.2.3 利害関係者の整理 \n2.4.3では生成AIの組織活用における担当者を定義しましたが、導入、運用、セキュリティ担当者以外\nにも多くの関係者との調整が必要です。本項ではその関係者の洗い出しに焦点を当てます。 \n生成AIの導入において、NISTのAI RMFでは、生成AIを含めたAIの導入におけるライフサイクル\nの関係者（AI Actor）が定義されており、それらを参考に関係者を洗い出し、各関係者の責任範囲を明確\n化することが重要です。以下に想定される関係者や立ち位置について記載します。 \n \n 導入ベンダ \n生成AIを組織に提供する導入ベンダは、生成AIの導入時に最も重要な立ち位置を占める外部関係者\nとなる為、データの取り扱いや責任範囲についての合意が必要です。 \n \n 法務担当者 \n生成AIを利用する上で、社内情報の取り扱いや著作物の利用範囲や権利について、導入担当者や運用\n担当者、セキュリティ評価者では判断できない分野の専門的な知識を確認するために、必要に応じて組\n織内外の有識者の協力を得ることが推奨されます。",
    "content_summary": "29 \n \n3.2.2 目標の設定 \n生成AI導入に関する達成目標の設定を行います。適切な達成目標を設定してはじめて、その後の効果\n的な意思決定が可能となります。 \n目標設定にあたり、 「定性的目標」と「定量的目標」をそれぞれ検討することが重要です。生成AIの導\n入や活用が組織やプロジェクトに与える影響について、業務品質の改善や目標を定める 「定性的目標」と\n具体的な数値で測定できる 「定量的目標」の観点での検討がそれぞれ必要となります。特に定量的目標に\nついては、生成AIの効果測定において指標...",
    "content_length": 934,
    "created_at": "2025-05-12T10:04:28.769520+00:00",
    "updated_at": "2025-05-12T10:04:28.769521+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[57]": {
    "status": "pending",
    "content": "55 \n \n 2サイクル目以降の「運用・評価」時 \n1サイクル目と同様、定期的なリスクアセスメント実施を推奨します。 \n \n リスク対応 \n対策ごとに、異なるタイミングで実施。具体的なタイミングは組織によって異なります。 \n \n注意事項 \n リスク管理では、セキュリティ担当者には導入者や運用者と協力することが求められます。また、 導\n入者・運用者のほかにも必要な関係者と協力しましょう。組織・チームとして取り組むことで、抜け\n漏れの少なく、精度の高いリスクの特定・分析・評価に繋がります。 \n リスク評価は、 リスク対策を決める意思決定の工程となります。 ゆえに、 経営層をはじめとした意思\n決定者の協力が得ることが重要です。 \n \n5.3 生成AIにおけるリスクアセスメントの例 \n5.3.1 特定・分析に向けた生成AIリスクの把握 \n \n※本節のリスクアセスメントで使用する構成は一例であり、実際には、所属組織の構成を把握し、リス\nクと照らし合わせた上で実施してください。 \n \n本節では、リスク特定・分析を行う上で参考となるように、生成AI特有のリスクを紹介します。ここ\nでは「OWASP Top 10 for LLM」を使って、一般的な生成AI特有のリスクを見ていきましょう。なお、\nリスクがシステム上のどこに発生するかを併せて紹介4しますが、そのシステムは、3.2.5にて定義したハ\nイブリッド型またはオンプレ型を想定しています（図 5-5。これは図 2-5の再掲） 。 \n  \n \n4 実際にリスク特定を行う際には、資産に対してリスクを特定します。その参考となるように、ここ\nで、代表的な生成AIシステム構成のどこに、何のリスクが紐づくかを紹介します。",
    "content_summary": "55 \n \n 2サイクル目以降の「運用・評価」時 \n1サイクル目と同様、定期的なリスクアセスメント実施を推奨します。 \n \n リスク対応 \n対策ごとに、異なるタイミングで実施。具体的なタイミングは組織によって異なります。 \n \n注意事項 \n リスク管理では、セキュリティ担当者には導入者や運用者と協力することが求められます。また、 導\n入者・運用者のほかにも必要な関係者と協力しましょう。組織・チームとして取り組むことで、抜け\n漏れの少なく、精度の高いリスクの特定・分析・評価に繋がります。 \n...",
    "content_length": 737,
    "created_at": "2025-05-12T10:04:28.769583+00:00",
    "updated_at": "2025-05-12T10:04:28.769584+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[24]": {
    "status": "pending",
    "content": "22 \n \n 法的および社会的リスクに関する課題 \nテキスト生成AIのトレーニングデータには第三者の著作物が含まれる場合があり、 意図\nせず著作権を侵害する可能性があります。加えて、データが収集・処理される場合、個人情\n報保護法やGDPRなどの法規制に抵触する可能性もあり罰則や訴訟のリスクもあります。\nまた、テキスト生成AIにはトレーニングデータによってバイアス（偏り、偏見）が発生し\nてしまうことが懸念されています。システムのユーザがバイアスを含んだ回答を正しい情\n報として捉え、その情報を使用する場合、組織の信用失墜や法的トラブルに繋がる可能性\nもあります。 \n \n 攻撃に起因するリスク \nLLMを対象としたサイバー攻撃には多種多様な攻撃が存在しており、AI特有の被害を\n引き起こすサイバー攻撃がいくつか存在しています。 \n有名な攻撃として、LLMや学習データに関する情報の再構築を目的とした情報抽出攻撃\n（プライバシー攻撃） やLLMの応答動作を意図的に操作、 敵対的プロンプトを用いてLLM\nへの入力を誤分類させることを目的とした回避攻撃、LLMを汚染することで誤動作や性能\n劣化を引き起こすことを目的としたポイズニング攻撃などが存在します。 \n \nこのようにテキスト生成AIの組織導入においては、数多くのリスクを検討する必要があります。これ\nらのリスクのうち、導入・運用における内部リスクについては、第3章から第5章で留意事項を述べて\nいきます。 \n \n2.4 テキスト生成AIの組織導入・運用プロセスと担当者 \n本節では、後の第3章～第5章を読む上で、本書が定義する「生成AIの組織導入 ・運用プロセス」の\n全体像と担当者の役割について説明します。なお、以降ではテキスト生成AIを生成AIと呼称します。 \n2.4.1 導入・運用の前提事項 \n本節では、一般的な新技術導入についても当てはまりますが、生成AIの導入・運用プロセス全体を通\nして重要となる要素を以下の3点に分けて説明します。 \n① 段階的導入（スモールスタート） \n② ドキュメンテーション \n③ 継続的改善",
    "content_summary": "22 \n \n 法的および社会的リスクに関する課題 \nテキスト生成AIのトレーニングデータには第三者の著作物が含まれる場合があり、 意図\nせず著作権を侵害する可能性があります。加えて、データが収集・処理される場合、個人情\n報保護法やGDPRなどの法規制に抵触する可能性もあり罰則や訴訟のリスクもあります。\nまた、テキスト生成AIにはトレーニングデータによってバイアス（偏り、偏見）が発生し\nてしまうことが懸念されています。システムのユーザがバイアスを含んだ回答を正しい情\n報として捉え、その情報を使用...",
    "content_length": 895,
    "created_at": "2025-05-12T10:04:28.769504+00:00",
    "updated_at": "2025-05-12T10:04:28.769505+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[59]": {
    "status": "pending",
    "content": "57 \n \n \n図 5-5: 生成AIシステム構成例 \n \n5.3.2 特定の例 \nここからは、実際にリスクアセスメントの実施例を記載します。まず、リスク特定の実施例を説明しま\nす。 \n下記は、リスク特定の手順です。 \na) 資産の特定 \n組織で保有する資産（システム、データ、ネットワーク等）の棚卸を実施し、リスク管理を\n行う対象を明確にします。生成AIを新規導入する際であれば、既存の資産の棚卸に加え、\n生成AIシステムと関連するデータ・ネットワークを追加します。 \nb) リスクの特定 \n資産毎にどのようなリスクが存在するのか、 リスクの洗い出しを行います。例えば、 フィッ\nシング攻撃やDoS攻撃などの外部からのリスク、ユーザの過失や内部不正などの内部から\nのリスク等、様々な観点からリスクを洗い出します。",
    "content_summary": "57 \n \n \n図 5-5: 生成AIシステム構成例 \n \n5.3.2 特定の例 \nここからは、実際にリスクアセスメントの実施例を記載します。まず、リスク特定の実施例を説明しま\nす。 \n下記は、リスク特定の手順です。 \na) 資産の特定 \n組織で保有する資産（システム、データ、ネットワーク等）の棚卸を実施し、リスク管理を\n行う対象を明確にします。生成AIを新規導入する際であれば、既存の資産の棚卸に加え、\n生成AIシステムと関連するデータ・ネットワークを追加します。 \nb) リスクの特定 \n資産毎...",
    "content_length": 357,
    "created_at": "2025-05-12T10:04:28.769588+00:00",
    "updated_at": "2025-05-12T10:04:28.769588+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[48]": {
    "status": "pending",
    "content": "46 \n \n4.3.2 RAGを利用する場合の注意 \nLLMが学習していない内容のうちRAGを使用して精度の高い回答が得られるのは、ベクトルDBを\n検索して得られた質問に関連した上位数件のデータの内容のみです。そのため、ベクトルDBに格納さ\nれていない新しい情報について質問する場合や、ベクトルDBに古い情報や重複した情報が存在する場\n合には、誤った回答を生成する可能性が高くなります （図 4-9） 。そのため、RAGの精度の維持には、ベ\nクトルDBに格納されている情報の更新を定期的に行い、できるだけ最新かつ内容が重複しない状態に\n保つことが重要になります。 \n \n \n図 4-9: ベクトルDB内のデータが重複している場合 \n \nまた、ベクトルDBに格納されている情報の重要度に関しても考慮が必要です。注意点として、格\n納した情報はユーザ全員が閲覧する可能性があるため対象ユーザの役職と所属部署に適していること\nを確認する必要があります。 \n \n4.4 評価とフィードバック \n4.4.1 評価項目の策定 \n導入効果の評価とフィードバックを定期的に行うことが重要です。導入した生成AIを継続して使用し\n続けるかの判断や使用実績を踏まえたより効果的な活用のため、生成AIを導入した目的を振り返り、当\n初目的に対しての達成度合いや定量・定性的な効果を評価することが必要です。 \n生成AIの評価軸を以下に示します。 評価軸は導入目的によって異なるため、 以下に代表例を示します。",
    "content_summary": "46 \n \n4.3.2 RAGを利用する場合の注意 \nLLMが学習していない内容のうちRAGを使用して精度の高い回答が得られるのは、ベクトルDBを\n検索して得られた質問に関連した上位数件のデータの内容のみです。そのため、ベクトルDBに格納さ\nれていない新しい情報について質問する場合や、ベクトルDBに古い情報や重複した情報が存在する場\n合には、誤った回答を生成する可能性が高くなります （図 4-9） 。そのため、RAGの精度の維持には、ベ\nクトルDBに格納されている情報の更新を定期的に行い、できる...",
    "content_length": 639,
    "created_at": "2025-05-12T10:04:28.769562+00:00",
    "updated_at": "2025-05-12T10:04:28.769562+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[74]": {
    "status": "pending",
    "content": "72 \n \nまた、 開発手法としてはアジャイル開発が採用される傾向が見られました。これは、 現状、生成AI\nの導入に関するベストプラクティスが存在していないことに起因しており、自社に合った構成を手\n探りで検討する中で、結果的にアジャイル形式の開発手法が最も合理的な選択であったと考えられ\nます。 また、 生成AIはモデルの更新頻度が多いことや、 社会情勢の変化に対応する必要があるため、\n通常のシステム構築におけるウォーターフォール型ではなく、アジャイル型が開発手法として最も\n適しています。 \n \n6.1.2 セキュリティとガイドライン \n ヒアリング内容 \n生成AIを導入・運用する組織が、セキュリティ対策時に重点を置いたリスクや、具体的なセキュ\nリティ対策方法についてヒアリングを実施しました。また、組織における生成AIの利活用ガイドラ\nイン作成時に参考にした資料や考慮した点についてもヒアリングしました。 \n \n ヒアリング結果 \n組織が特に重視しているセキュリティリスクは情報漏洩とハルシネーションの2点でした。 \n \n 情報漏洩について \n情報漏洩は、全ての組織において最上位のリスクとして認識され、ガバナンス面・システム面の\n2つの側面から対策が実施されていました。 以下にて、 それぞれの組織が講じた対策を説明します。 \n \n ガバナンスにおける対策 \nガバナンスにおける対策として挙げられたのは、組織内の生成AIの取扱い方法や規則を記載\nしたガイドライン・ポリシーの作成です。ガイドラインを作成する上では、JDLAが2023年5\n月1日に発行した 「生成AIの利用ガイドライン」 やNISTが2023年1月に発表した 「AI RMF」 、\n既存の社内ガイドライン（クラウド規定）等を参考にされている傾向が見られました。今回ヒア\nリングを実施した組織では、クラウドサービスを活用して生成AIのシステムを利用することを\n前提としていたため、 クラウドに関する既存ルールと乖離がないかという観点が、 ガイドライン\n作成に重要であったという言及もありました。 \nまた、生成AI独自の観点として、入力内容がAI事業者・AI提供者に学習されてしまうとい\nうリスクを考慮し、オプトアウト可能なサービスを選定するという対策も講じられていました。 \n \n システムにおける対策 \nシステム面においてはログ管理によって、いつ、誰が、どのような内容を入力し、生成AIが\nどのような出力をしたのかを全て保管することで、万が一情報漏洩が発生した場合でも即座に\n原因究明が可能となるような対策が講じられていました。",
    "content_summary": "72 \n \nまた、 開発手法としてはアジャイル開発が採用される傾向が見られました。これは、 現状、生成AI\nの導入に関するベストプラクティスが存在していないことに起因しており、自社に合った構成を手\n探りで検討する中で、結果的にアジャイル形式の開発手法が最も合理的な選択であったと考えられ\nます。 また、 生成AIはモデルの更新頻度が多いことや、 社会情勢の変化に対応する必要があるため、\n通常のシステム構築におけるウォーターフォール型ではなく、アジャイル型が開発手法として最も\n適しています。 \n \n...",
    "content_length": 1107,
    "created_at": "2025-05-12T10:04:28.769630+00:00",
    "updated_at": "2025-05-12T10:04:28.769631+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[43]": {
    "status": "pending",
    "content": "41 \n \n生成AIからの生成物（回答）について \n生成AIが出力する回答については、以下の点に注意して取扱うことが重要です。 \n 生成物の解釈に関する注意 \n 誤りの確認（ハルシネーション） \n生成AIが提供する生成物には誤りが含まれる可能性があります。特に、生成物が現実には存\n在しない情報や事実と異なる内容を含む場合があるため、常にその正確性を確認する必要があ\nります。ハルシネーションの軽減策として、例えばRAGを活用する方法などが知られています\nが、完全に解消することはできないため、重ねてユーザに周知することが重要です。 \n \n図 4-5: 生成物にハルシネーションが含まれる例 \n \n 偏りの確認（バイアス） \n生成物にはモデルが使用した学習データに基づくバイアスが含まれる可能性があります。公\n平性を保つために、生成物が特定の視点に偏っていないか、差別的な表現が含まれていないか\n注意深く確認することが必要です。 \n \n図 4-6: 生成物にバイアスが含まれる例 \n \n 生成物の引用および外部公開に関する注意 \n 引用元の注釈 \n生成AIからの生成物を引用する場合は、生成AIにより生成した事実を明示することが求め\nられます。適切な引用元の注釈を行い、情報の出所を明らかにすることで、生成物の透明性を\n確保します。",
    "content_summary": "41 \n \n生成AIからの生成物（回答）について \n生成AIが出力する回答については、以下の点に注意して取扱うことが重要です。 \n 生成物の解釈に関する注意 \n 誤りの確認（ハルシネーション） \n生成AIが提供する生成物には誤りが含まれる可能性があります。特に、生成物が現実には存\n在しない情報や事実と異なる内容を含む場合があるため、常にその正確性を確認する必要があ\nります。ハルシネーションの軽減策として、例えばRAGを活用する方法などが知られています\nが、完全に解消することはできないため、重...",
    "content_length": 571,
    "created_at": "2025-05-12T10:04:28.769549+00:00",
    "updated_at": "2025-05-12T10:04:28.769550+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[19]": {
    "status": "pending",
    "content": "17 \n \n システムの構成 \n「フロントエンド」は、ユーザが直接見て操作する部分であり、Web UIが該当します。 「バックエン\nド」はLLMへの問い合わせを行う部分であり、LLMそのものや、ユーザとLLMの間の処理を行う統\n合ミドルウェアが該当します。統合ミドルウェアの例にはLangChainがあります。最後に「連携システ\nム」は、LLMへの問い合わせのほかにシステムに必要な処理に関係する部分を指し、RAGに使用するベ\nクトルDBや入出力内容のログを保管するサーバなどが該当します。 \n \n システムの処理 \nまず、ユーザがWeb UIを通してシステムへ質問や指示（プロンプト）を入力します。そのプロンプト\nは統合ミドルウェアに渡り、LLMへの問い合わせが行われます。問い合わせの際、プロンプトはLLM\nで処理可能にするため、トークンと呼ばれる形式に変換されます。RAGを使用する場合は、問い合わせ\nの前にベクトルDBへの検索が行われ、検索結果がプロンプトに追加されてからトークンへの変換と問\nい合わせが行われます。その後、LLMが出力した回答は統合ミドルウェアを経由してWeb UIに表示さ\nれ、ユーザは入力内容に対する回答を得ることができます。 \n \n2.2 テキスト生成AIの組織活用 \n2.2.1 組織活用可能な場面 \nテキスト生成AIは一般企業等を含め多様な組織での普及が進み、さまざまな業務への活用が始まって\nいます。ここでは、有効に活用できる場面として、大きく3つの区分を紹介します。 \n \n 業務の効率化 \nテキスト生成AIは、人手を介さず高速に自然言語処理を提供できるため、文章の校正、資料の\n要約、Excelマクロのコード生成等、作業時間の短縮およびコスト削減、品質向上に寄与すること\nが期待されます。 \n \n 意思決定の補助 \nテキスト生成AIは、 大量のデータを素早く分析してさまざまな観点からの示唆を提示できるた\nめ、過去事例や公開情報の調査、必要な情報の抽出等、 意思決定プロセスを強力に支援することが\n期待されます。 \n \n 新事業の提案補助 \nテキスト生成AIは既存データ （市場の売り上げ等）から新しいアイデアのブレーンストーミン\nグの補助が可能なため、ソリューションの提案や近年の需要が高いソリューション傾向の抽出等\nの新たな事業機会の創出や新規サービスの構想策定に活用されることが期待されます。",
    "content_summary": "17 \n \n システムの構成 \n「フロントエンド」は、ユーザが直接見て操作する部分であり、Web UIが該当します。 「バックエン\nド」はLLMへの問い合わせを行う部分であり、LLMそのものや、ユーザとLLMの間の処理を行う統\n合ミドルウェアが該当します。統合ミドルウェアの例にはLangChainがあります。最後に「連携システ\nム」は、LLMへの問い合わせのほかにシステムに必要な処理に関係する部分を指し、RAGに使用するベ\nクトルDBや入出力内容のログを保管するサーバなどが該当します。 \n \n...",
    "content_length": 1025,
    "created_at": "2025-05-12T10:04:28.769492+00:00",
    "updated_at": "2025-05-12T10:04:28.769493+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[11]": {
    "status": "pending",
    "content": "9 \n \n本書は、生成AIのセキュリティリスクと適切な対策を示すことで、組織における生成AI利用の不安\n感を払拭し、安全な導入と運用を促進することを目的とします。今後、ますます重要になると予想される\n生成AIですが、本書を活用することで、適切なリスク管理を施し、安全で効果的な活用ができるように\nなることを期待します。 \n \n1.3 本書のスコープ \nまず、本書の対象読者は、総務省・経済産業省発行の「AI事業者におけるガイドライン第1版」 [6]\n（以降、AIガイドライン）における 「AI利用者」とします。 「AI利用者」の中でも特に、 「組織が管理す\nる生成AIを導入・運用・管理を行う担当者」に焦点を当てています。 \nなお、AIガイドラインでは、 「AIの事業活動を担う主体」を、 「AI利用者」に加えて 「AI提供者」 、 「AI\n開発者」と、3者に大別しています。参考までに、それぞれの定義を以下に引用します。 \n \n AI利用者（AI Business User） \n事業活動において、AIシステム又はAIサービスを利用する事業者 \nAI提供者が意図している適正な利用を行い、環境変化等の情報をAI提供者と共有し正常稼\n働を継続すること又は必要に応じて提供されたAIシステムを運用する役割を担う。また、AI\nの活用において業務外利用者に何らかの影響が考えられる場合は、当該者に対するAIによる\n意図しない不利益の回避、AIによる便益最大化の実現に努める役割を担う。 \n \n AI提供者（AI Provider） \nAIシステムをアプリケーション、製品、既存のシステム、ビジネスプロセス等に組み込んだ\nサービスとしてAI利用者（AI Business User） 、場合によっては業務外利用者に提供する事業\n者 \nAIシステム検証、AIシステムの他システムとの連携の実装、AIシステム・サービスの提供、\n正常稼働のためのAIシステムにおけるAI利用者（AI Business User）側の運用サポート又は\nAIサービスの運用自体を担う。AIサービスの提供に伴い、様々なステークホルダとのコミュ\nニケーションが求められることもある。 \n \n AI開発者（AI Developer） \nAIシステムを開発する事業者（AIを研究開発する事業者を含む） \nAIモデル・アルゴリズムの開発、データ収集（購入を含む） 、前処理、AIモデル学習及び検\n証を通してAIモデル、AIモデルのシステム基盤、入出力機能等を含むAIシステムを構築す\nる役割を担う。 \n \n（総務省・経済産業省,2024, p.5）",
    "content_summary": "9 \n \n本書は、生成AIのセキュリティリスクと適切な対策を示すことで、組織における生成AI利用の不安\n感を払拭し、安全な導入と運用を促進することを目的とします。今後、ますます重要になると予想される\n生成AIですが、本書を活用することで、適切なリスク管理を施し、安全で効果的な活用ができるように\nなることを期待します。 \n \n1.3 本書のスコープ \nまず、本書の対象読者は、総務省・経済産業省発行の「AI事業者におけるガイドライン第1版」 [6]\n（以降、AIガイドライン）における 「AI利用者」...",
    "content_length": 1105,
    "created_at": "2025-05-12T10:04:28.769473+00:00",
    "updated_at": "2025-05-12T10:04:28.769473+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[36]": {
    "status": "pending",
    "content": "34 \n \n3.2.6 回答精度向上における選択肢 \n生成AIの課題の1つとして、LLMが学習していないデータに関する回答の精度が大きく低下する点\nが挙げられます。例えば、インターネットに掲載されていない社内ドキュメントのようなデータ、専門性\nの高いデータ、LLM作成時点では公開されていない最新のデータなどに関する質問に正確に回答するこ\nとは困難です。この課題への代表的な対策としてはファインチューニングとRAG （Retrieval-Augmented \nGeneration）の2つの技術が存在します（詳細については2.1.3「テキスト生成AIの回答精度向上のた\nめの技術」を参照ください） 。 \nファインチューニングとRAGの効果は単純に比較することは難しいですが、Microsoftの検証結果で\nは、RAGのほうがファインチューニングよりも優れたパフォーマンスを発揮するとされています [15]。\nまた、2024年6月時点では導入難易度の観点においてもRAGのほうに優位性があり、組織での活用が\nより現実的であるとされています。しかし、RAGを利用することの優位性を保つためには、いくつか注\n意すべき点も存在します。例えば、時間が進むにつれて、学習させた情報は古くなっていくため、回答精\n度を安定させるためにはRAGに使用するデータを必要に応じて更新することが重要です。 \nまた、セキュリティとプライバシーの観点から、RAGに使用するデータに機密情報や個人情報が含ま\nれる場合、適切なアクセス制限やデータの定期的な棚卸が重要です。さらに、RAGをはじめとする生成\nAIに関する技術は、その進化が著しいため、常にその動向を注視することが重要です。 \n \n3.3 設計・開発 \n設計・開発のフェーズで、導入担当者は、要件定義の内容を設計書に落とし込み、設計内容を共有が必\n要な関係各位2に伝えます。設計の詳細は組織によって異なるため、ここでは一般的な考慮事項について\n記載します。 \n \n3.3.1 導入ベンダへのフィードバック \n生成AIの導入において、自社独自で設計および開発を実行できる組織は少なく、実際の導入時には主\nに導入ベンダが設計および開発を担当することが多くなると想定されます。 \n導入ベンダは事前に定めた要件定義に沿って設計・開発を進めますが、 組織の社内規定やポリシーに沿\nっているか適宜確認していく必要があります。各組織によって部署が管轄する範囲は異なりますが、導\n入担当者が運用担当者およびセキュリティ担当者の意見を収集し、導入ベンダへフィードバックしてい\nくことが重要です。 \n \n \n2 設計・開発者は組織の内部の者である場合もあれば、外部の者（外注）である場合もある。また、導\n入者＝設計・開発者の場合もある。",
    "content_summary": "34 \n \n3.2.6 回答精度向上における選択肢 \n生成AIの課題の1つとして、LLMが学習していないデータに関する回答の精度が大きく低下する点\nが挙げられます。例えば、インターネットに掲載されていない社内ドキュメントのようなデータ、専門性\nの高いデータ、LLM作成時点では公開されていない最新のデータなどに関する質問に正確に回答するこ\nとは困難です。この課題への代表的な対策としてはファインチューニングとRAG （Retrieval-Augmented \nGeneration）の2つの技術が存在...",
    "content_length": 1173,
    "created_at": "2025-05-12T10:04:28.769533+00:00",
    "updated_at": "2025-05-12T10:04:28.769533+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[44]": {
    "status": "pending",
    "content": "42 \n \n 著作権（※2024年6月時点の情報） [23] \n生成AIが提供する生成物は著作物に該当しない場合があります。著作物は「思想又は感情を\n創作的に表現したものであつて、文芸、学術、美術又は音楽の範囲に属するもの」 （文化庁, 2023, \np.56） とされており、 生成AIの生成物は 「思想又は感情を創作的に表現したもの」 （文化庁, 2023, \np.57）ではないためです。一方で、人が思想感情を創作的に表現するための道具としてAIを使\n用したものと認められれば、 著作物に該当し、 生成AIのユーザが著作者となる場合もあります。\n生成物の著作権に関しては現在も議論が進められているため、常に動向を調査する必要があり\nます。 \n 商用利用の制限 \n生成物の商用利用は、利用する生成AIの利用規約により制限されている場合があります。商\n用利用する際は、必要に応じて許可を得ることが求められます。 \n 権利侵害の確認 \n生成物が以下に該当しないことを確認する必要があります。 \n- 著作権侵害：既存のキャッチコピーや他者の著作物と類似していないか確認します。 \n- 商標権、意匠権侵害：他者の商標や意匠を侵害していないか確認します。 \n- 虚偽の個人情報・名誉毀損：生成物が虚偽の情報を含んでいないか、または個人や団体の\n名誉を毀損する内容でないかを確認します。 \n \n4.2 ユーザへの教育 \n4.2.1 教育によって期待される効果 \n生成AIを効果的に活用するためには、生成AI自体の性能だけでなく、ユーザが適切に生成AIを利用\nすることが必要不可欠です。ユーザが生成AIに関する正しい知識を身に付け適切に活用することによっ\nて、以下に示す2点の効果を得られます。 \n \n 生成AI利用における倫理観およびセキュリティ意識の醸成 \nユーザが生成AIの使用において、 コンプライアンスに留意して知識を深めることで、AIの利用\nにおける倫理観が醸成され、企業の信用失墜のリスクを軽減できます。 \n \n 業務効率の向上 \nユーザが生成AIの操作方法や効果的な使用方法を習得することで、業務の効率化を図り、業務\nプロセスの迅速化と生産性の向上が期待されます。",
    "content_summary": "42 \n \n 著作権（※2024年6月時点の情報） [23] \n生成AIが提供する生成物は著作物に該当しない場合があります。著作物は「思想又は感情を\n創作的に表現したものであつて、文芸、学術、美術又は音楽の範囲に属するもの」 （文化庁, 2023, \np.56） とされており、 生成AIの生成物は 「思想又は感情を創作的に表現したもの」 （文化庁, 2023, \np.57）ではないためです。一方で、人が思想感情を創作的に表現するための道具としてAIを使\n用したものと認められれば、 著作物に該当...",
    "content_length": 940,
    "created_at": "2025-05-12T10:04:28.769552+00:00",
    "updated_at": "2025-05-12T10:04:28.769553+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[9]": {
    "status": "pending",
    "content": "7 \n \n1.1.4 課題 \nAIの中でも、特に生成AIの加速度的な普及の流れには目を見張るものがあります。一般財団法人\nJIPDECが実施した「企業IT利活用動向調査2024」における生成AI使用状況に関するアンケート結果\nによると、 全体の69.5%が生成AIを導入済みまたは導入予定と回答しており、 今後も企業による生成AI\n利用の流れはさらに加速していくと想定されます（図 1-3） 。 \n \n \n図 1-3: 生成AIの使用状況 [4] \n（出典）JIPDEC／ITR「企業IT利活用動向調査2024」p20 \n \n生成AIが普及し、利用開始 ・導入検討している組織も多い一方で、さまざまな課題から導入に踏み切\nれない組織も存在します。 これは、 生成AI導入のために解決すべき課題が数多く存在するにも関わらず、\n企業にとってそれらの多くは未知の課題であり、課題の把握と対策方法の明確化ができていないことが\n原因ではないでしょうか。",
    "content_summary": "7 \n \n1.1.4 課題 \nAIの中でも、特に生成AIの加速度的な普及の流れには目を見張るものがあります。一般財団法人\nJIPDECが実施した「企業IT利活用動向調査2024」における生成AI使用状況に関するアンケート結果\nによると、 全体の69.5%が生成AIを導入済みまたは導入予定と回答しており、 今後も企業による生成AI\n利用の流れはさらに加速していくと想定されます（図 1-3） 。 \n \n \n図 1-3: 生成AIの使用状況 [4] \n（出典）JIPDEC／ITR「企業IT利活用動向調...",
    "content_length": 421,
    "created_at": "2025-05-12T10:04:28.769468+00:00",
    "updated_at": "2025-05-12T10:04:28.769469+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[58]": {
    "status": "pending",
    "content": "56 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1）表 5-1が10大脅威の概要です（説明の都合上、一部内\n容を修正） 。表中の「影響範囲」は、生成AIシステムのどこでそのリスクが顕現するかを表します（図 \n5-5のアルファベットa～iおよび数字I～VIで、システム内の箇所を示します） 。 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1） [11] \n \nNo リスク 概要 影響範囲\n001プロンプト・インジェクション巧妙な入力によって大規模な言語モデル（LLM）を操作し、LLMが意図しない動作を引き起こします。システムのプロンプトを直接、上書きする手法、外部ソースからの入力を操作し、間接的に行う手法があります。a,b,g\n002安全が確認されていない出力ハンドリングLLMの出力を細かくチェックせずに連携システムに送った場合、システムの脆弱性をつかれ、意図しない結果を引き起こすことです。悪用されると、XSS、CSRF、SSRF、特権の昇格、リモート・コードの実行といった深刻な結果につながる可能性があります。d,h \n003 訓練データの汚染LLMの訓練データが改ざんされ、セキュリティ、有効性、倫理的行動を損なう脆弱性やバイアスなどが入り込むことです。訓練データの情報源として、CommonCrawl、WebText、OpenWebText、書籍などが使われます。今回のシステム上には該当しない\n004 モデルのDoSLLMが計算リソースを大量に消費するようにしむけ、LLMを使ったサービスの品質低下や高コストを狙ったものです。b,g\n005サプライチェーンの脆弱性LLMアプリケーションが使用するコンポーネントやサービスの脆弱性によって引き起こされる攻撃です。サードパーティのデータセット、事前に訓練されたモデル、およびプラグインを使用することで脆弱性が増す可能性があります。 Ⅱ,Ⅲ,Ⅳ,Ⅴ,Ⅵ\n006 機微情報の漏えいLLMはその応答の中に意図せず機密データを含めてしまう可能性があり、不正なデータアクセス、プライバシー侵害、セキュリティ侵害につながります。これを軽減するためには、データの浄化と厳格なユーザー・ポリシーを導入することが極めて重要です。b,d,h\n007安全が確認されていないプラグイン設計LLMプラグインにおいて、入力の安全性が確認されておらず、あるいはアクセスコントロールが不十分な場合、悪意のあるリモート・コード実行のような結果をもたらす可能性があります。Ⅲ\n008 過剰な代理行為この問題は、LLMベースのシステムに与えられた過剰な機能、権限、または自律性に起因し、意図しない結果を招くことがあります。Ⅱ,Ⅲ,Ⅴ,Ⅵ\n009 過度の信頼十分監督されていないLLMに過度に依存したシステムやユーザーは、LLMが生成したコンテンツが不正確または不適切なものであることに気づかず、誤った情報、誤ったコミュニケーション、法的問題、セキュリティの脆弱性に直面する可能性があります。i\n010 モデルの盗難独自のLLMモデルへの不正アクセス、モデルのコピー、または流出が含まれます。その影響は、経済的損失、競争上の優位性の低下、機密情報へのアクセスの可能性などです。a,Ⅳ",
    "content_summary": "56 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1）表 5-1が10大脅威の概要です（説明の都合上、一部内\n容を修正） 。表中の「影響範囲」は、生成AIシステムのどこでそのリスクが顕現するかを表します（図 \n5-5のアルファベットa～iおよび数字I～VIで、システム内の箇所を示します） 。 \n \n表 5-1: OWASP Top 10 for LLM （ver. 1.1） [11] \n \nNo リスク 概要 影響範囲\n001プロンプト・インジェクション巧妙な入...",
    "content_length": 1387,
    "created_at": "2025-05-12T10:04:28.769585+00:00",
    "updated_at": "2025-05-12T10:04:28.769586+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[22]": {
    "status": "pending",
    "content": "20 \n \n2.3.2 AI システムの組織導入における信頼性 \nテキスト生成AIに限らず、システムを組織に導入する上で、組織の人間が動作について信頼性の高い\nシステムを目指すことは重要な要素であると考えます。 \nNISTのAI RMFでは、信頼できるAIシステムの特徴を7つの観点で整理しています（表 2-1） 。AI\nシステムを使用する環境や状況に応じてこの7 つのバランス（どこに重点を置くか）は異なるため、各\n項目単体ではなく全ての項目を考慮することが適切なリスク管理に繋がります。 \n \n表 2-1: 信頼できる AI システムの特徴 [7] \n \n※1：①はシステムの基本動作に影響を与える項目の為、②から⑥までに関わる形で表記する。 \n※2：⑦は他者への説明責任や情報の開示などの運用面での特徴について記載している。 \n \n信頼できるAIシステムの重要性はテキスト生成AIにおいても変わりません。組織でのテキスト生成\nAI導入では、この7つの観点をもとにリスクを軽減し、信頼できるAIシステムを目指すことが推奨さ\nれます。 \n \n  \n概要①有効性/信頼性※1故障することなく、意図したとおりに動作している状態②安全性人間の生命、健康、財産、環境が危険にさらされていない状態③セキュリティと回復力機密性や完全性、可用性などを維持する仕組みを保っている状態、予期せぬ事態から回復できる状態④説明可能かつ解釈可能AIシステムの動作の根底にあるメカニズムを言語化でき、アウトプットが解釈できる状態⑤プライバシー保護個人情報やプライバシーが保護されている状態⑥公平性（有害なバイアス管理）偏見や差別による影響がなく、平等性や公平性に配慮されている状態⑦説明責任と透明性※2AIシステムのライフサイクルに応じた適切なレベルの情報へのアクセスを提供できる状態\n信頼できるAIシステムの特徴",
    "content_summary": "20 \n \n2.3.2 AI システムの組織導入における信頼性 \nテキスト生成AIに限らず、システムを組織に導入する上で、組織の人間が動作について信頼性の高い\nシステムを目指すことは重要な要素であると考えます。 \nNISTのAI RMFでは、信頼できるAIシステムの特徴を7つの観点で整理しています（表 2-1） 。AI\nシステムを使用する環境や状況に応じてこの7 つのバランス（どこに重点を置くか）は異なるため、各\n項目単体ではなく全ての項目を考慮することが適切なリスク管理に繋がります。 \n \n表...",
    "content_length": 795,
    "created_at": "2025-05-12T10:04:28.769499+00:00",
    "updated_at": "2025-05-12T10:04:28.769500+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[33]": {
    "status": "pending",
    "content": "31 \n \nOWASPのLLM AI Cybersecurity & Governance Checklist v1.1では、モデルの利用方法の観点から、\n導入方法が6つのタイプで分類されています （図 3-2） [11] [14]。 本書では、OWASPの分類をもとに、\n以下6 つの利用方法を定義します。それぞれの利用方法の特徴を理解し、自組織の環境や目的に合った\n導入方法を選択することが重要です。 \n \n \n図 3-2: モデルの利用方法 \n \n生成AIシステムの構築環境の選択 \n3.2.5ではモデルの利用方法について説明しました。本項では選択したモデルの導入環境について説明\nします。組織にエンタープライズ向けの生成AIを導入する場合、導入環境は「オンプレミス型 （以下オ\nンプレと表記）」「クラウド型」「ハイブリッド型 （API利用） 」の3つに分類できます（図 3-3） 。各導入\n環境の特徴を理解し、導入目的に合った導入環境を選択することが重要です。 \n \n \n図 3-3: 生成AIの構築環境",
    "content_summary": "31 \n \nOWASPのLLM AI Cybersecurity & Governance Checklist v1.1では、モデルの利用方法の観点から、\n導入方法が6つのタイプで分類されています （図 3-2） [11] [14]。 本書では、OWASPの分類をもとに、\n以下6 つの利用方法を定義します。それぞれの利用方法の特徴を理解し、自組織の環境や目的に合った\n導入方法を選択することが重要です。 \n \n \n図 3-2: モデルの利用方法 \n \n生成AIシステムの構築環境の選択 \n3.2.5...",
    "content_length": 456,
    "created_at": "2025-05-12T10:04:28.769525+00:00",
    "updated_at": "2025-05-12T10:04:28.769526+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[95]": {
    "status": "pending",
    "content": "93 \n \n \nベクトルDB 情報をデータオブジェクトの数値表現であるベクトルとして\n保存するデータベース。生成AIが扱う非構造化データの格\n納・管理・照会で利用される。 \nベンチマークテスト ハードウェアおよびソフトウェアの処理性能、AIの回答精\n度などを定量的に評価するための基準となるテストのこと。 \nポイズニング攻撃 LLMを汚染することで誤動作や性能劣化を引き起こすこと\nを目的とした攻撃手法。 \nマルウェア コンピュータやそのユーザに被害をもたらすことを目的とし\nた、悪意のあるソフトウェア。 \nAIモデル あらかじめ収集されたデータや入力データの中に存在するパ\nターンや相関関係を学習したもの。未知のデータやプロンプ\nトを与えた際に学習した結果から予測や判別、データの生成\nを行う。 \nラガード イノベーター理論におけるユーザ層の5つの区分のうち、最\nも遅く新製品・サービスを採用する層で、ユーザの約16%\nを占めている。世の中の動きに関心が薄く、流行が一般化し\nてからそれを採用する、最も保守的・伝統的な層。 \nランサムウェア 感染するパソコンなどに保存されているデータを暗号化して\n使用できなくした上で、そのデータを復号する対価（金銭や\n暗号資産など）を要求する不正プログラムのこと。 \nリージョン クラウドサービスにおいて、サービスを提供する拠点を地理\n的に近いものでグループ化したもの。ユーザは利用するリー\nジョンを選択して、仮想サーバやストレージを利用すること\nができる。 \nレイトマジョリティ イノベーター理論におけるユーザ層の5つの区分のうち、2\n番目に遅く新製品・サービスを採用する層で、ユーザの約\n34%を占めている。新製品や新技術の採用には懐疑的で、周\n囲の大多数が採用している場面を見てから採用する層。 \n安全保障貿易管理（輸出管理） 武器や軍事転用可能な貨物・技術が、国家および国際社会の\n安全性を脅かす国家やテロリスト等、懸念活動を行うおそれ\nのある者に渡ることを防ぐため、先進国を中心とした国際的\nな枠組みを作り、国際社会と協調して輸出等の管理を実施す\nること。 \n回避攻撃 敵対的サンプルを利用してAIの誤認識を発生させる攻撃手\n法。",
    "content_summary": "93 \n \n \nベクトルDB 情報をデータオブジェクトの数値表現であるベクトルとして\n保存するデータベース。生成AIが扱う非構造化データの格\n納・管理・照会で利用される。 \nベンチマークテスト ハードウェアおよびソフトウェアの処理性能、AIの回答精\n度などを定量的に評価するための基準となるテストのこと。 \nポイズニング攻撃 LLMを汚染することで誤動作や性能劣化を引き起こすこと\nを目的とした攻撃手法。 \nマルウェア コンピュータやそのユーザに被害をもたらすことを目的とし\nた、悪意のあるソフトウェ...",
    "content_length": 939,
    "created_at": "2025-05-12T10:04:28.769687+00:00",
    "updated_at": "2025-05-12T10:04:28.769688+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[8]": {
    "status": "pending",
    "content": "6 \n \n表 1-1: 生成AIが普及するまでの人工知能（AI）の歴史 [3] \n \n \n1.1.3 ディープラーニングの発展 \nここまで述べた半世紀以上の技術的発展に加え、既に述べた「ディープラーニング（機械学習を含む）\nの発展」のほかに、 「コンピュータ計算性能の向上」や「ビッグデータ」の出現が近年のAIの急速な発\n展・普及につながっています。 \n「コンピュータ計算性能の向上」は、回路の集積率に比例して性能が向上することから、大規模集積回\n路の進化と言い換えることができます。インテル社の共同創設者であるゴードン・ムーア氏が提言した\n「ムーアの法則」では、半導体の集積率は18か月ごとに2倍に増加すると謳われており、現在に至るま\nで指数関数的に性能が向上しています。 また、GPUの使用による複雑な並列計算が可能となったことも、\n計算性能向上の要因として知られています。 \n次に高速通信網の整備やクラウド技術の発展などを背景に 「ビッグデータ」という概念が生まれたこと\nにより、初期投資を抑制しつつ、膨大で多様なデータを安全かつ簡単に蓄積できようになりました。ま\nた、このデータ利用の敷居の低下に伴い、専門機関でなくとも、機械学習モデルの学習や検証が可能とな\nったことも、AIの発展・普及に大きく寄与したものと考えられます。 \n年代 年 AIに関する出来事 主な技術等1950アラン・チューリングが「チューリングテスト」を提唱し、機械が知能を持っているかどうかを評価する基準を設定1956ダートマス会議で「人工知能」という用語が初めて使われ、AI研究の分野が正式に誕生1960年代1964 人工対話システムELIZA開発1972 初のエキスパートシステムMUCIN開発MYCINの知識表現と推論を一般化したEMYCIN開発ディープラーニングの基本構造の一つ「ネオコグニトロン」が考案1982～92 第5世代コンピュータプロジェクト1984 知識記述のプロジェクト開始1986 誤差逆伝播法の発表1989 CNN（畳み込みニューラルネットワーク）が発表1990年代 1997 IBMが開発したディープブルーが、世界チェスチャンピオンに勝利2000年代2006 ディープラーニングの提唱2012 ディープラーニングの提唱技術を画像認識コンテストに適用2017 Googleの研究者らが深層学習モデル「Transformer」を発表2018 OpenAIが大規模言語モデル「GPT」を開発2022 OpenAIが対話型AIサービス「ChatGPT」を発表2023OpenAIのみならず様々な企業の大規模言語モデルが登場（Meta社,Llama2、Anthropic社,Claude2等）\n2024～上記大規模言語モデルの発展バージョンが多く公開され、急速に開発が進んでいる\n・Transformer・GPT・BERT・大規模言語モデル（LLM）2020年代\n1950年代\n2010年代 ・機械学習・ディープラーニング\n19791970年代\n・探索、推論・自然言語処理・ニューラルネットワーク・遺伝的アルゴリズム・エキスパートシステム\n1980年代 ・知識ベース・音声認識・データマイニング・オントロジー・統計的自然言語処理",
    "content_summary": "6 \n \n表 1-1: 生成AIが普及するまでの人工知能（AI）の歴史 [3] \n \n \n1.1.3 ディープラーニングの発展 \nここまで述べた半世紀以上の技術的発展に加え、既に述べた「ディープラーニング（機械学習を含む）\nの発展」のほかに、 「コンピュータ計算性能の向上」や「ビッグデータ」の出現が近年のAIの急速な発\n展・普及につながっています。 \n「コンピュータ計算性能の向上」は、回路の集積率に比例して性能が向上することから、大規模集積回\n路の進化と言い換えることができます。インテル社の共同...",
    "content_length": 1362,
    "created_at": "2025-05-12T10:04:28.769465+00:00",
    "updated_at": "2025-05-12T10:04:28.769466+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[96]": {
    "status": "pending",
    "content": "94 \n \n学習データ 機械学習モデルを学習させる上で必要となる情報のこと。 \n一般的な機械学習では、回答精度を高める上で重要な役割を\n担う。特に生成AIに関しては、学習データの品質が回答精\n度に大きく影響を与える。 \n間接プロンプトインジェクション 攻撃者が事前にウェブサイトや画像といったデータに悪意の\nある指示文を紛れ込ませ、Webクロールを行う生成AIに学\n習あるいは一般ユーザに悪意のあるプロンプト入力を誘導す\nるという手法。 \n機械学習 コンピュータがデータを自動で学習し、データの背景にある\nルールやパターンを発見する方法。 \n個人情報保護法 個人情報の有用性に配慮しながら、個人の権利や利益を守る\nことを目的とした法律。 \n（正式名称：個人情報の保護に関する法律） \n自然言語処理 コンピュータが、人間が使う日常の言葉の解釈を1つに絞り\nながら、できるだけ自然に意味を把握するための技術。 \n情報抽出攻撃（プライバシー攻撃） LLMや学習データに関する情報を再構築し盗むことを目的\nとした攻撃。 \n多層防御（Defense in Depth） 単一の防御策に頼るのではなく、複数の異なる防御策を実施\nすることでセキュリティを強化する手法。 \n大規模集積回路 半導体集積回路（IC）の中でも素子数が1000以上のもの。 \nLSI（Large Scale Integrated circuit）とも呼ばれる。 \n段階的導入（スモールスタート） サービスやソフトウェアを部署や業務単位など小規模な範囲\nでの導入を開始し、順次導入範囲を広げていく導入手法。 \n透明性 AIシステムにおける意思決定および回答のプロセスや使用\nした学習データを第三者が確認できる状態。 \n特権の昇格 システムなどで管理者権限などの本来割り当てられていない\n権限を不正に取得する攻撃手法。",
    "content_summary": "94 \n \n学習データ 機械学習モデルを学習させる上で必要となる情報のこと。 \n一般的な機械学習では、回答精度を高める上で重要な役割を\n担う。特に生成AIに関しては、学習データの品質が回答精\n度に大きく影響を与える。 \n間接プロンプトインジェクション 攻撃者が事前にウェブサイトや画像といったデータに悪意の\nある指示文を紛れ込ませ、Webクロールを行う生成AIに学\n習あるいは一般ユーザに悪意のあるプロンプト入力を誘導す\nるという手法。 \n機械学習 コンピュータがデータを自動で学習し、データの背景に...",
    "content_length": 787,
    "created_at": "2025-05-12T10:04:28.769689+00:00",
    "updated_at": "2025-05-12T10:04:28.769690+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[70]": {
    "status": "pending",
    "content": "68 \n \n特定の話題に応答しないようにする機能 \n特定の話題に応答しないようにガードレールを設定する場合、担当者が特定のキーワードやフレーズ\nを指定（図 5-14）し、それに基づいてAIモデルが応答を回避するように設定します。この設定により、\n設定した話題に関連する質問やコメントを受けた場合、予め決められた無害な応答を返すか、その話題\nに関しては応答を避けるようになります。 \n \n図 5-14: 政治に関する情報を制限する設定（Colang7形式） \n \n「deﬁne user ask about politics」では、制限したい話題に関連するキーワードやフレーズを登録するこ\nとができます。検索にはベクトル検索8が使用されているため、プロンプト文で全く同じ文章やキーワー\nドを入力せずとも似たような文章であれば、検知することができます。また、検知した際のユーザへの返\n答は、 「deﬁne bot refuse to about politics」で設定が可能です。ここで、 「politics」は、担当者が適宜設定\nする変数です。 \n実際に図 5-14で政治に関する制限をした後に、 チャットアプリにて政治に関する内容をプロンプト文\nに入力し問い合わせると、制限されていることがわかります（図 5-15） 。 \n \n図 5-15: 政治に関する話題が制限されているイメージ \n  \n \n7 会話型アプリケーション用のモデリング言語。 \n8 テキストや画像などのデータを数値ベクトルとして表現し、それらのベクトル間のコサイン類似度を\n計算することで、関連する情報を見つけ出す検索方法のこと。",
    "content_summary": "68 \n \n特定の話題に応答しないようにする機能 \n特定の話題に応答しないようにガードレールを設定する場合、担当者が特定のキーワードやフレーズ\nを指定（図 5-14）し、それに基づいてAIモデルが応答を回避するように設定します。この設定により、\n設定した話題に関連する質問やコメントを受けた場合、予め決められた無害な応答を返すか、その話題\nに関しては応答を避けるようになります。 \n \n図 5-14: 政治に関する情報を制限する設定（Colang7形式） \n \n「deﬁne user ask abo...",
    "content_length": 701,
    "created_at": "2025-05-12T10:04:28.769614+00:00",
    "updated_at": "2025-05-12T10:04:28.769615+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[17]": {
    "status": "pending",
    "content": "15 \n \n2.1.3 テキスト生成AIの回答精度向上のための技術 \nテキスト生成AIの課題の1つとして、LLMが学習していないデータに関する回答は精度が著しく低\n下することが挙げられます。例えばインターネットに掲載されていない社内ドキュメントのようなデー\nタや専門性の高いデータ、LLMが作成された時点では公開されていない最新のデータなどに関する質問\nに正確に回答することは困難です。この課題を克服するために技術開発が進められており、本項ではそ\nの技術の中でもファインチューニングとRAG （Retrieval-Augmented Generation、検索拡張生成）の2つ\nについて紹介します。 \n \n① ファインチューニング \nファインチューニングは、学習済みのモデルに対して新たなデータを膨大なリソースと時間を使\n用して追加で学習させる技術で、LLMに限らずディープラーニングで作成されたモデルには広く用\nいられています。この技術により汎用的なモデルを特定の分野に特化させることができ、ファイン\nチューニングしたLLMを使用することで新たに学習させたデータに関する回答精度を向上させる\nことができます。 \nファインチューニングを行うにあたり、学習させるデータの量と質が性能に大きく影響するため、\nノイズや重複の削除などを行ったデータを大量に用意することが重要になります。また、学習内容\nを特化させた分、汎用性が低下する可能性がある点にも注意が必要です。 \n \n \n図 2-3: ファインチューニングの概要",
    "content_summary": "15 \n \n2.1.3 テキスト生成AIの回答精度向上のための技術 \nテキスト生成AIの課題の1つとして、LLMが学習していないデータに関する回答は精度が著しく低\n下することが挙げられます。例えばインターネットに掲載されていない社内ドキュメントのようなデー\nタや専門性の高いデータ、LLMが作成された時点では公開されていない最新のデータなどに関する質問\nに正確に回答することは困難です。この課題を克服するために技術開発が進められており、本項ではそ\nの技術の中でもファインチューニングとRAG （Ret...",
    "content_length": 656,
    "created_at": "2025-05-12T10:04:28.769487+00:00",
    "updated_at": "2025-05-12T10:04:28.769488+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[63]": {
    "status": "pending",
    "content": "61 \n \n5.4.1 多層防御 \n多層防御（Defense in Depth）は、単一の防御策に頼るのではなく、複数の異なる防御層を設けること\nでセキュリティを強化する手法です。この手法は、各防御層がそれぞれ異なる種類の脅威に対応し、他の\n層が失敗した場合でもシステム全体の保護が維持されるように設計されています。多層防御の基本的な\n考え方は、攻撃者がシステムに侵入する際に直面する障壁を増やすことです（図 5-8） 。 \n \n図 5-8: 多層防御の考え方（スイスチーズモデル） \n \nこれにより、 攻撃者が攻撃を成功させるためには、 複数のセキュリティ対策を突破しなければならず、\n攻撃の難易度とコストが大幅に上昇します。また、攻撃を早期に検知し、対応するための時間を確保する\nことも可能になります。 \n多層防御は一般的に以下3つの対策の組合せとなります。 \n 侵入を防ぐための入口対策 \n 侵入されたことを検知して被害の拡大を防ぐための内部対策 \n 情報の流出を防ぐための出口対策 \nこれら複数の対策により、システム全体のセキュリティを向上できます。 \n \n入口対策 \n入口対策では、ユーザがフロントエンドにあるWeb UIに入力したプロンプト文をバックエンドへ送\nる場所での対策を考えます。図 5-5のシステム構成図における入口対策の場所を、図 5-9に緑色の盾マ\nークで示します。 \n \n図 5-9: 入口対策場所のイメージ",
    "content_summary": "61 \n \n5.4.1 多層防御 \n多層防御（Defense in Depth）は、単一の防御策に頼るのではなく、複数の異なる防御層を設けること\nでセキュリティを強化する手法です。この手法は、各防御層がそれぞれ異なる種類の脅威に対応し、他の\n層が失敗した場合でもシステム全体の保護が維持されるように設計されています。多層防御の基本的な\n考え方は、攻撃者がシステムに侵入する際に直面する障壁を増やすことです（図 5-8） 。 \n \n図 5-8: 多層防御の考え方（スイスチーズモデル） \n \nこれにより...",
    "content_length": 621,
    "created_at": "2025-05-12T10:04:28.769597+00:00",
    "updated_at": "2025-05-12T10:04:28.769598+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[28]": {
    "status": "pending",
    "content": "26 \n \n図 2-9は、 「担当者別に着目してほしい章（担当者別の考慮事項が記載） 」 、 「関連する導入・運用プロ\nセスのフェーズ」をまとめたものです。導入担当者の考慮事項については第3 章を、運用担当者の考慮\n事項については第4章を、セキュリティ担当者の考慮事項については第5章を参照してください。 \n但し、他の担当者との円滑な連携のために自身の担当に対応しない章についても閲覧を推奨します。 \n \n \n \n図 2-9: 生成AI導入・運用プロセスの1サイクルにおける担当者の役割",
    "content_summary": "26 \n \n図 2-9は、 「担当者別に着目してほしい章（担当者別の考慮事項が記載） 」 、 「関連する導入・運用プロ\nセスのフェーズ」をまとめたものです。導入担当者の考慮事項については第3 章を、運用担当者の考慮\n事項については第4章を、セキュリティ担当者の考慮事項については第5章を参照してください。 \n但し、他の担当者との円滑な連携のために自身の担当に対応しない章についても閲覧を推奨します。 \n \n \n \n図 2-9: 生成AI導入・運用プロセスの1サイクルにおける担当者の役割",
    "content_length": 243,
    "created_at": "2025-05-12T10:04:28.769513+00:00",
    "updated_at": "2025-05-12T10:04:28.769514+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[92]": {
    "status": "pending",
    "content": "90 \n \n \nSSRF（Server Side Request Forgery） Webサーバ等の公開サーバを通じ、通常アクセスできない\n内部のサーバや公開サーバを連携している別サーバなどへ攻\n撃を仕掛ける手法。 \nSaaS（Software as a Service） クラウド事業者が提供するソフトウェアをユーザが利用する\nサービス形態。 \nTransformer 系列変換のためのニューラルネットワーク。系列とは順序を\n持った並びのことであり、例えば文は単語の系列とみなすこ\nとができる。多くの大規模言語モデルがその中核として採用\nしている機構であり、BERTやGPT等多方面で利用されて\nいる。 \nVertex AI GCP のクラウドプラットフォーム上で提供される、Google\n社のAIサービス。 \nWeb UI ユーザがWebブラウザからアプリケーションやサーバの設\n定や操作を行うためのインターフェース。 \nWebクロール プログラムがWeb上を巡って、Webページのリンクをたど\nりながらWebサイトを巡回し、Webページにある情報を保\n存・収集すること。 \nXSS（Cross Site Scripting） ユーザの入力データを処理するWebアプリケーションや\nWebページを操作するJavaScriptなどに存在する脆弱性を\n悪用し、ユーザのPC上で不正なスクリプトを実行させる手\n法のこと。 \n反射型、格納型、DOMベース型の3種類に分類される。 \nアーリーアダプター イノベーター理論におけるユーザ層の5つの区分のうち、2\n番目に早く新製品・サービスを採用する層で、ユーザの約\n13.5%を占めている。商品やサービスを初期段階で購入する\n人々で、初期採用者とも呼ばれ、市場で商品やサービスを普\n及させるときに重要になる層。 \nアーリーマジョリティ イノベーター理論におけるユーザ層の5つの区分のうち、3\n番目に早く新製品・サービスを採用する層で、ユーザの約\n34%を占めている。アーリーアダプターに比べると慎重では\nあるものの、新しい商品やサービスなどに対しての関心が高\nい層。 \nアジャイル システム開発手法の一種。計画からリリースまでを1サイク\nルとして、サイクルを繰り返し開発する手法。 \nアルゴリズム コンピュータにおける計算処理を行う手順のこと。",
    "content_summary": "90 \n \n \nSSRF（Server Side Request Forgery） Webサーバ等の公開サーバを通じ、通常アクセスできない\n内部のサーバや公開サーバを連携している別サーバなどへ攻\n撃を仕掛ける手法。 \nSaaS（Software as a Service） クラウド事業者が提供するソフトウェアをユーザが利用する\nサービス形態。 \nTransformer 系列変換のためのニューラルネットワーク。系列とは順序を\n持った並びのことであり、例えば文は単語の系列とみなすこ\nとができる。多く...",
    "content_length": 993,
    "created_at": "2025-05-12T10:04:28.769680+00:00",
    "updated_at": "2025-05-12T10:04:28.769681+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[40]": {
    "status": "pending",
    "content": "38 \n \n利活用ガイドラインが存在しない場合、生成AIの利用方法をユーザが自己判断せざるを得ず、個人情\n報を入力して漏洩してしまう、効果的な利用方法がわからず利用をやめてしまうなどの事態が発生する\n可能性が高くなってしまいます。 \nしたがって、生成AIを効果的かつ安全にユーザに利用してもらうため、利活用ガイドラインの策定は\n重要です。 \n \n4.1.2 利活用ガイドラインに記載すべき項目 \n利用制限に関する項目 \n生成AIの利用制限に関する項目を定めることは、組織の機密情報の漏洩やユーザによる意図しない違\n法行為への加担といったリスクの回避に有効です。生成AIのモデルを開発するAnthropic社やGoogle\n社、OpenAI社は利用規約等にて、主に以下の目的での使用を禁止しています [16] [17] [18]。 \n \n 違法行為、または違法行為を促進・助長するコンテンツの作成 \n 違法な物質、商品の製造 \n 犯罪行為 \n 児童ポルノ、性的暴力 \n 個人の精神・身体や、権利に危害をもたらすリスクのあるコンテンツの作成 \n 銃や爆弾、生物兵器や化学兵器の製造 \n 暴力、自傷行為、人身売買 \n 本人の同意を得ずに他者の情報を利用 \n 誤った情報の提供、個人を意図的に欺くことを目的としたコンテンツの作成 \n 詐欺行為 \n 別の個人へのなりすまし \n \nまた、組織の規定に反する内容や次項の「入力制限に関する項目」の内容に関する業務では、生成AI\nの利用制限を検討することが必要です。例えば、以下のような業務が考えられます。 \n 顧客情報や機密情報を取扱う業務 \n 外部公開前の情報を取扱う業務 \n 業務以外の目的での使用 \n \n生成AIへの入力について \n生成AIへのプロンプト入力にあたり、ユーザに意識してもらう内容として、 「プロンプトエンジニア\nリング」と「入力制限に関する項目」の2つが考えられます。 \n \n プロンプトエンジニアリング \n生成AIは、ユーザが求める回答を常に出力するとは限りません。効果的に活用するためには、適切\nなプロンプトの作成が重要です。",
    "content_summary": "38 \n \n利活用ガイドラインが存在しない場合、生成AIの利用方法をユーザが自己判断せざるを得ず、個人情\n報を入力して漏洩してしまう、効果的な利用方法がわからず利用をやめてしまうなどの事態が発生する\n可能性が高くなってしまいます。 \nしたがって、生成AIを効果的かつ安全にユーザに利用してもらうため、利活用ガイドラインの策定は\n重要です。 \n \n4.1.2 利活用ガイドラインに記載すべき項目 \n利用制限に関する項目 \n生成AIの利用制限に関する項目を定めることは、組織の機密情報の漏洩やユーザによる...",
    "content_length": 909,
    "created_at": "2025-05-12T10:04:28.769542+00:00",
    "updated_at": "2025-05-12T10:04:28.769543+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[27]": {
    "status": "pending",
    "content": "25 \n \nDo \n 設計・開発 \n具体的なシステム構成や利用するLLMについて検討し、システム構築を行います。 \n \n テスト・デプロイ \n構築した生成AIシステムに対するテストを実施し、 実環境へのAIシステムの導入可否を判断します。 \n \nCheck \n 運用・評価 \nデプロイされた生成AIシステムの保守・運用作業を実施します。また、導入効果やセキュリティ等の\n評価を実施します。 \n \nAct \n 改善 \n評価結果を生成AIシステムや利用ポリシーに反映し、改善を行います。 \n \n2.4.3 導入・運用における担当者 \n本書では生成AIの組織活用における担当者を、以下のように3つに分類します。 \n \n 導入担当者 \n組織において生成AIの導入を担当する従業員を指します。 \n具体的には、生成AI導入時における導入プロセス（構想策定・要件定義・設計開発・テスト・デプ\nロイ）を牽引し、組織における生成AI導入を促進します。 \n \n 運用担当者 \n組織において生成AIの維持・運用を担当する従業員を指します。 \n具体的には、組織における生成AIの安全な利活用のためのガイドライン・利用ポリシー・規定など\nを制定し、ユーザに周知を行います。 \n \n セキュリティ担当者 \n組織におけるセキュリティやリスクマネジメントを担当する従業員を指します。 \n具体的には、組織における生成AIの安全な利活用のためのリスクアセスメントを実施した上で対策\nを講じます。",
    "content_summary": "25 \n \nDo \n 設計・開発 \n具体的なシステム構成や利用するLLMについて検討し、システム構築を行います。 \n \n テスト・デプロイ \n構築した生成AIシステムに対するテストを実施し、 実環境へのAIシステムの導入可否を判断します。 \n \nCheck \n 運用・評価 \nデプロイされた生成AIシステムの保守・運用作業を実施します。また、導入効果やセキュリティ等の\n評価を実施します。 \n \nAct \n 改善 \n評価結果を生成AIシステムや利用ポリシーに反映し、改善を行います。 \n \n2...",
    "content_length": 636,
    "created_at": "2025-05-12T10:04:28.769511+00:00",
    "updated_at": "2025-05-12T10:04:28.769512+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[66]": {
    "status": "pending",
    "content": "64 \n \n ログの保存 \n出力された回答を保存する。入口対策に記載した入力に関するログを一緒に保存することで、生成\n物に対する問題が発生した際には、確認を行うことができる。 \n \nここで挙げた多層防御の対策は、 あくまで一例であり、 これらの対策を全て実施すれば全ての脅威を防\nげるということを保証するものではありません。その他の対策も併せて検討し、総合的なセキュリティ\n対策を講じることが重要です。 \n \n5.4.2 チェックリストの作成 \n生成AIシステムのセキュリティに関する考慮事項をチェックリストとして一覧化しておくことで、抜\nけ漏れない対策に繋がります。また、一覧化することで、作成者も使用者も自組織の生成AIシステムへ\nの理解が深まるという学習面での副次効果も期待できます。 \nチェックリストには、ガバナンスの観点とシステムの観点という、大きく分けて2 つの観点を盛り込\nむ必要があります。生成AIはユーザの入力によってリスクが発生する可能性が高いため、システム的な\n観点だけでなく、ユーザの管理や社会情勢への考慮、いわゆるガバナンスの観点も必要です。 \n \nガバナンス面 \nガバナンスに関する項目は、主に生成AIを利用するユーザ向けを想定する事項です。チェックリスト\nの項目については、4.1.2、4.3.1を参照ください。また、組織内の既存のチェック項目と照らし合わせ、\n流用可能な項目や既にカバーされている内容についても別途確認することを推奨します。 \n \nシステム面 \nシステムに関する項目は、主に生成AIを社内に導入する担当者向けを想定する事項です。以下は、\nLLMを組み込んだシステム上で考慮する必要がある項目の一例です。これ以外にも組織内の既存のチェ\nックリストなどと併用して確認することを推奨します。 \n 入出力プロンプトを含めたログ管理 \n入力プロンプトと出力プロンプトのログを保存しておくことにより、迅速な事後対応ができます。 \n \n 入力の制限 \n敵対的プロンプトの入力を受け付けないようにする必要があります。敵対的プロンプトの入力が成\n功すると情報漏洩やシステム停止につながる恐れがあります。 \n \n オプトアウト可能なサービスの選定 \n入力したデータが学習されないようにオプトアウト可能なサービスを選定する必要があります。オ\nプトアウトが明記されていないサービスを利用した場合、ユーザが入力した内容が学習に使用され、\n情報漏洩に繋がる恐れがあります。",
    "content_summary": "64 \n \n ログの保存 \n出力された回答を保存する。入口対策に記載した入力に関するログを一緒に保存することで、生成\n物に対する問題が発生した際には、確認を行うことができる。 \n \nここで挙げた多層防御の対策は、 あくまで一例であり、 これらの対策を全て実施すれば全ての脅威を防\nげるということを保証するものではありません。その他の対策も併せて検討し、総合的なセキュリティ\n対策を講じることが重要です。 \n \n5.4.2 チェックリストの作成 \n生成AIシステムのセキュリティに関する考慮事項をチェ...",
    "content_length": 1050,
    "created_at": "2025-05-12T10:04:28.769604+00:00",
    "updated_at": "2025-05-12T10:04:28.769605+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[68]": {
    "status": "pending",
    "content": "66 \n \n5.4.3 生成AIにおける最新の攻撃手法 \nこれまで、生成AIにおけるリスクアセスメントとリスク対応について説明しました。今回はOWASP\nに記載されているリスクを元に解説を行いましたが、現在も生成AIに対する新たな攻撃手法や脆弱性は\n報告され続けています。ここでは、現在研究されている攻撃手法の一例として、間接プロンプトインジェ\nクションについて説明します。 \n \nRAG（検索拡張生成）への攻撃手法（間接プロンプトインジェクション） \n間接プロンプトインジェクションとは、回答生成時にWebクロールを行う生成AIを対象とした攻撃\nです。この攻撃により、攻撃者は事前にウェブサイトに記載しているデータの中に悪意のある指示文を\n紛れ込ませ、生成AIに指示を与えてその挙動を乗っ取ることができます（図 5-13） 。 \n \n \n \n図 5-13: 間接プロンプトインジェクションにおけるイメージ \n \n今後、生成AIの組織における活用が増加すればするほど、生成AIに対する攻撃は高度化し、増加し\nていくことが懸念されます。 \nまた、攻撃者が生成AIを利用して攻撃を仕掛けるケースも考えられます。セキュリティ担当者として\nは、このような新たなセキュリティリスクが常に増え続けることを念頭に置きながらリスクマネジメン\nトを行いましょう。",
    "content_summary": "66 \n \n5.4.3 生成AIにおける最新の攻撃手法 \nこれまで、生成AIにおけるリスクアセスメントとリスク対応について説明しました。今回はOWASP\nに記載されているリスクを元に解説を行いましたが、現在も生成AIに対する新たな攻撃手法や脆弱性は\n報告され続けています。ここでは、現在研究されている攻撃手法の一例として、間接プロンプトインジェ\nクションについて説明します。 \n \nRAG（検索拡張生成）への攻撃手法（間接プロンプトインジェクション） \n間接プロンプトインジェクションとは、回答生成時...",
    "content_length": 572,
    "created_at": "2025-05-12T10:04:28.769609+00:00",
    "updated_at": "2025-05-12T10:04:28.769610+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[14]": {
    "status": "pending",
    "content": "12 \n \n1.6 免責事項 \n 本書は単に情報として提供され、内容は予告なしに変更される場合があります。  \n 本書に誤りがないことの保証や、商品性または特定目的への適合性の黙示的な保証や条件を含め\n明示的または黙示的な保証や条件は一切ないものとします。  \n 本書に記載の内容は、独立行政法人情報処理推進機構および産業サイバーセキュリティセンター\nの意見を代表するものではなく、著者の見解に基づいています。 \n 本書の利用によるトラブルに対し、本書著者ならびに監修者は一切の責任を負わないものとしま\nす。 \n 本書の有効期限は、発行日から2年間とします。",
    "content_summary": "12 \n \n1.6 免責事項 \n 本書は単に情報として提供され、内容は予告なしに変更される場合があります。  \n 本書に誤りがないことの保証や、商品性または特定目的への適合性の黙示的な保証や条件を含め\n明示的または黙示的な保証や条件は一切ないものとします。  \n 本書に記載の内容は、独立行政法人情報処理推進機構および産業サイバーセキュリティセンター\nの意見を代表するものではなく、著者の見解に基づいています。 \n 本書の利用によるトラブルに対し、本書著者ならびに監修者は一切の責任を負わない...",
    "content_length": 284,
    "created_at": "2025-05-12T10:04:28.769480+00:00",
    "updated_at": "2025-05-12T10:04:28.769481+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[55]": {
    "status": "pending",
    "content": "53 \n \n リスク分析 \n潜在的な脅威を考えることで、洗い出した各リスクの「影響度（Impact）」および「発生可能\n性（Likelihood） 」を定量的に分析する工程。一般的に、影響度と発生可能性を独立に分析し、\n両方の結果を考慮してそのリスクの定量値とします。各リスクの定量値を比較する方法には、\n例えばリスクマトリクスがあります （図 5-3） 。リスクマトリクスでは影響度と発生可能性をも\nとに各リスクを2次元的にマッピングします。 \n \n図 5-3: リスクマトリクスの一例 \n \n リスク評価 \nリスク分析結果（各リスクの比較）から総合的にリスク対応策を決定する工程。対策の方向性\nとして、回避・軽減・受容・移転のいずれかを選択し、具体的な対応策を決定します3。対応す\nる範囲や優先度の決定により、限られたリソースを適切に振り分けることができます。 \n \n リスク対応 \n具体的な対策計画を立て、決定した対策を実施する工程。 \n  \n \n3 より現実的には、各リスクの分析結果を列挙して、リスク分析値に対し閾値を設定することで、ある\n閾値以上は回避または軽減、ある閾値以下は受容のように判断します。",
    "content_summary": "53 \n \n リスク分析 \n潜在的な脅威を考えることで、洗い出した各リスクの「影響度（Impact）」および「発生可能\n性（Likelihood） 」を定量的に分析する工程。一般的に、影響度と発生可能性を独立に分析し、\n両方の結果を考慮してそのリスクの定量値とします。各リスクの定量値を比較する方法には、\n例えばリスクマトリクスがあります （図 5-3） 。リスクマトリクスでは影響度と発生可能性をも\nとに各リスクを2次元的にマッピングします。 \n \n図 5-3: リスクマトリクスの一例 \n \n...",
    "content_length": 510,
    "created_at": "2025-05-12T10:04:28.769578+00:00",
    "updated_at": "2025-05-12T10:04:28.769579+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[53]": {
    "status": "pending",
    "content": "51 \n \n 原因 \nこの情報漏洩の原因は、生成AIのデータ管理の仕組みと、それに対するユーザの認識不足に\nあります。生成AIは、ユーザが入力したデータをサーバに保存し、AIモデルの改善に使用しま\nすが、この過程で機密情報が外部に漏れるリスクが生じます。さらに、ユーザがチャット履歴の\n保存を手動で無効にしない限り、データは削除されずに残る可能性があります （図 5-1） 。この\nような管理体制の不備と従業員の誤操作が重なり、情報漏洩が発生しました。加えて、他の企業\nも同様の懸念から生成AIの利用を制限しており、生成AIの安全性に対する懸念が高まる原因\nとなる事件となりました。 \n \n図 5-1: 生成AIに入力した機密情報がAI提供者・AI事業者に流出するイメージ \n \n 対話型生成AIのサイバー犯罪への利用 [26] \n 背景 \n2024年5月27日、 警視庁は川崎市の男性を不正指令電磁的記録作成の容疑で逮捕しました。\nこの事件は、 対話型生成AIを使用してマルウェアを作成した国内初の事例となります （図 5-2） 。\n報道によると、作成されたマルウェアは暗号化や暗号資産の要求といったランサムウェアに類\n似した機能を持ち、容疑者は「ランサムウェアによって楽に金を稼ぎたかった」と供述してい\nます。 この事件は、 生成AIの悪用が新たなサイバー犯罪の手段となり得ることを示しています。 \n \n 原因 \n今回の事件の原因は、生成AIの普及とその悪用の容易さにあります。報道によると、容疑者\nは特別なIT専門知識を持たず、複数の生成AIサービスを利用して悪意のあるプログラムを作\n成したと報じられました。これは、技術的な知識が乏しい人でも生成AIを使って簡単にマルウ\nェアを作成できることを示し、生成AIツールの悪用リスクが顕在化した象徴的な事件です。さ\nらに、生成AIが犯罪行為を助長しうるという点で、サイバーセキュリティに新たな課題をもた\nらす可能性があります。",
    "content_summary": "51 \n \n 原因 \nこの情報漏洩の原因は、生成AIのデータ管理の仕組みと、それに対するユーザの認識不足に\nあります。生成AIは、ユーザが入力したデータをサーバに保存し、AIモデルの改善に使用しま\nすが、この過程で機密情報が外部に漏れるリスクが生じます。さらに、ユーザがチャット履歴の\n保存を手動で無効にしない限り、データは削除されずに残る可能性があります （図 5-1） 。この\nような管理体制の不備と従業員の誤操作が重なり、情報漏洩が発生しました。加えて、他の企業\nも同様の懸念から生成AIの利...",
    "content_length": 843,
    "created_at": "2025-05-12T10:04:28.769573+00:00",
    "updated_at": "2025-05-12T10:04:28.769574+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[93]": {
    "status": "pending",
    "content": "91 \n \nイノベーター イノベーター理論におけるユーザ層の5つの区分のうち、最\nも早く新製品・サービスを採用する層で、ユーザの約2.5%\nを占めている。新しい商品やサービスなどを最も早い段階で\n受け入れ受容する層。 \nイノベーター理論 新製品・サービスの市場への普及率を表したマーケティング\n理論で、1962年にエベレット・M・ロジャーズによって提\n唱された。 \nウォーターフォール システム開発手法の一種。要件定義からテストまで事前に定\nめられた工程で開発する手法 \nエキスパートシステム 特定の専門分野の知識をもち、専門家のように事象の推論や\n判断ができるようにしたコンピューターシステムのこと。 \nオプトアウト ユーザが情報を送り付けられる場合やユーザ本人の情報が事\n業者等に利用される場合などにおいて、それらの行為を拒否\nすること。生成AIにおいては入力した情報をLLMの学習\nデータとして利用することを拒否する場合などを指す。 \nキャズム イノベーター理論におけるアーリーアダプターとアーリーマ\nジョリティの間に存在にする容易に越えられない深い溝のこ\nと。この溝を越えて市場で存続するために、アーリーアダプ\nターだけでなくアーリーマジョリティへのマーケティングも\n必要であるという「キャズム理論」がジェフリー・Ａ・ムー\nアによって提言された。 \nサプライチェーン 原料の生産から製品の提供までの一連の流れのこと。生成\nAIにおいては使用するモデルや学習データを考慮に入れる\n必要がある。 \nチャットボット ユーザとの会話に対してロボットに自動で応答させる技術の\nこと。ロボットに生成AIを利用することでより柔軟な応答\nが可能となった。 \nディープラーニング ニューラルネットワークにおける入力層と出力層の間に存在\nする中間層を多層化し、各中間層において特徴点を抽出する\nことで複雑なデータを詳細に分析して学習する。 \nデプロイ システム開発工程で、アプリケーションの機能やサービスを\nサーバ上に配置・展開し、利用可能な状態にする一連の作業 \nトークン LLMへ問い合わせを行う際に分割したプロンプトの最小単\n位。生成AIのクラウドサービスを利用する際はトークンの\n数が料金に影響する場合がある。プロンプトが長いほど、ま\nた、より細かく分割するほどトークンは増加することに留意\nが必要。",
    "content_summary": "91 \n \nイノベーター イノベーター理論におけるユーザ層の5つの区分のうち、最\nも早く新製品・サービスを採用する層で、ユーザの約2.5%\nを占めている。新しい商品やサービスなどを最も早い段階で\n受け入れ受容する層。 \nイノベーター理論 新製品・サービスの市場への普及率を表したマーケティング\n理論で、1962年にエベレット・M・ロジャーズによって提\n唱された。 \nウォーターフォール システム開発手法の一種。要件定義からテストまで事前に定\nめられた工程で開発する手法 \nエキスパートシステム 特定の...",
    "content_length": 998,
    "created_at": "2025-05-12T10:04:28.769683+00:00",
    "updated_at": "2025-05-12T10:04:28.769683+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[65]": {
    "status": "pending",
    "content": "63 \n \n 防御用プロンプトテンプレートの実装 \nLLM統合システムの内部で定義するプロンプトテンプレートに防御用のプロンプトを設定する （図 \n5-11）ことで、不正な操作や出力を減らすことができる。 \n \n \n図 5-11: 防御用プロンプトテンプレート例 \n \n出口対策 \n出口対策では、バックエンドにある統合ミドルウェアからフロントエンドにあるWeb UIにレスポン\nスを送る場所での対策とユーザへ情報が渡る場所での対策を考えます。図 5-5のシステム構成図におけ\nる入口対策の場所を、図 5-12に緑色の盾マークで示します。 \n \n \n図 5-12: 出口対策場所のイメージ \n \n具体的な出口対策の例を以下示します。 \n ユーザへの教育 \nLLMを使った生成物は著作権の侵害やハルシネーション、バイアスがかかっている可能性がある\nことを周知するなどの教育を行う。これにより、間違った情報を使用することによる事故を防ぐこ\nとができる。 \n ガードレールの設置 \nガードレールを設置することで、出力された内容が事前に設定したポリシーに違反しているか\nLLMを使用して検証する。これにより、不利益をもたらす内容や不適切な表現、バイアスの発生\nなどを軽減することができる。",
    "content_summary": "63 \n \n 防御用プロンプトテンプレートの実装 \nLLM統合システムの内部で定義するプロンプトテンプレートに防御用のプロンプトを設定する （図 \n5-11）ことで、不正な操作や出力を減らすことができる。 \n \n \n図 5-11: 防御用プロンプトテンプレート例 \n \n出口対策 \n出口対策では、バックエンドにある統合ミドルウェアからフロントエンドにあるWeb UIにレスポン\nスを送る場所での対策とユーザへ情報が渡る場所での対策を考えます。図 5-5のシステム構成図におけ\nる入口対策の場所を、図...",
    "content_length": 542,
    "created_at": "2025-05-12T10:04:28.769602+00:00",
    "updated_at": "2025-05-12T10:04:28.769603+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[45]": {
    "status": "pending",
    "content": "43 \n \n4.2.2 ユーザへの教育方法 \n 利活用ガイドラインの普及 \neラーニングプラットフォームなどを活用して、利活用ガイドラインの内容を普及します。定期\n的に実施することで、生成AIの利用規範や安全な利用方法に対する意識付けを行うことができ、\n倫理観およびセキュリティ意識の醸成に寄与することができます。 \n \n 効果的なプロンプトの共有 \n生成AIの効果的な使用方法を示すプロンプトを共有します。具体的な例を通じて、ユーザがど\nのようにプロンプトを作成すればよいかを学び、実際の業務に応用できるようにすることで、業\n務効率の向上に寄与できます。 共有するプロンプトは運用担当者自身が考えても良いですが、4.1.2\nで述べたような公式ドキュメントに記載されているサンプルを検証した内容も有効です。 \n \n 生成AI活用文化の醸成 \n生成AIを日常的に活用する文化を醸成します。例えば、日報作成に生成AIを利用するなど、\n日常業務の一部として生成AIを取り入れることで、ユーザが自然に生成AIを使いこなせるよう\nにします。実際に利用することで、生成AIに対する認識誤りを自覚することによって倫理観の醸\n成や、利用に慣れることによる業務効率の向上が期待できます。 \nまた、有志の人を集めて、活用方法を探り、共有するためのチームを設立することも有効な手段\nとなります。 ユーザが実際に生成AIを利用しながらプロンプトを共有し合える環境を提供するこ\nとで、生成AIの使用促進につなげることができます。 \n \nこれらの方法を通じて、ユーザのスキル向上を図ることで、生成AIの効果的な活用と企業全体の生産\n性向上が期待できます。運用部門は、継続的に教育プログラムを提供し、ユーザが常に最新の知識とスキ\nルを持ち続けられるようサポートすることが重要です。これにより、生成AIの運用がより効果的かつ倫\n理的に行われ、組織全体の競争力強化に寄与します。 \n \n4.3 生成AIの更新管理 \n4.3.1 透明性の確保と維持 \n生成AIにおける透明性とは、生成AIが回答に使用した学習データや回答に至ったプロセスを可視化\nすることを指します。透明性を確保することには多くのメリットがあります。例えば、ユーザやステーク\nホルダからすると、生成AIがどのようにして回答を導き出したのかを理解することで、回答の正誤に対\nする判断能力が高まります。また、生成AIがバイアスを含んでいるかどうかを検出しやすくなり、不公\n平な結果や差別的な判断を排除することができます。",
    "content_summary": "43 \n \n4.2.2 ユーザへの教育方法 \n 利活用ガイドラインの普及 \neラーニングプラットフォームなどを活用して、利活用ガイドラインの内容を普及します。定期\n的に実施することで、生成AIの利用規範や安全な利用方法に対する意識付けを行うことができ、\n倫理観およびセキュリティ意識の醸成に寄与することができます。 \n \n 効果的なプロンプトの共有 \n生成AIの効果的な使用方法を示すプロンプトを共有します。具体的な例を通じて、ユーザがど\nのようにプロンプトを作成すればよいかを学び、実際の業務に...",
    "content_length": 1076,
    "created_at": "2025-05-12T10:04:28.769554+00:00",
    "updated_at": "2025-05-12T10:04:28.769555+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[12]": {
    "status": "pending",
    "content": "10 \n \n \n図 1-5:一般的なAI活用の流れにおける主体の対応 \nAI事業者におけるガイドライン第1版 P5 を元に作成 \n \nまた本書は、企業における「テキスト生成AI」の安全かつ効果的な活用を対象とします。テキスト生\n成特有のリスクとその対策に焦点を当て、具体的かつ実用的なセキュリティ対策を提供することを目指\nし、画像生成AIや動画生成AIなど、テキスト生成以外のAI技術を対象外とします。 \nテキスト生成AIの活用は多岐にわたり、製品説明資料やマーケティング資料に伴うアイデア出しや文\n法修正、コードの作成や作成したコードにおける説明や修正など、企業活動の多くの場面で大きな効果\nを発揮します。本書を参照することで、組織はこれらの活用シナリオにおいてテキスト生成AIをより安\n全かつ効率的に運用する方法を学ぶことができます。 \n \n1.4 本書の特徴 \n本書は、NIST （米国国立標準技術研究所）が発行するAI RMF [7]、AI RMF Generative AI Proﬁle [8]、\nISO（国際標準化機構）が取り決めるISO/IEC 42001 [9]、JDLAが発行する生成AIの利用ガイドライ\nン [10]など、AIに関連する既存の多くのガイドラインやフレームワークを参考に作成されています。\nNISTやISOが広範囲にわたる汎用的なAI技術を記載するのに対し、本書はテキスト生成AIの導入と\n運用を担当する者に特化した内容を記載することで、より具体的な内容に言及します。また、JDLAのガ\nイドラインが生成AIの利用者（ユーザ）を対象とするのに対して、本書は、企業や組織でテキスト生成\nAIを導入・運用する担当者を対象とします。 \n加えて、本書は生成AIにおけるセキュリティリスクにフォーカスし、従来の生成AIに関連するセキ\nュリティリスクだけでなく、 今後さらに利活用されるであろうRAG （Retrieval-Augmented Generation）\nを企業で導入することによって新たに発生するセキュリティリスクについても詳述します。",
    "content_summary": "10 \n \n \n図 1-5:一般的なAI活用の流れにおける主体の対応 \nAI事業者におけるガイドライン第1版 P5 を元に作成 \n \nまた本書は、企業における「テキスト生成AI」の安全かつ効果的な活用を対象とします。テキスト生\n成特有のリスクとその対策に焦点を当て、具体的かつ実用的なセキュリティ対策を提供することを目指\nし、画像生成AIや動画生成AIなど、テキスト生成以外のAI技術を対象外とします。 \nテキスト生成AIの活用は多岐にわたり、製品説明資料やマーケティング資料に伴うアイデア出しや文\n...",
    "content_length": 887,
    "created_at": "2025-05-12T10:04:28.769475+00:00",
    "updated_at": "2025-05-12T10:04:28.769476+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[82]": {
    "status": "pending",
    "content": "80 \n \n一方、Mistral AI社は、Alphabet社とMeta社の元研究者によって2023年4月に設立されました。設\n立当初から世界の注目を浴び、 設立の5か月後には 「Mistral 7B」 という独自モデルの発表を行いました。\nその3か月後には「Mistral 8x7B」を発表するなど、進歩の著しい企業です [40]。2024年3月には、こ\nれら2 つのモデルが大手クラウドで利用可能になり、同社が大手クラウドサービスとの連携も強めてい\nることがわかります [41]。そんな中、新たな開発資金調達が、2024年3月で5億ドルに達し、5月時点\nでは調達額が6億ドルに達する見込みと報道されました [40]。 \n \n繰り返しとなりますが、高性能な生成AIモデルの構築するための学習には、多額のコストが必要とな\nります。裏返せば、多額のコストを費やすことができれば、生成AIモデルの性能を向上させる可能性が\n高まります。 多額の生成AI開発資金の調達を成したAleph Alpha社とMistral社が今後提供するAIモデ\nルについても注視していく必要があると言えます。投資以外にも公的機関の支援もAI開発を加速させま\nす。EU政府は前述のスタートアップ企業以外からも強いAIを生み出すために、AI関連のスタートアッ\nプ企業に対して支援を開始しました。欧州委員会と欧州高性能コンピューティング共同事業が共同で設\n置したスーパーコンピュータを、AIを開発するスタートアップ企業に開放し、モデルの構築を促してい\nます。これらの背景からEUからより多くのAIモデルが構築される可能性が高まっています。 \n \n7.2 法規制について \n過去の歴史を振り返ると、新しい技術が産まれる際には、社会や国民生活の間に軋轢が生じてきまし\nた。生成AIもその例に漏れず、今現在いくつかの社会的な課題を抱えています。多くは、学習データに\n起因する課題や新たな概念に適合できていない法規制に関する課題です。例えば学習データの収集に焦\n点を当てると、ウェブクローリングを行い無差別にWebページや書籍、雑誌、論文、ニュース記事を収\n集することが問題視されています [42]。 つまり、 インターネット上に存在する個人情報や著作物をAIモ\nデルの学習データとして利用することの是非が争点となっています。個人情報や著作物が利用者の同意\nを得ないまま利用されることが、プライバシーや経済的な権利や表現を奪われることになります。加え\nて、ポルノや犯罪行為をはじめとする非倫理的なデータの利用により犯罪を増長する恐れもあります \n[43]。 ほかにも出力データの信頼性などを問題視する声があがるなど多くの課題が存在するため、 関連し\nて多くの規制やガイドラインが発行されています。ここでは、各国の法規制やガイドラインの発行につ\nいて触れます。",
    "content_summary": "80 \n \n一方、Mistral AI社は、Alphabet社とMeta社の元研究者によって2023年4月に設立されました。設\n立当初から世界の注目を浴び、 設立の5か月後には 「Mistral 7B」 という独自モデルの発表を行いました。\nその3か月後には「Mistral 8x7B」を発表するなど、進歩の著しい企業です [40]。2024年3月には、こ\nれら2 つのモデルが大手クラウドで利用可能になり、同社が大手クラウドサービスとの連携も強めてい\nることがわかります [41]。そんな中、新たな...",
    "content_length": 1208,
    "created_at": "2025-05-12T10:04:28.769650+00:00",
    "updated_at": "2025-05-12T10:04:28.769651+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[75]": {
    "status": "pending",
    "content": "73 \n \n ハルシネーションについて \nハルシネーションは生成AIが抱える大きなリスクの1つです。 このリスクを完全に取り除く\nことは現状の技術では困難であり、軽減策を講じることしかできません。ヒアリング先の組織\nもユーザが誤った情報を信用してしまうリスクや重要な意思決定が誤った情報に基づいて行わ\nれるリスクに対して大きな危機感を抱いていました。 \n現在このリスクに対し、組織が講じている対策として挙げられたのは、ユーザの生成AIに対\nする認識とスキルを向上させるための教育や、RAGを用いた回答精度の向上です。ただ、これ\nらの対策のみでは本リスクへの根本的な対応にはならず、今後も継続的に組織内で検討が必要\nであると考えます。 \nなお、プロンプトインジェクションやジェイルブレイクのような生成AIを対象とした敵対的\nプロンプト攻撃のリスクは低いものと認識されている傾向があり、敵対的プロンプト攻撃をは\nじめとしたサイバー攻撃への対策は、 具体的な対策手法を含め、 現在も組織内で検討を進めてい\nる途中であるということがわかりました。 \n \n6.1.3 ユーザのフィードバック \n ヒアリング内容 \n生成AIの本格稼働後に、ユーザからあったフィードバックや問い合わせ内容などについて、回数\nの多いものをヒアリングしました。 \n \n ヒアリング結果 \n組織にヒアリングする中で多く回答されたのは次の内容でした。システム導入当初は、 「生成AI\nというものがどういうものか」、 「どのように活用すればよいか （活用法）」など、ユーザからの質問\nには基本的な内容が多い傾向にあったものの、導入から約1年が経過した現在では、 「新たなサービ\nス （画像生成AIや動画生成AIなど） を導入してほしい」 、 「RAGの効果的な使い方がわからない」 、\n「外販に活用するためにはどうしたらよいのか」などの、当初の質問に比べ高度な質問に変化して\nいることがわかりました。 \n質問内容の高度化は、組織が今までに実施した情報周知や教育で、ユーザの生成AIへの理解度が\n向上したからと考えられます。組織における努力の賜物ではないかと感じ取れました。",
    "content_summary": "73 \n \n ハルシネーションについて \nハルシネーションは生成AIが抱える大きなリスクの1つです。 このリスクを完全に取り除く\nことは現状の技術では困難であり、軽減策を講じることしかできません。ヒアリング先の組織\nもユーザが誤った情報を信用してしまうリスクや重要な意思決定が誤った情報に基づいて行わ\nれるリスクに対して大きな危機感を抱いていました。 \n現在このリスクに対し、組織が講じている対策として挙げられたのは、ユーザの生成AIに対\nする認識とスキルを向上させるための教育や、RAGを用いた回...",
    "content_length": 919,
    "created_at": "2025-05-12T10:04:28.769634+00:00",
    "updated_at": "2025-05-12T10:04:28.769634+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[84]": {
    "status": "pending",
    "content": "82 \n \nこれらの法規には、EUに住む個人の権利を保護する価値観が反映されており、AI規制に対してもこ\nの価値観が反映されています。欧州委員会は、2020年2月に欧州データ戦略を示しました。この戦略で\nは、安全なAIシステムを利活用する世界的リーダーになること、中小企業を含めてAI市場参入を加速\nさせるエコシステムの構築、活用しきれていないデータをEU域内で利活用できる枠組み作り、厳格な\n消費者保護ルールの遵守を前提としています。つまり、個人の権利を保護しながらも、欧州内のデータを\n欧州内で活発に利用する方針を打ち出したといえます [53]。 \nまたほかには「信頼性を備えたAIのための倫理ガイドライン」が発表されており、 「人による監督」\n「プライバシーとデータのガバナンス」 「透明性」 などのデータの取り扱いが示されました [54]。 そして、\n2021年からEUにおけるAI規制法が起草され、広がり続けるAI市場と生成AIに対する危機感の声を\n反映し、AI規制法は2024年5月に可決されました。 \nこの法規は、GDPR同様、EUに関連する経済活動を行う全ての企業を対象にしており、世界各国に影\n響を与えるものです。日本企業においても、EU圏内のユーザを抱える場合もあるため、意図せず規制に\n抵触することがないよう、この規制を一読しておくことを推奨します。 \n \nAI規制法では「人間を中心とするAI」 「信頼に足るAI」 「欧州連合の価値観に沿ったAIシステムを創\n造する」という観点を重視しています。この観点から次の要件が求められ、違反時の罰則や違反者が定義\nされています。 \n リスクベース・アプローチによるAI管理 \n 汎用的な生成AIに対する透明性の確保 \n 欧州の価値観に基づくAIの構築 \nAI規制法は、AIのリスクを分析し、深刻度を段階的に分けて整理を行いました。そのリスク深刻度に従\nい活用可能な条件を整理しています。AI規制法に定められた罰則とその範囲、そして罰則の要件を簡単\nに示します。 \n罰則：厳しい罰則 \n「3500万ユーロ」か「年間売上高の7％」のいずれか高いほうの制裁金が課されます。 \n \n対象範囲：違反者の範囲 \nEU域外で利用された高リスクAIの出力を欧州の事業者が活用する場合には、利用されたEU域外の\n高リスクAI事業者が罰則の対象として含まれます。そのため高リスクと判断されるAIの出力を欧州内\nで利用することについて明示的に契約書に記載する必要があります。 \n \n要件①：リスクベース・アプローチによるAI管理 \nAIのリスクを以下のように4段階に分け、それぞれに例を示します。 \n- 許容できないリスク ：原則禁止。出身・趣向などを基にしたスコアリング、人を操作するものなど \n- 高リスク：第三者認証が必要。教育や重要インフラの管理など人権や安全に影響があるもの \n- 限定的なリスク：透明性の確保が必要。対話型AIや生成AIなど \n- 最小リスク：上記を満たさないもの",
    "content_summary": "82 \n \nこれらの法規には、EUに住む個人の権利を保護する価値観が反映されており、AI規制に対してもこ\nの価値観が反映されています。欧州委員会は、2020年2月に欧州データ戦略を示しました。この戦略で\nは、安全なAIシステムを利活用する世界的リーダーになること、中小企業を含めてAI市場参入を加速\nさせるエコシステムの構築、活用しきれていないデータをEU域内で利活用できる枠組み作り、厳格な\n消費者保護ルールの遵守を前提としています。つまり、個人の権利を保護しながらも、欧州内のデータを\n欧州内で活...",
    "content_length": 1271,
    "created_at": "2025-05-12T10:04:28.769655+00:00",
    "updated_at": "2025-05-12T10:04:28.769656+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[94]": {
    "status": "pending",
    "content": "92 \n \n \nニューラルネットワーク 人間の脳(ニューロン)の働きを模してコンピュータに学習さ\nせる手法。入力層と出力層の間に中間層を設ける３層化構造\nを用いてデータを分析して学習する。中間層をより多層化し\nたものをディープラーニングと呼ぶ。 \nノイズ HTMLタグや改行コードなどLLMに学習させたいデータ\nやベクトルDBに格納したいデータとは関係のない文字のこ\nと。回答精度の低下につながる。 \nハルシネーション AIが事実に基づかない情報を生成する現象。AIが幻覚（ハ\nルシネーション）を見ているかのようにもっともらしい嘘を\n出力するため、そのように呼ばれる。 \nバックエンド DBなどの直接ユーザの目に触れない部分。生成AIにおい\nては、LLMそのものや、ユーザとLLMの間の処理を行う\n統合ミドルウェア等を指す。 \nビッグデータ 「日々生成される多種多様なデータ群」のこと。Volume\n（大量さ） 、Variety（多種多様さ） 、Velocity（発生頻度・処\n理速度の速さ）という3つのVの特徴を持ち、構造化デー\nタと非構造化データで構成されている。 \nファインチューニング 学習済みのモデルに対して新たなデータを追加で学習させる\n技術で、LLMに限らずディープラーニングで作成されたモ\nデルには広く用いられている。 \nフィッシング攻撃 悪意のある人間が、価値ある情報をユーザから詐取すること\nを目的としたサイバー犯罪。詐取の対象としては、クレジッ\nトカード番号、個人情報、企業データなどが挙げられる。 \nフロントエンド WebサービスやWebアプリケーションで直接ユーザの目に\n触れる部分。生成AIにおいては、Web UI等のユーザが直\n接操作する部分やバックエンドのソフトウェアとのやり取り\nをする部分を指す。 \nブラックボックス 利用者が内部構造や動作原理についてわからない構造になっ\nていること。AIにおいては、どのような判断基準で回答を\n生成しているのかが見えないことを指す。 \nプロンプト 生成AIに対する質問や指示のこと。 \nプロンプトインジェクション 生成AIを意図的に誤作動させるような指令入力を与え、提\n供側が出力を禁止している情報（開発に関する情報、犯罪に\n使われうる情報等）を生成させる攻撃。 \nプロンプトエンジニアリング 生成AIへの問い合わせを具体的に指示し適切に組み合わせ\nることで、目的の出力を生成しやすくするための手法。",
    "content_summary": "92 \n \n \nニューラルネットワーク 人間の脳(ニューロン)の働きを模してコンピュータに学習さ\nせる手法。入力層と出力層の間に中間層を設ける３層化構造\nを用いてデータを分析して学習する。中間層をより多層化し\nたものをディープラーニングと呼ぶ。 \nノイズ HTMLタグや改行コードなどLLMに学習させたいデータ\nやベクトルDBに格納したいデータとは関係のない文字のこ\nと。回答精度の低下につながる。 \nハルシネーション AIが事実に基づかない情報を生成する現象。AIが幻覚（ハ\nルシネーション）を見て...",
    "content_length": 1036,
    "created_at": "2025-05-12T10:04:28.769685+00:00",
    "updated_at": "2025-05-12T10:04:28.769686+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[39]": {
    "status": "pending",
    "content": "37 \n \n第4章 生成 AI の運用について \n本章では、組織で生成AIを運用する担当者（運用担当者）の主な考慮事項を説明します。生成AIを\n組織で運用する上で、利活用ガイドラインやルールを策定・文書化し、組織内で共有することが重要にな\nります。また、文書の中では、ユーザの行動制限や業務円滑化に関する内容を記載することがポイントで\nす。例えば、利活用ガイドラインを策定する際は、入力してはいけない内容や目的の出力を生成させるプ\nロンプトのコツ、生成物の取扱い方法などを記述します。 \n \n図 4-1: 導入プロセスと運用担当者の該当フェーズ \n \n4.1 利活用ガイドラインの策定 \n4.1.1 利活用ガイドライン策定の重要性 \n2024年1月に一般財団法人JIPDECによって実施された「企業IT利用調査2024」によると、生成AI\nに関する利用規定やガイドラインが策定されている企業の割合は、会社で構築・契約した生成AIを使用\nしている企業では68.6%、社員各自で契約・登録した生成AIを使用している企業では9.0%となってお\nり、利活用ガイドラインを策定せずに生成AIを運用している企業が多いのが現状です（図 4-2） 。 \n \n図 4-2:生成AIの利活用ガイドラインの策定状況 \nJIPDEC／ITR「企業IT利活用動向調査2024」より作成 [4]",
    "content_summary": "37 \n \n第4章 生成 AI の運用について \n本章では、組織で生成AIを運用する担当者（運用担当者）の主な考慮事項を説明します。生成AIを\n組織で運用する上で、利活用ガイドラインやルールを策定・文書化し、組織内で共有することが重要にな\nります。また、文書の中では、ユーザの行動制限や業務円滑化に関する内容を記載することがポイントで\nす。例えば、利活用ガイドラインを策定する際は、入力してはいけない内容や目的の出力を生成させるプ\nロンプトのコツ、生成物の取扱い方法などを記述します。 \n \n図 4-...",
    "content_length": 583,
    "created_at": "2025-05-12T10:04:28.769540+00:00",
    "updated_at": "2025-05-12T10:04:28.769540+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[73]": {
    "status": "pending",
    "content": "71 \n \n第6章 組織ヒアリング分析 \n本書の記載にあたり、我々は、既に生成AI活用を開始している組織に、ヒアリングを実施しました。\n本章では、ヒアリング結果から見えた「組織が感じる生成AIの課題」を紹介します。また「生成AI活\n用で現在最も脅威と考えるリスク」 、 「実際に実施しているリスク対策」についても触れます。なお、ヒア\nリングは2024年3月～5月に実施し、内容はその時点のものを記載しました。 \n \n6.1 ヒアリング結果から見る組織の生成AIとの在り方 \n6.1.1 導入目的とプロセス \n ヒアリング内容 \n「3.1.2 導入目的の決定」にも記載した通り、組織での生成AI導入では目的の明確化が重要なた\nめ、その組織の生成AIの導入目的（生成AI導入に至った理由）を確認しました。その上で、実際\nの導入プロセス（どんな導入プロセスをとったか）も確認しました。 \n \n ヒアリング結果 \n 導入目的 \nヒアリングを行った組織の生成AI導入の目的は、以下のようなものでした。 \n- 文章校正や要約 \n- 専門性の高いドキュメントの探索時間短縮 \n- システム開発効率の改善（プログラム添削）等 \n上記結果から、組織の生成AI導入の目的は 「業務効率化による生産性の向上」や 「サービスの品\n質向上」であり、一般的な雑務のみならず、コアとなる業務の効率化も見据えていることがわかり\nました。 \n \n 導入プロセス \n全体的な印象として、導入はスモールスタートで実施されている傾向が見られました。第3 章\nに記載の通り、まずは部門単位での先行利用や、ユーザを選定した導入を行います。そこでユーザ\nの利用率や利用料金、 ユーザの活用方法を確認した上で、 全社展開を開始している組織が多く見ら\nれました。",
    "content_summary": "71 \n \n第6章 組織ヒアリング分析 \n本書の記載にあたり、我々は、既に生成AI活用を開始している組織に、ヒアリングを実施しました。\n本章では、ヒアリング結果から見えた「組織が感じる生成AIの課題」を紹介します。また「生成AI活\n用で現在最も脅威と考えるリスク」 、 「実際に実施しているリスク対策」についても触れます。なお、ヒア\nリングは2024年3月～5月に実施し、内容はその時点のものを記載しました。 \n \n6.1 ヒアリング結果から見る組織の生成AIとの在り方 \n6.1.1 導入目的とプロ...",
    "content_length": 760,
    "created_at": "2025-05-12T10:04:28.769627+00:00",
    "updated_at": "2025-05-12T10:04:28.769629+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[23]": {
    "status": "pending",
    "content": "21 \n \n2.3.3 テキスト生成AIの組織導入におけるリスク \n本項では、一般にテキスト生成AIにどのようなリスクが存在するのかを説明します。ドイツの情報セ\nキュリティ庁（BSI, Bundesamt für Sicherheit in der Informationstechnik）発行のレポートではテキスト\n生成AIのLLMに関する3つのリスクカテゴリーが提示されています [13]。しかし、上述のレポートを\n含めたAIセキュリティに特化したドキュメントでは、AI特有の攻撃やリスクに重点が置かれているた\nめ、組織導入におけるリスク検討としては必ずしも十分とは言えません。そのため、本書ではBSIのレ\nポートに記載されているカテゴリーをベースに、テキスト生成AIを組織に導入する上で必要と考える内\n容を加えた4つのカテゴリーにリスクを分類しました。 \nまた4 つのリスクカテゴリーは、組織の内部要因で発生するリスクと外部要因で発生するリスクに分\n類することができます（図 2-6） 。 \n \n \n図 2-6: テキスト生成AIの組織導入におけるリスク \n \n各リスクカテゴリーの概要を以下に記載します。 \n 運用時のリスク \n機密情報をテキスト生成AIに入力することによって組織内の機密情報が外部に流出する\n可能性、更新される前の古い情報に基づいた回答を生成、もしくは事実に基づかない情報\nを生成する現象であるハルシネーション（詳細は4.1.2を参照）を引き起こすことも懸念さ\nれています。ほかにも、テキスト生成AIを悪用することでマルウェアの作成等も可能にな\nる場合があることもリスクの一つです。 \n \n 悪意のある生成AIを利用するリスク \nテキスト生成AIにはさまざまなWebサービスが存在しています。その中には故意に誤\n情報を出力するサービスや、プログラムコードの校正を実施しようとした際にマルウェア\nを組み込んで回答するサービスも存在する可能性があります。 \nこれらのテキスト生成AIサービスを利用することで、 意図しないマルウェアのインスト\nール・拡散につながってしまう可能性が存在します。",
    "content_summary": "21 \n \n2.3.3 テキスト生成AIの組織導入におけるリスク \n本項では、一般にテキスト生成AIにどのようなリスクが存在するのかを説明します。ドイツの情報セ\nキュリティ庁（BSI, Bundesamt für Sicherheit in der Informationstechnik）発行のレポートではテキスト\n生成AIのLLMに関する3つのリスクカテゴリーが提示されています [13]。しかし、上述のレポートを\n含めたAIセキュリティに特化したドキュメントでは、AI特有の攻撃やリスクに重点が...",
    "content_length": 908,
    "created_at": "2025-05-12T10:04:28.769502+00:00",
    "updated_at": "2025-05-12T10:04:28.769502+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[38]": {
    "status": "pending",
    "content": "36 \n \n3.4.2 生成AIの性能評価 \n生成AIの性能評価は、そのシステムが期待通りのパフォーマンスを発揮するかどうかを確認するため\nに極めて重要です。しかし、一般的なシステムの性能評価と比べて、生成AIの性能評価は特に難しい場\n合が多いとされています。これは、生成AIの回答プロセスがブラックボックス化しており、評価基準を\n定義する必要があるためです。このような状況を踏まえて、性能評価フェーズでは生成AIの性能を総合\n的に評価することが求められます。 \n性能評価の主要な指標には、回答の正確性、応答時間、スケーラビリティなどが含まれます。より具\n体的な指標としては、ベンチマークテストの正答率や、生成されたコンテンツの品質、システムの応答\n時間、入出力トークン数、出力速度などが考えられます。性能評価を実施する際の主な注意点は以下の\n通りです。これらの指標や注意点を考慮し、生成AIの性能を総合的に評価することが必要です。 \n \n注意点 \n 回答の正確性や偏り（バイアス）などを検証する。 \n生成AIの性能を評価する上で重要な要素である、回答の正確性やバイアスについてテスト段階\nで検証を実施しておくことが重要です。 \n ベンチマークの結果を過信しないようにする。 \n一般的にベンチマークを利用した評価が行われることが多いとされていますが、その種類はさま\nざまであり、同じ生成AIを評価対象にしても、利用するベンチマークによって結果が大きく異な\nる場合があります。利用するベンチマークの種類やデータセットなど、前提条件をきちんと把握し\nた上で評価に活用することが重要です。 \n \n3.4.3 利活用ガイドラインの策定 \n生成AIを実装する前には、生成AIユーザのための利活用ガイドラインを策定することも重要です。\nユーザに生成AIを安全かつ効率的に利用してもらうため、利用する上での禁止事項や入出力内容の取扱\nいに関する注意点、目的の出力を生成するために考慮すべき点などを利活用ガイドラインに盛り込む必\n要があります（ガイドラインの具体的な内容については4.1を参照してください） 。 \nまた、ここで作成するガイドラインは導入担当者だけではなく、運用担当者と連携し、協力して作成す\nることが重要です。両担当者の視点から、自社の状況に合った運用可能なガイドラインを策定すること\nが求められます。",
    "content_summary": "36 \n \n3.4.2 生成AIの性能評価 \n生成AIの性能評価は、そのシステムが期待通りのパフォーマンスを発揮するかどうかを確認するため\nに極めて重要です。しかし、一般的なシステムの性能評価と比べて、生成AIの性能評価は特に難しい場\n合が多いとされています。これは、生成AIの回答プロセスがブラックボックス化しており、評価基準を\n定義する必要があるためです。このような状況を踏まえて、性能評価フェーズでは生成AIの性能を総合\n的に評価することが求められます。 \n性能評価の主要な指標には、回答の正確...",
    "content_length": 1003,
    "created_at": "2025-05-12T10:04:28.769537+00:00",
    "updated_at": "2025-05-12T10:04:28.769538+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[87]": {
    "status": "pending",
    "content": "85 \n \n \n図 7-2: 生成AIの特徴の相関 \n \n法規と安全な利用 \n各国で行ったAIに対するアンケート結果によると、 「AIを理解しているか」という質問に対し、 「理解\nしている」と回答したのは、日本では43％と、米国の67%や、最も高いインドネシアの84％を下回って\nいます。しかし、 「AIに不安を感じるか」という質問に対しても、不安を示す回答が、同じく日本が米国\nを下回りました（日本23％に対し米国63％） [32]。 \nつまり、 「日本はAIに対する深い理解はないが、楽観的に捉えている」という結果が得られたと言え\nます。この結果からは、AIに対し、先進的な技術であるというイメージが先行し、それに関するリスク\nが認識されていないことが危惧されます。リスクは例えば、AIが行う「推論」によって作られたハルシ\nネーションや潜在的思考への影響、過失によるもの （情報漏洩など）に加えて、悪意によるもの（ディー\nプフェイクによる個人の尊厳を汚す行為、フェイクニュースを作成し大衆を混乱に陥れる行為など）で\nす。 \nこのようなリスクに対し、 米国は法律による規制を行っていく可能性を示しており、 同盟国である日本\nに対しても足並みを揃えた規制が求めることが想定されます [62]。現在、日本におけるAIの法規制は\n議論が始まったばかりであり、継続的に注視していく必要があります。一方で、法規やガイドラインは安\n全な利用を促すために作られるものの、安全はそれだけでは担保されません。ユーザがAIの作り出すハ\nルシネーションや悪意のあるフェイクニュースなどに惑わされないためには、ユーザ自身が正しくAIを\n理解し、その危険性を回避する方法を学ぶ必要があります。具体的には、信頼のおける公的機関の情報を\n活用し、事実関係の確認を行うべきです。 \n組織において利用する際には継続的なAIの教育を行い、 “もっともらしいAIの出力の正しさ”を確認\nする習慣を根付かせることが重要です。情報の真偽性を確認する習慣を浸透させ、AIの持つ利便性や有\n効性を最大化し、業務効率と企業価値の最大化を図っていきましょう。",
    "content_summary": "85 \n \n \n図 7-2: 生成AIの特徴の相関 \n \n法規と安全な利用 \n各国で行ったAIに対するアンケート結果によると、 「AIを理解しているか」という質問に対し、 「理解\nしている」と回答したのは、日本では43％と、米国の67%や、最も高いインドネシアの84％を下回って\nいます。しかし、 「AIに不安を感じるか」という質問に対しても、不安を示す回答が、同じく日本が米国\nを下回りました（日本23％に対し米国63％） [32]。 \nつまり、 「日本はAIに対する深い理解はないが、楽観的に捉え...",
    "content_length": 905,
    "created_at": "2025-05-12T10:04:28.769663+00:00",
    "updated_at": "2025-05-12T10:04:28.769664+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[56]": {
    "status": "pending",
    "content": "54 \n \n実施タイミング \n \n図 5-4: 導入プロセスとセキュリティ担当の該当フェーズ \n \nリスク管理は、導入時から運用時にわたり、継続的に幾度も実施されるものです。ただ、工程（特定・\n分析・評価・対応）によって、その実施タイミングは僅かに異なると考えられます。リスク対応は、対策\nごとに異なるタイミングで実施されますし、組織ごとに各対応のタイミングは異なります。一方、それ以\n外の3工程については、一般的な推奨タイミングを述べます。 \n図 5-4は、2.4.2で定義した、生成AI導入プロセスにおけるPDCAの1サイクルです。その1サイク\nル内のどこでリスクアセスメントをすればよいかを以下に記載します。 \n \n リスク特定・分析・評価（まとめて「リスクアセスメント」と称す） \n特定の期間を取り、3工程をまとめて実施。 \n 1サイクル目の「要件定義」時 \n理想的には 「運用・評価」時より前の各工程（ 「構想策定」「要件定義」「設計」「テスト・デプロ\nイ」 ）で毎回リスクアセスメントを実施すべきですが、現実的には、初回サイクル時には何かと\n不明点が多く、毎回リスクアセスメントを実施しても十分な結果が得られない（費用対効果が\n見込めない）場合も多いでしょう。そこで本書では、 「要件定義」を必ず実施すべきタイミング\nと定めます （もし1回のみの実施となるなら、ここで実施します） 。リスクアセスメントはなる\nべく早期段階での実施がよいですが、初回サイクルでは何かと不明点が多いため、 「構想策定」\nフェーズでの実施が難しいと考えた結果の推奨です。 \n \n 1サイクル目の「運用・評価」時 \n定期的なリスクアセスメント実施を推奨します。現在、生成AIは発展途上であり、変化が激し\nいため、新たなリスクが明らかになるかもしれません。それを反映して、定期的な実施を推奨し\nます。 \n \n 2サイクル目以降の「要件定義」時 \n生成AIシステムに何らかの改修を行う場合は、2サイクル目のPDCAを実施します。この時\nには、再度「要件定義」時にリスクアセスメントを実施しましょう。",
    "content_summary": "54 \n \n実施タイミング \n \n図 5-4: 導入プロセスとセキュリティ担当の該当フェーズ \n \nリスク管理は、導入時から運用時にわたり、継続的に幾度も実施されるものです。ただ、工程（特定・\n分析・評価・対応）によって、その実施タイミングは僅かに異なると考えられます。リスク対応は、対策\nごとに異なるタイミングで実施されますし、組織ごとに各対応のタイミングは異なります。一方、それ以\n外の3工程については、一般的な推奨タイミングを述べます。 \n図 5-4は、2.4.2で定義した、生成AI導入プロセ...",
    "content_length": 895,
    "created_at": "2025-05-12T10:04:28.769580+00:00",
    "updated_at": "2025-05-12T10:04:28.769581+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[98]": {
    "status": "pending",
    "content": "96 \n \n[13] The Federal Oﬃce for Information Security, “Generative AI Models - Opportunities and Risks \nfor Industry and Authorities” Generative AI Models - Opportunities and Risks for Industry and \nAuthorities, 2024. [アクセス日: 2024-06]. \n[14] OWASP, “LLM AI Cybersecurity & Governance Checklist”, 2024-04-11, \nhttps://genai.owasp.org/wp-\ncontent/uploads/2024/05/LLM_AI_Security_and_Governance_Checklist-v1.1.pdf. [アクセス日: \n2024-06]. \n[15] O. Ovadia, M. Brief , M. Mishaeli, “Fine-Tuning or Retrieval? Comparing Knowledge Injection \nin LLMs”, Microsoft, 2023. [アクセス日: 2024-06]. \n[16] Anthropic, “Usage Policy”, 2024-06-06, https://www.anthropic.com/legal/aup. [アクセス日: \n2024-06]. \n[17] Google, “生成 AI の使用禁止に関するポリシー”, 2023-03-14, \nhttps://policies.google.com/terms/generative-ai/use-policy. [アクセス日: 2024-06]. \n[18] Open AI, “使用に関するポリシー”, 2024-01-10, https://openai.com/ja-JP/policies/usage-\npolicies/. [アクセス日: 2024-06]. \n[19] DAIR.AI, “Prompt Engineering Guide”, 2024, https://www.promptingguide.ai/jp. [アクセス\n日: 2024-06]. \n[20] Anthropic, “プロンプトライブラリ”, https://docs.anthropic.com/ja/prompt-library/library. \n[アクセス日: 2024-06]. \n[21] Google, “Generative AI prompt samples”, 2024-06-14, https://cloud.google.com/vertex-\nai/generative-ai/docs/prompt-gallery. [アクセス日: 2024-06]. \n[22] OpenAI, “Prompt examples”, https://platform.openai.com/docs/examples. [アクセス日: 2024-\n06]. \n[23] 文化庁, “令和5年度著作権セミナー AIと著作権”, 2023-06, \nhttps://www.bunka.go.jp/seisaku/chosakuken/pdf/93903601_01.pdf. [アクセス日: 2024-06]. \n[24] ワンマーケティング株式会社, “イノベーター理論とは？”, 2023-04-04, \nhttps://www.onemarketing.jp/contents/innovation-theory_re/. [アクセス日: 2024-06]. \n[25] E. Dreibelbis, “Samsung Software Engineers Busted for Pasting Proprietary Code Into \nChatGPT”, 2023-04.  \n[26] 東京新聞, “生成AI使いコンピューターウイルス作成疑い 警視庁が男を再逮捕”, 2024-05-28, \nhttps://www.tokyo-np.co.jp/article/329884.  \n[27] 日本経済新聞, “ChatGPTで資料作成、実在しない判例引用 米国の弁護士” 日本経済新聞, \n2023-05-31.  \n[28] G. Rohan, “ChatGPT cited ‘bogus’ cases for a New York federal court ﬁling. The attorneys \ninvolved may face sanctions.” CNBC, 2023-05-30.",
    "content_summary": "96 \n \n[13] The Federal Oﬃce for Information Security, “Generative AI Models - Opportunities and Risks \nfor Industry and Authorities” Generative AI Models - Opportunities and Risks for Industry and \nAuthorities, 2024. [アクセス日: 2024-06]. \n[14] OWASP, “L...",
    "content_length": 2041,
    "created_at": "2025-05-12T10:04:28.769694+00:00",
    "updated_at": "2025-05-12T10:04:28.769695+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[61]": {
    "status": "pending",
    "content": "59 \n \n次に発生可能性の決定では、そのリスクの組織内での実際の発生確率を基準とします。今回は、そのリ\nスク発生が、ユーザ起因か攻撃者起因かという点でランク分けを行いました。但し、影響度や発生可能性\nの判定基準は組織によって変化するため、各組織で明確な基準を設け、多角的な視点からリスク分析を\n行うことが重要です。 \n各リスクの分析結果が表 5-3です。 \n \n表 5-3: リスク分析 \n \n \n手順b) リスクマトリクスの作成 \nリスクマトリクスでは、ここまでにランク分けした各リスクを、視覚的に比較できます。今回のリスク\nマトリクスは図 5-6で、 表 5-3でランク分けしたリスクをマッピングしました。 今回のリスクの中では、\n最も大きいものが「機密情報の漏洩」 、次点が「ハルシネーション」でした。 \n \n図 5-6: リスクマトリクス分析",
    "content_summary": "59 \n \n次に発生可能性の決定では、そのリスクの組織内での実際の発生確率を基準とします。今回は、そのリ\nスク発生が、ユーザ起因か攻撃者起因かという点でランク分けを行いました。但し、影響度や発生可能性\nの判定基準は組織によって変化するため、各組織で明確な基準を設け、多角的な視点からリスク分析を\n行うことが重要です。 \n各リスクの分析結果が表 5-3です。 \n \n表 5-3: リスク分析 \n \n \n手順b) リスクマトリクスの作成 \nリスクマトリクスでは、ここまでにランク分けした各リスクを、視覚的...",
    "content_length": 376,
    "created_at": "2025-05-12T10:04:28.769592+00:00",
    "updated_at": "2025-05-12T10:04:28.769593+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[54]": {
    "status": "pending",
    "content": "52 \n \n \n図 5-2: さまざまな生成AIを用いて悪意あるプログラムを作成してしまうイメージ（一部DALL·E 3を用いて作成） \n \n上述の例以外にも架空の判例を生成AIが作り出し、それを元に作成した資料を事実確認が取れないま\nま裁判所に提出した結果、5000ドルの罰金が科されたといった事例 [27] [28] [29]も存在します。これ\nは生成AIにおけるハルシネーションに起因して発生したインシデントであり、ユーザが生成AIの出力\nした内容を精査していれば避けることが出来た事例です。 \n2024年6月時点では、生成AIの技術は発展途上です。そのため、今後もセキュリティインシデント\n事例は増加していくことが予想されます。 \n \n5.2 リスク管理全体の概観 \n5.1に記載したセキュリティインシデント事例の影響度や発生可能性を低減するため、組織はリスク管\n理を実施する必要があります。生成AIの場合も、基本的に従来システムと同様のリスク管理を行うこと\nが重要であると考えて間違いはありません。また、生成AIシステムはクラウドなどの既存技術を利用し\nて構築されている場合も多く、既存技術に対するリスク管理手法が組織に存在すれば、それを参考とし\nて活用できます。ただし、リスクには生成AI特有のものも多く存在するため、注意深く検討する必要が\nあります。 \n \nリスク管理とは \nリスク管理は、大まかに次の4工程を伴います。 \n リスク特定 \n導入検討中の生成AIシステムにどんなリスクが存在するかを洗い出す工程。より詳細には、組\n織の所有する資産とそれに紐づくリスクを順に特定します。",
    "content_summary": "52 \n \n \n図 5-2: さまざまな生成AIを用いて悪意あるプログラムを作成してしまうイメージ（一部DALL·E 3を用いて作成） \n \n上述の例以外にも架空の判例を生成AIが作り出し、それを元に作成した資料を事実確認が取れないま\nま裁判所に提出した結果、5000ドルの罰金が科されたといった事例 [27] [28] [29]も存在します。これ\nは生成AIにおけるハルシネーションに起因して発生したインシデントであり、ユーザが生成AIの出力\nした内容を精査していれば避けることが出来た事例です。 ...",
    "content_length": 699,
    "created_at": "2025-05-12T10:04:28.769576+00:00",
    "updated_at": "2025-05-12T10:04:28.769576+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[78]": {
    "status": "pending",
    "content": "76 \n \nA) 該当の業務に生成AIの利用を義務化 \nヒアリング事例の中では、週報作成のような、毎週同じ形式で書かれる反復的な特性を持つ\n報告文書等の作成に生成AIを活用するのは非常に効果的です。週報作成に生成AIを活用する\nことで作成に費やす時間を大幅に削減することも可能になるため、 生成AIの有効性を理解する\nという点においても非常に有用な施策であると考えられます。また、ドキュメントの誤字脱字\n添削やメールのドラフト作成など、通常の業務において避けて通れない作業で形式が確定して\nいるものについて、生成AIの利用を強制するという施策は、利用を通じてユーザの生成AIへ\nの理解を深める良い機会となり、利用率向上の一助となることが期待できます。 \n \nB) 効果的なプロンプト例を提示し、システムに組み込む \nシステム内に効果的なプロンプトテンプレートを組み込み、逐次呼び出すことで効果的な回\n答を出力できるようにする対策も効果的です。 通常、 生成AIから効果的な回答を得るためには、\n高度なプロンプトエンジニアリングの能力が必要となります。しかし、全てのユーザがその能\n力をもち、適切に活用できているわけではありません。そこで活用できるのがプロンプトテン\nプレートですが、ユーザが個々で調査を行い、プロンプトを作成するのは難易度が高いことが\n想像されます。 \nこの課題への対策として考えられるのは、社内システムの機能として、プロンプトテンプレ\nートを選択可能な仕組みを導入することです。この仕組みを導入することにより、ユーザは簡\n単に効果的なプロンプトを元に生成された回答を得ることができるようになり、 生成AIの効果\nを実感し、業務において生成AIを活用したいと感じるための一助となることが期待できます。\n以下にその実装イメージを示します。 \n \n \n図 6-1: プロンプトテンプレート選択イメージ①",
    "content_summary": "76 \n \nA) 該当の業務に生成AIの利用を義務化 \nヒアリング事例の中では、週報作成のような、毎週同じ形式で書かれる反復的な特性を持つ\n報告文書等の作成に生成AIを活用するのは非常に効果的です。週報作成に生成AIを活用する\nことで作成に費やす時間を大幅に削減することも可能になるため、 生成AIの有効性を理解する\nという点においても非常に有用な施策であると考えられます。また、ドキュメントの誤字脱字\n添削やメールのドラフト作成など、通常の業務において避けて通れない作業で形式が確定して\nいるものに...",
    "content_length": 807,
    "created_at": "2025-05-12T10:04:28.769641+00:00",
    "updated_at": "2025-05-12T10:04:28.769642+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[100]": {
    "status": "pending",
    "content": "98 \n \n[43] WIRED, “ディープフェイク・ポルノに勝てるのは、テイラー・スウィフトしかいない”, 2024-\n01-31, https://wired.jp/article/taylor-swift-deepfake-porn-artiﬁcial-intelligence-pushback/. [アク\nセス日: 2024-06]. \n[44] 総務省, “海外の動向及び国際的な議論の動向”, 2019-02, \nhttps://www.soumu.go.jp/main_content/000604970.pdf. [アクセス日: 2024-06]. \n[45] Pew Research Center, “Looking ahead to 2050, Americans are pessimistic about many aspects of \nlife in U.S.”, https://www.pewresearch.org/short-reads/2019/03/21/looking-ahead-to-2050-\namericans-are-pessimistic-about-many-aspects-of-life-in-u-s/. [アクセス日: 2024-06]. \n[46] Pew Research Center, “An update on our research into trust, facts and democracy”, 2019-06-05, \nhttps://www.pewresearch.org/2019/06/05/an-update-on-our-research-into-trust-facts-and-\ndemocracy/. [アクセス日: 2024-06]. \n[47] 内閣府, “米国の AI権利章典（AI Bill of Rights）について”, 2022-12, \nhttps://www8.cao.go.jp/cstp/ai/ningen/r4_2kai/siryo3.pdf. [アクセス日: 2024-06]. \n[48] NIST, “AI RISK MANAGEMENT FRAMEWORK”, https://www.nist.gov/itl/ai-risk-\nmanagement-framework. [アクセス日: 2024-06]. \n[49] 日本貿易振興機構, “バイデン米政権、AIの安全性に関する新基準などの大統領令公表”, 2023-\n11-01, https://www.jetro.go.jp/biznews/2023/11/495833ae70119dbf.html. [アクセス日: 2024-\n06]. \n[50] Homeland Security, “Promoting AI Safety and Security”, 2024-05-13, \nhttps://www.dhs.gov/ai/promoting-ai-safety-and-security. [アクセス日: 2024-06]. \n[51] NIST, “NIST Launches ARIA, a New Program to Advance Sociotechnical T esting and Evaluation \nfor AI”, 2024-05-28, https://www.nist.gov/news-events/news/2024/05/nist-launches-aria-new-\nprogram-advance-sociotechnical-testing-and. [アクセス日: 2024-06]. \n[52] 日本貿易振興機構, “EU 一般データ保護規則（GDPR）について”, \nhttps://www.jetro.go.jp/world/europe/eu/gdpr/. [アクセス日: 2024-06]. \n[53] 駐日欧州連合代表部, “欧州委員会、データと人工知能に関する戦略を発表”, 2020-02-19, \nhttps://www.eeas.europa.eu/delegations/japan/%E6%AC%A7%E5%B7%9E%E5%A7%94%E5%\n93%A1%E4%BC%9A%E3%80%81%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A8%E4\n%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%E3%81%AB%E9%96%A2%E3%81%99\n%E3%82%8B%E6%88%A6%E7%95%A5%E3%82%92%E7%99%BA%E8%A1%A8_ja. [アクセ\nス日: 2024-06]. \n[54] 日本貿易振興機構, “欧州委、AI倫理ガイドラインを発表”, 2019-04-15, \nhttps://www.jetro.go.jp/biznews/2019/04/17aa7120c9481135.html. [アクセス日: 2024-06]. \n[55] Ledge.ai, “AGIと超知能がもたらす未来を予見”, 2024-06-08, \nhttps://ledge.ai/articles/former_openai_member_warns_situational_awareness. [アクセス日:",
    "content_summary": "98 \n \n[43] WIRED, “ディープフェイク・ポルノに勝てるのは、テイラー・スウィフトしかいない”, 2024-\n01-31, https://wired.jp/article/taylor-swift-deepfake-porn-artiﬁcial-intelligence-pushback/. [アク\nセス日: 2024-06]. \n[44] 総務省, “海外の動向及び国際的な議論の動向”, 2019-02, \nhttps://www.soumu.go.jp/main_conten...",
    "content_length": 2277,
    "created_at": "2025-05-12T10:04:28.769699+00:00",
    "updated_at": "2025-05-12T10:04:28.769700+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[15]": {
    "status": "pending",
    "content": "13 \n \n第2章 本書を最大限に活用するために \n本章では、セキュアな生成AIを導入・運用するために読者が持っておくべき基礎的な知識を記載しま\nす。また、第3章～第5章の概要および各章の対象読者についても記載します。 \n \n2.1 生成AIとは \n2.1.1 生成AIの定義 \n「AI （Artiﬁcial Intelligence、人工知能） 」は、一般的に、コンピュータによる知的な振る舞いを実現す\nる技術全般を指します。AIを実現する技術の1つであり、現在のAIの中核技術となっているのが「機械\n学習」です。機械学習は、データの背景にある法則をコンピュータで自動的に見つける技術と言えます。\n学習用データを用いて計算モデルが規則性を見つけるプロセスが「学習」 （もしくは訓練）です。学習済\nみの計算モデル（学習済みモデル）を使うことで、未知のデータに対して予測や判断ができます。 \n機械学習の中でも 「ディープラーニング」は、従来の機械学習では困難であった複雑なデータパターン\nの分析に優れています。ディープラーニングは、入力データと出力データの間に多層にわたる中間層と\n呼ばれる構造を設け、各中間層で異なる特徴量を抽出し、データを学習・判断するアルゴリズムです。多\n層化した中間層を持つ、この構造がディープラーニングと呼ばれる所以です。このディープラーニング\nの技術を活用した学習モデルを利用することで、AIは複雑な予測・判断などを行うことができます。 \n「生成AI」は、従来型のAIが単なる入力データの予測・判断をするのに対し、入力データから新しい\n創造物（コンテンツなど）を生成する技術の総称を意味します。一般的に、生成AIにはディープラーニ\nングが利用されており、特に、自然言語処理や画像処理といった技術を組み合わせて利用されます。 \n \n \n図 2-1: AIにおける生成AIの位置付け",
    "content_summary": "13 \n \n第2章 本書を最大限に活用するために \n本章では、セキュアな生成AIを導入・運用するために読者が持っておくべき基礎的な知識を記載しま\nす。また、第3章～第5章の概要および各章の対象読者についても記載します。 \n \n2.1 生成AIとは \n2.1.1 生成AIの定義 \n「AI （Artiﬁcial Intelligence、人工知能） 」は、一般的に、コンピュータによる知的な振る舞いを実現す\nる技術全般を指します。AIを実現する技術の1つであり、現在のAIの中核技術となっているのが「機...",
    "content_length": 802,
    "created_at": "2025-05-12T10:04:28.769482+00:00",
    "updated_at": "2025-05-12T10:04:28.769483+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[85]": {
    "status": "pending",
    "content": "83 \n \n要件②：汎用的な生成AIに対する透明性の確保 \n生成AIに対しては、 「学習データの詳細」 「学習・テストの過程」 「著作権保護の方針」に関するドキュ\nメントの提出を求め、汎用的なAIを利用するサービスを提供する事業者についても同様に 「透明性の義\n務」が求められています。 \n \n要件③：欧州の価値観に基づくAIの構築 \n生成AIの学習データや学習データから構築されたモデルの出力結果が、基本的人権やデータ保護規則\nを始めとする欧州の価値観に抵触しないようにすることが求められます。欧州外で作成されたAIモデル\nに含まれる欧州外のデータや価値観が欧州の価値観に沿わない出力を行うことで、欧州の価値観に沿っ\nた欧州のエコシステムの形成を阻害することを懸念しています。そのため、 “欧州の、欧州による、欧州\nのためのAI”を求めている背景があります。 \n \n最後に、AI規制法には興味深い一文が記載されているため、それを紹介します。 「AIは、人間の幸福\n度を高めることを究極の目的として、 人間のためのツールとして機能すべき」 という一文です。 これは、\nAIの位置づけを明確にしていますが、ここからは、 「人間に近いAIが作られること」が想定されている\nように読み取れます。 \n今現在、人間のようなAI、つまり「AGI（汎用人工知能） 」の構築を目指した各国の競争があります \n[55] 。AGIの特性は、 「さまざまなタスクをこなす汎用的な能力」「新たな情報を自己学習する能力」 「独\n自の判断をこなす能力」といえます [57]。現在盛んに開発されている生成AIは、このAGIを作り上げ\nるための大きな礎とも捉えることができます。未来学者のレイ・カーツワイルは、 「2029年にはAIが人\n間並の知能をもつ」と語っています [58]。この発言を踏まえると、AI規制法の先の一文はそう遠くない\n未来にAGIが作られ、 「上記3つの能力を持つので、AIが人格を持った」 「人よりも有能なAIが現れた」\nと言われる可能性を踏まえ追加された前提条件のようにも捉えることができます。本書の記載時点では、\n荒唐無稽で冗談のような話に思えますが、現在多くの科学者が目指している未来でもあり、そのような\nAIが作り上げられるのはすぐそこまで来ているのかもしれません。 \n \n7.3 日本 \n現在、大規模で汎用的な生成AIの構築については、米国が独走している状況です。その裏で欧州は、\n個人と権利の保護を中心とした法規制に取り組み、同時に欧州内のAI開発を進めています。ここでは、\n日本の取り組みについて触れていきます。 \n \nAI開発の未来 \n2023年の日本のAIに対する投資額は6.8億米国ドルであり、世界12位です。一方、現在の生成AIモ\nデル開発の覇権を担う米国は、日本に比べ約100倍、2位の中国と比べても約9倍の投資を行うなど、\n圧倒的な資金をAIに投じており、投資額の競争で米国に追いつくことは容易ではありません。",
    "content_summary": "83 \n \n要件②：汎用的な生成AIに対する透明性の確保 \n生成AIに対しては、 「学習データの詳細」 「学習・テストの過程」 「著作権保護の方針」に関するドキュ\nメントの提出を求め、汎用的なAIを利用するサービスを提供する事業者についても同様に 「透明性の義\n務」が求められています。 \n \n要件③：欧州の価値観に基づくAIの構築 \n生成AIの学習データや学習データから構築されたモデルの出力結果が、基本的人権やデータ保護規則\nを始めとする欧州の価値観に抵触しないようにすることが求められます。欧州...",
    "content_length": 1264,
    "created_at": "2025-05-12T10:04:28.769658+00:00",
    "updated_at": "2025-05-12T10:04:28.769659+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[62]": {
    "status": "pending",
    "content": "60 \n \n5.3.4 評価の例 \nリスク評価では、リスク全体から、対応/非対応の閾値決めや対応優先度付けを行います。引き続きリ\nスクマトリクスを使用します。 \n今回の閾値決めでは、 図 5-6のリスクマトリクスにてMedium （中程度）以上とされたリスクに対し、\n優先的にリスク対策を行うこととします。 図 5-7中、 赤色の点線で示した範囲内のリスクが該当します。\n実際にはさらに、各リスクに対する優先度付けを、対策に必要な費用および工数等の費用対効果の観点\nから行う手順を実施します。 \n \n図 5-7: リスクマトリクスにおける閾値決定 \n \n5.4 リスク対応 \nリスク対応では、リスクアセスメントにおいて決定したリスク対策を実施します。本節では、生成AI\n特有の対策方法に注目して記載します。生成AI特有といっても、基本的な対策の考え方には従来の考え\n方に共通する部分が多く、まず基本となる考え方として、 「多層防御」に触れます。 \nまた、 全てのリスク対策を実施しても残存リスクが完全にゼロになることはありません。 対策に過剰な\nコストやリソースをかけるのではなく、残存リスクの受容も選択肢の一つとして経営者と一緒に検討し\nていくことが重要です。",
    "content_summary": "60 \n \n5.3.4 評価の例 \nリスク評価では、リスク全体から、対応/非対応の閾値決めや対応優先度付けを行います。引き続きリ\nスクマトリクスを使用します。 \n今回の閾値決めでは、 図 5-6のリスクマトリクスにてMedium （中程度）以上とされたリスクに対し、\n優先的にリスク対策を行うこととします。 図 5-7中、 赤色の点線で示した範囲内のリスクが該当します。\n実際にはさらに、各リスクに対する優先度付けを、対策に必要な費用および工数等の費用対効果の観点\nから行う手順を実施します。 \n \n...",
    "content_length": 531,
    "created_at": "2025-05-12T10:04:28.769595+00:00",
    "updated_at": "2025-05-12T10:04:28.769596+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[83]": {
    "status": "pending",
    "content": "81 \n \n7.2.1 米国の場合 \nTransformerモデルに関する論文の発表、ChatGPTサービスの開始、その他の主だった生成AIサービ\nスを提供するなど米国のAI市場が急速な発展するなかで米国民は不安を感じています。 \n2019年2月、トランプ前大統領は、米国がAI技術の開発と利用においてグローバルリーダーの地位\nを維持し強化する「人工知能における米国のリーダーシップ維持のための大統領命令」に署名しました \n[44]。Pew Research Centerが2019年に公表した結果では、米国民のうち82%が、AIやロボットを用い\nた業務の自動化によって、37％が雇用を奪われるという認識をもっていることが示されました [45]。加\nえて、その後実施された大統領選でも相手陣営を貶めるためにAIを使い作られたディープフェイクがソ\nーシャルネットワークを中心に拡散され、AIに対する不信感が高まりました [46]。米国民が、生成AI\nの発展がもたらしたこれらの弊害に対して不安を抱いているという状況を踏まえ、2021年1月に就任し\nたバイデン大統領は、プライバシーの原則を含む公民権や民主主義的価値をより強く守る方針を打ち出\nし、国民が持つ権利の保護を示しました [47]。 \n米国科学技術政策局（OSTP）は、バイデン大統領の方針を基に、2021年10月から「AI権利章典の\n青写真」の作成を開始し、翌2022年10月に公表しました [47]。また、新技術である生成AIの有用性\nと裏に潜む危険性のバランスを取るべく、2023年1月に米国商務省国立標準技術研究所（NIST）はAI \nRMFを発行し、法規制による明示的な産業活動の締め付けを避け、ガイドラインを公表することで企業\nに社会的責任を果たすことを求める市場に働きかけを促す選択をしました [48]。 \nこれらに続き、バイデン大統領は2023年10月に「人工知能（AI）の安心、安全で信頼できる開発と\n利用に関する大統領令」に署名を行い、これまでのAIにおける米国のリーダーシップの強化やAIエコ\nシステムへの支援などAI市場の支援を継続しながら、安全性とセキュリティ基準の策定やプライバシー\nの保護、公平性や市民権の推進、責任あるAIについて言及しました [49]。加えて、2024年4月にAIの\n安全とセキュリティに関する諮問委員会 （AISSB）を設置し、AIに対する、もしくはAIを用いた攻撃な\nどに対して安全を確保するための推奨事項を示していく方針を打ち出しました [50]。 \n2024年5月にAIの能力や影響などのリスクを評価するプログラムを開始し、常に変化し続けるAIの\nリスクに対して継続的かつ流動的に対応できる体制を構築しています [51]。また、2023年に議会に提出\nされたAI関連法案は181本に上るなど諸外国と足並みを揃えるために米国も法規制を行う機運が高ま\nっています [32]。 \n \n7.2.2 EU の場合 \n現時点で高度な生成AIサービスを十全に活用するためには、クラウドサービスを利用することが主流\nといえます。クラウドと関連性の強い欧州の法規といえば、2018年に施行されたGDPR（EU一般デー\nタ保護規則）が連想されます。GDPRは、利用に関する事前通知、データの処理、利活用、移転のほか、\nデータの取扱いについて詳細な要件を定義し、違反した場合には多額の罰金が課されます。この法規に\nより、EU市民の個人データおよび基本的人権を保護することができます [52]。",
    "content_summary": "81 \n \n7.2.1 米国の場合 \nTransformerモデルに関する論文の発表、ChatGPTサービスの開始、その他の主だった生成AIサービ\nスを提供するなど米国のAI市場が急速な発展するなかで米国民は不安を感じています。 \n2019年2月、トランプ前大統領は、米国がAI技術の開発と利用においてグローバルリーダーの地位\nを維持し強化する「人工知能における米国のリーダーシップ維持のための大統領命令」に署名しました \n[44]。Pew Research Centerが2019年に公表した結果で...",
    "content_length": 1492,
    "created_at": "2025-05-12T10:04:28.769653+00:00",
    "updated_at": "2025-05-12T10:04:28.769654+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[1]": {
    "status": "pending",
    "content": "テキスト生成AIの \n導入・運用ガイドライン \n \n \n \n2024年7月 \n独立行政法人情報処理推進機構 \n産業サイバーセキュリティセンター \n中核人材育成プログラム 7期生 \n生成AIのセキュリティリスクと対策プロジェクト \n（DALL·E 3を用いて作成）",
    "content_summary": "テキスト生成AIの \n導入・運用ガイドライン \n \n \n \n2024年7月 \n独立行政法人情報処理推進機構 \n産業サイバーセキュリティセンター \n中核人材育成プログラム 7期生 \n生成AIのセキュリティリスクと対策プロジェクト \n（DALL·E 3を用いて作成）",
    "content_length": 131,
    "created_at": "2025-05-12T10:04:28.769433+00:00",
    "updated_at": "2025-05-12T10:04:28.769443+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[7]": {
    "status": "pending",
    "content": "5 \n \n1.1.2 AI 発展の歴史 \n生成AIを含む近年のAIの目覚ましい発展は、これまでの技術開発が実を結んだ結果といえます（表 \n1-1） 。AIと呼ばれる技術の歴史は古く、イギリスの数学者アラン・チューリングによる1950年の著書\n『計算する機械と人間』で初めてAIの概念が提唱されたことを発端に、1956年のダートマス会議で「人\n工知能 （Artiﬁcial Intelligence） 」という用語が初めて公式に使われ、AIの研究分野が誕生しました。この\n時代には、コンピュータによる「推論」や「探索」の研究が進展し、迷路の攻略や定理の証明のような、\n明確かつ単純な問題の解決が可能になりました。 \n1970年代には、主にシンボリックAI（Symbolic AI）として知られるアプローチに焦点を当てた研究\nがなされていました。シンボリックAIは、明確なルールに基づく知識表現と演繹を重視したアプローチ\nであり、エキスパートシステムと呼ばれる特定の専門領域で専門知識をルールとして組み込まれました。\nこのシステムは、組み込まれたルールに基づいて問題解決を行うことが可能であり、大きな成果を得る\nことができました。 \n一方、1990年代以降のAI研究はニューラルネットワーク（Neural AI）を基盤とした新たなアプロー\nチへと進化しました。ニューラルネットワークは、脳の神経回路を模倣したモデルであり、入力層、出力\n層、隠れ層から構成され、層と層の間には、ニューロンの繋がりの強さを示す重みがあります。これを多\n数組み合わせることで、幅広い応用が可能となり、現在のAI技術の基盤を築き、特に画像認識や音声認\n識などのパターン認識の分野で大きな成果を得ることができました。 \nそして、2010年代にはディープラーニングと呼ばれる手法が登場したことで、高精度な予測が現実的\nとなり、AIが更なる脚光を浴びることになりました。 \nさまざまな言語処理タスクへのAI活用は、2017年頃に、Transformerと呼ばれるディープラーニング\nモデルがGoogleの研究者らによって開発され、続いてGPT、BERTが開発されたことで大きく推進し\nました。これが、テキスト生成を目的とするテキスト生成AIの発展へと繋がります。従来のAIがデー\nタから何らかの予測を得ることを目的とするのに対し、生成AIはデータを基に新たなデータを生成しま\nす。テキスト生成AIに関しては、OpenAI社によるChatGPTを皮切りにさまざまな大規模言語モデル\n（LLM）が開発されました。Google社のGemini（旧名：Bard）やAnthropic社のClaudeなどです。 \nこれらのサービスは前述のディープラーニングモデルを元に構築されているため、画像や音声のパタ\nーン認識、創造的なタスクにおいて卓越した性能を発揮しますが、シンボリックAIが得意とする明確な\nルールと論理に基づいた推論や演繹においては、まだ改善の余地があると言われています。",
    "content_summary": "5 \n \n1.1.2 AI 発展の歴史 \n生成AIを含む近年のAIの目覚ましい発展は、これまでの技術開発が実を結んだ結果といえます（表 \n1-1） 。AIと呼ばれる技術の歴史は古く、イギリスの数学者アラン・チューリングによる1950年の著書\n『計算する機械と人間』で初めてAIの概念が提唱されたことを発端に、1956年のダートマス会議で「人\n工知能 （Artiﬁcial Intelligence） 」という用語が初めて公式に使われ、AIの研究分野が誕生しました。この\n時代には、コンピュータによる「...",
    "content_length": 1270,
    "created_at": "2025-05-12T10:04:28.769462+00:00",
    "updated_at": "2025-05-12T10:04:28.769463+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[47]": {
    "status": "pending",
    "content": "45 \n \n＜透明性のある生成AIの例＞ \n \n図 4-8: 透明性のある生成AIの例 \n \n透明性確保の手段 \n透明性を確保・維持することは生成AIを活用する上で極めて重要です。多くの生成AIシステムは複\n雑なアルゴリズムと大量のデータを用いており、そのプロセスを完全に可視化するのは容易ではありま\nせん。本項では透明性を確保するために実施可能な手段の例を3点紹介します。 \n \n 学習データの開示依頼 \n学習データを可能な範囲で開示するようAI提供者へ依頼し、 データの出どころや内容に関する\n情報が提供されることで、生成AIの基盤となるデータが適切であることを確認できるため、学習\nデータの透明性確保に有効です。クラウドサービスの生成AIを利用している場合は、通知なしで\n学習データがアップデートされる場合があるため、定期的な確認が必要です。なお、 学習データは\nLLMの性能に直結する重要な情報であることから、開示されない可能性が十分に考えられますが、\n責任分界点の明確化のために学習データを確認する行動そのものが重要になります。 \n \n マスタープロンプトの設定 \nマスタープロンプトとは、ユーザが入力したプロンプトに加えて自動で付与されるプロンプト\nです。マスタープロンプトを設定することで、参照されたデータのURL ・パスの表示や、回答生\n成プロセスの説明を自動で行えば、透明性の確保におけるユーザの負担を軽減することができま\nす。 \n \n 定期的な内部監査や外部評価 \n専門知識を持つ人材が、生成AIの回答を定期的に評価することで、生成AIの回答が信頼に値\nするものか、また、コンプライアンスを遵守しているかを確認します。",
    "content_summary": "45 \n \n＜透明性のある生成AIの例＞ \n \n図 4-8: 透明性のある生成AIの例 \n \n透明性確保の手段 \n透明性を確保・維持することは生成AIを活用する上で極めて重要です。多くの生成AIシステムは複\n雑なアルゴリズムと大量のデータを用いており、そのプロセスを完全に可視化するのは容易ではありま\nせん。本項では透明性を確保するために実施可能な手段の例を3点紹介します。 \n \n 学習データの開示依頼 \n学習データを可能な範囲で開示するようAI提供者へ依頼し、 データの出どころや内容に関する\n...",
    "content_length": 722,
    "created_at": "2025-05-12T10:04:28.769559+00:00",
    "updated_at": "2025-05-12T10:04:28.769560+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[49]": {
    "status": "pending",
    "content": "47 \n \n 業務効率化の寄与 \n生成AIを導入することで幅広い分野で業務効率化を図ることができます。一例を挙げると、調\n査の時間短縮、各システムの自動化・連携、データ分析、アイデア出し等です。導入目的が業務\n効率化の場合、 生成AIの導入によってどの程度業務効率化が達成できたのかを測る必要があり\nます。業務効率化の測定について、定量評価が困難な面もありますが、評価手法としては生成\nAI導入前後の残業時間の推移を参考データとするほか、アンケートを実施して定性的に効果を\n確認することなどが考えられます。 \n \n 業務品質の改善、向上 \n業務知識の乏しい方でも生成AIを使用することにより、 知識豊富な方と同等の水準で業務を行\nうことができます。つまり、従来、業務知識の差異に伴って発生していた業務品質のばらつき\nが軽減され、導入企業全体の品質水準の向上が期待できます。また、文書の要約、添削、議事録\n作成など、 業務内容によっては既に人間が行うよりも生成AIが担う方が正確かつ迅速に処理で\nきることもあります。導入目的に業務品質の改善、向上が含まれる場合、業務品質を評価する\nための手法としては、アンケートやユーザインタビュー等があります。 \n \n 生成AIの社内普及率 \n導入した生成AIが利用されているか利用率を評価することで、 業務において積極的に利用され\nているかどうかを確認することができます。システムの普及について、類似点のある理論にマ\nーケティング分野において新しい商品が普及していく過程を分析した理論として、イノベータ\nー理論があります [24]。普及が進んでいく過程における利用者をイノベーター、アーリーアダ\nプター、アーリーマジョリティ、レイトマジョリティ、ラガードという5つの区分に分けてい\nます。",
    "content_summary": "47 \n \n 業務効率化の寄与 \n生成AIを導入することで幅広い分野で業務効率化を図ることができます。一例を挙げると、調\n査の時間短縮、各システムの自動化・連携、データ分析、アイデア出し等です。導入目的が業務\n効率化の場合、 生成AIの導入によってどの程度業務効率化が達成できたのかを測る必要があり\nます。業務効率化の測定について、定量評価が困難な面もありますが、評価手法としては生成\nAI導入前後の残業時間の推移を参考データとするほか、アンケートを実施して定性的に効果を\n確認することなどが考えら...",
    "content_length": 765,
    "created_at": "2025-05-12T10:04:28.769564+00:00",
    "updated_at": "2025-05-12T10:04:28.769565+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[90]": {
    "status": "pending",
    "content": "88 \n \n付録 \n用語集 \n用語 概要 \nAI \n（Artiﬁcial Intelligence：人工知能） \n人間の思考プロセスと同じような形で動作するコンピュータ\nープログラム、コンピュータ上で知的判断を下せるシステ\nム。 \nAI RMF（Artificial Intelligence Risk \nManagement Framework） \n米国商務省の国立標準技術研究所（NIST）がAIに関連する\nリスクを管理するために開発されたフレームワーク。 \nAPI（Application Programming \nInterface） \nソフトウェアやプログラム、Webサービスの間をつなぐ \nインターフェース。 \nAmazon Bedrock Amazon Web Service の生成AIアプリケーションを構築する\nために必要な幅広い機能を統合API経由で利用できるよう\nにするフルマネージドサービス。 \nAzure OpenAI Service Microsoft Azure のクラウドプラットフォーム上で提供され\nる、OpenAI社のAIサービス。 \nBERT \n（Bidirectional Encoder \nRepresentations from Transformers） \nGoogle社が開発した自然言語処理のためのディープラーニ\nングモデル。文脈を理解し、単語や文の意味表現を学習する\nために設計されているため、文章全体の文脈を考慮して、単\n語の意味を正確に捉えることに優れている。 \nCSRF（Cross Site Request Forgery） Web アプリケーションのユーザ認証やセッション管理の不\n備を突いて、サイトのユーザにWebアプリケーションに対\nする不正な処理を行わせる攻撃手法。 \nChatGPT OpenAI 社が提供している生成AIサービス。2024年6月時\n点での最新・最高性能モデルはChatGPT-4oである。 \nChatGPT Enterprise ChatGPT の全ての機能が利用でき、企業向けにアップデー\nトされたバージョン。企業利用を想定した管理コンソールを\n始め、入力データの暗号化、オプトアウト設定などのセキュ\nリティ機能も有する。 \nClaude Anthropic が提供している生成AIサービス。2024年6月時\n点での最新・最高性能サービスはClaude3 Opusである。 \nCopilot for Microsoft 365  OpenAI のGPT-4をベースにした大規模言語モデル。\n（LLM）を各Oﬃceアプリケーションに組み込み、生産性\nの向上や業務効率化を改善するためのツール。",
    "content_summary": "88 \n \n付録 \n用語集 \n用語 概要 \nAI \n（Artiﬁcial Intelligence：人工知能） \n人間の思考プロセスと同じような形で動作するコンピュータ\nープログラム、コンピュータ上で知的判断を下せるシステ\nム。 \nAI RMF（Artificial Intelligence Risk \nManagement Framework） \n米国商務省の国立標準技術研究所（NIST）がAIに関連する\nリスクを管理するために開発されたフレームワーク。 \nAPI（Application Pr...",
    "content_length": 1140,
    "created_at": "2025-05-12T10:04:28.769675+00:00",
    "updated_at": "2025-05-12T10:04:28.769676+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[80]": {
    "status": "pending",
    "content": "78 \n \n第7章 各国の動向 \n7.1 開発と投資について \nGoogle社の 「Attention Is All You Need」 （Transformerモデルに関する論文 ：2017年） [30]の発表を\n皮切りに、それまでと次元の異なる高精度なAIが多く開発されるようになりました。現時点において日\n本で最も有名な生成AIは、OpenAI社のChatGPTですが、 [31]。 無論それ以外にもGeminiやClaude、\nLlama 3などが、高度な生成AIとして広く認識されています。ここでは、これらの主な生成AIと、それ\nらに追従していく各国のAI開発について記載します。 \n \n7.1.1 米国について \n生成AIは、多くの学習データを学習させることで、AIモデルの推論能力を高めています。学習には大\n量のデータを処理する性能と、それを実現するリソースやコストが必要です。そのため、推論能力を向上\nさせたモデルを開発するには、より高い設備性能と多くの資本が求められます。 \n最も処理性能の高い生成AIの開発元もしくは業務提携先の多くには、世界で有数の資金力を持つ企業\nの数々が揃っており、特に米国企業が多いです。それらの企業は、多大な資本を武器に、大規模データを\n処理するスーパーコンピュータを用いたAIモデルの開発を行っています。AIの権威的なドキュメント\nであるAI Index Report [32]では、2023年までに開発されたAIモデルに利用されたコンピュータの計算\n処理速度が示されています（図 7-1） 。 \n \n図 7-1: AIモデルに利用されたコンピュータの計算処理速度 \n(出典)Stanford University, Artiﬁcial Intelligence Index Report 2024 p51 [32]",
    "content_summary": "78 \n \n第7章 各国の動向 \n7.1 開発と投資について \nGoogle社の 「Attention Is All You Need」 （Transformerモデルに関する論文 ：2017年） [30]の発表を\n皮切りに、それまでと次元の異なる高精度なAIが多く開発されるようになりました。現時点において日\n本で最も有名な生成AIは、OpenAI社のChatGPTですが、 [31]。 無論それ以外にもGeminiやClaude、\nLlama 3などが、高度な生成AIとして広く認識されています。...",
    "content_length": 782,
    "created_at": "2025-05-12T10:04:28.769646+00:00",
    "updated_at": "2025-05-12T10:04:28.769646+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[34]": {
    "status": "pending",
    "content": "32 \n \n以下に3つの導入環境について説明します。 \n \n オンプレ型 \nオンプレ型とは、自社で保有するサーバ上にAIサーバを構築し運用することで組織に生成AIを導入\nする方式のことです。全てのリソースを完全に自社の管理下に置くことができるためカスタマイズの自\n由度が高く、情報流出等のセキュリティリスクを抑えることができます。しかし、環境を構築するために\nは高度な専門知識が必要となり、多くのコストや開発期間がかかる点に注意が必要です。 \n \n クラウド型 \nクラウド型とは、クラウドサービスを利用して組織に生成AIを導入する方式のことです。現在、各ク\nラウドプロバイダーから生成AIを導入するためのさまざまなサービスが提供されています。オンプレ環\n境に生成AIを導入する場合と比べて導入難易度が低く、管理の手間も少なく済みます。しかし、入出力\nデータが外部サーバに保存されるなどのセキュリティリスクがあり、入力データを学習許可させないオ\nプトアウト申請などのセキュリティの検討が必要となります。また、サービスごとに設定できる内容も\n異なるため、導入前に各サービスの仕様や制約をしっかりと確認することも必要です。 \nまたクラウド環境を利用した環境構築において、 担当者に割り振る権限の調整が重要となります。 組織\n内でRAG環境を構築する場合、割り当てられた担当者の権限によっては、利用が制限される機能が存在\nします。そのため、円滑な生成AIシステムの導入にあたり、担当者への権限付与の設定が重要です。 \nクラウド型には利用するクラウドの形式によって、さらにPaaS型とSaaS型の2種類が存在します。\nSaaS型を利用する際は特に利用規約やセキュリティについて留意しましょう。 \n \n PaaS型 \nPaaS型は、モデルの開発や既存モデルの利用・デプロイを簡素化するためのプラットフォーム\nを提供するサービスのことです。PaaS型のサービスを利用することで、生成AIシステムを構築\nする上でネックとなるリソースをアウトソーシングすることができ、また、提供されているさま\nざまな機能を活用することで効率的に開発を行うことができます。セキュリティについてもサー\nビス提供者側で対策を講じている場合が多く、一定のセキュリティレベルが担保されています。",
    "content_summary": "32 \n \n以下に3つの導入環境について説明します。 \n \n オンプレ型 \nオンプレ型とは、自社で保有するサーバ上にAIサーバを構築し運用することで組織に生成AIを導入\nする方式のことです。全てのリソースを完全に自社の管理下に置くことができるためカスタマイズの自\n由度が高く、情報流出等のセキュリティリスクを抑えることができます。しかし、環境を構築するために\nは高度な専門知識が必要となり、多くのコストや開発期間がかかる点に注意が必要です。 \n \n クラウド型 \nクラウド型とは、クラウドサービス...",
    "content_length": 978,
    "created_at": "2025-05-12T10:04:28.769528+00:00",
    "updated_at": "2025-05-12T10:04:28.769528+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[5]": {
    "status": "pending",
    "content": "5.4.1 多層防御 ......................................................................................................... 61 \n5.4.2 チェックリストの作成 .................................................................................... 64 \n5.4.3 生成AIにおける最新の攻撃手法 ................................................................... 66 \n5.5 実機検証 ................................................................................................................. 67 \n5.5.1 ガードレールの実装 ....................................................................................... 67 \n5.5.2 RAGにおけるアクセス管理の実装 ................................................................ 70 \n第6章 組織ヒアリング分析 ............................................................................................... 71 \n6.1 ヒアリング結果から見る組織の生成AIとの在り方 ............................................. 71 \n6.1.1 導入目的とプロセス ....................................................................................... 71 \n6.1.2 セキュリティとガイドライン ......................................................................... 72 \n6.1.3 ユーザのフィードバック ................................................................................ 73 \n6.1.4 RAGを業務に活用する上での課題 ................................................................ 74 \n6.2 生成AIシステム導入に際した懸念事項 ................................................................ 74 \n第7章 各国の動向 ............................................................................................................. 78 \n7.1 開発と投資について ............................................................................................... 78 \n7.1.1 米国について .................................................................................................. 78 \n7.1.2 欧州の生成AI ................................................................................................. 79 \n7.2 法規制について ...................................................................................................... 80 \n7.2.1 米国の場合 ...................................................................................................... 81 \n7.2.2 EUの場合 ....................................................................................................... 81 \n7.3 日本 ........................................................................................................................ 83 \n第8章 終わりに ................................................................................................................. 86 \n8.1 あとがき ................................................................................................................. 86 \n8.2 謝辞 ........................................................................................................................ 87 \n付録  ................................................................................................................................... 88 \n用語集 ................................................................................................................................ 88 \n参照文献 ............................................................................................................................. 95",
    "content_summary": "5.4.1 多層防御 ......................................................................................................... 61 \n5.4.2 チェックリストの作成 .................................................................................... 64 \n5.4.3 生成AIにおける最新の攻撃手法 ....",
    "content_length": 3089,
    "created_at": "2025-05-12T10:04:28.769457+00:00",
    "updated_at": "2025-05-12T10:04:28.769458+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[10]": {
    "status": "pending",
    "content": "8 \n \n2024年3月にICT市場調査コンサルティング企業である株式会社MM総研がプレスリリースを行っ\nた 「生成AI／LLMの国内利活用動向調査2024」 [5]によると、 「導入にあたって課題を感じている企業\nは97％」 （図 1-4）と、生成AIを組織として導入するにはほぼ全ての組織で何かしらの課題感を抱えて\nいるといった結果が示されました。 \n \n \n図 1-4: 生成AIを導入する上での課題 \n（出典）MM総研 \n \n図 1-4より、突出している課題があるわけではなく、幅広い課題を抱えていることが分かります。これ\nは、生成AIへの理解不足が起因となって、漠然とした課題認識、不安感が生じていることが見て取れま\nす。 \n \n1.2 本書の作成目的 \n生成AI技術の急速な発展に伴い、国家主導で多くの組織にて生成AIの利用が推進されています。た\nとえば経済産業省（METI）は生成AIに関する開発支援や計算資源提供など、組織の生成AI利用推進に\n向けて、さまざまな取り組みを実施しています。我々のプロジェクトも、組織への生成AI利用を推進し\nていきたいという想いをもとに立ち上げました。 \nその一方で、生成AIを利用したいと考えている組織の中でも導入に踏み切れないといった場合や、導\n入したものの、現在の適切な運用ができているのかという懸念を持っている組織もあることが想定され\nます。我々はこれらの要因を「組織の生成AIに対する漠然とした不安感」と捉えています。組織からす\nると、1.1.4に記載した潜在的な課題の存在を認識できるものの、より具体的に“セキュリティリスク”\nや“リスク対策”に落とし込むことは難しく、その困難さが漠然とした不安感に繋がると推測していま\nす。",
    "content_summary": "8 \n \n2024年3月にICT市場調査コンサルティング企業である株式会社MM総研がプレスリリースを行っ\nた 「生成AI／LLMの国内利活用動向調査2024」 [5]によると、 「導入にあたって課題を感じている企業\nは97％」 （図 1-4）と、生成AIを組織として導入するにはほぼ全ての組織で何かしらの課題感を抱えて\nいるといった結果が示されました。 \n \n \n図 1-4: 生成AIを導入する上での課題 \n（出典）MM総研 \n \n図 1-4より、突出している課題があるわけではなく、幅広い課題を抱...",
    "content_length": 743,
    "created_at": "2025-05-12T10:04:28.769470+00:00",
    "updated_at": "2025-05-12T10:04:28.769471+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[50]": {
    "status": "pending",
    "content": "48 \n \nユーザ全体に占めるイノベーターとアーリーアダプターの合計の割合が約16%とされています。\nこの普及率約16%にはキャズム（深い溝）が存在し、ここを越えられるかどうかで新しいシス\nテムが普及するかしないかが分かれるとされています（図 4-10） 。 \n生成AIシステムの導入においても、社内普及率が約16%に達するかという観点を1つの指標\nとして利用することができます。 \n \n \n図 4-10: イノベーター理論におけるユーザの区分と普及率の溝 \n \n セキュリティ \n導入した生成AIを評価するためにはユーザの業務に関する項目だけではなく、 セキュリティに\n関する項目も必要になります。運用担当者のみでセキュリティを評価することは困難であるた\nめ、セキュリティ担当者と協力して評価を行う必要があります。具体的な評価方法については\n5.2にて記述します。 \n \n4.4.2 ユーザとの情報共有 \n生成AIの運用において、フィードバックを適切に行うために運用担当者とユーザ間で密に情報交換を\nすることが重要です。適切な情報共有をすることで、生成AIの有効活用と継続的な改善に繋がります。\n以下に、運用担当者がユーザから得るべき情報とその活用方法について説明します。",
    "content_summary": "48 \n \nユーザ全体に占めるイノベーターとアーリーアダプターの合計の割合が約16%とされています。\nこの普及率約16%にはキャズム（深い溝）が存在し、ここを越えられるかどうかで新しいシス\nテムが普及するかしないかが分かれるとされています（図 4-10） 。 \n生成AIシステムの導入においても、社内普及率が約16%に達するかという観点を1つの指標\nとして利用することができます。 \n \n \n図 4-10: イノベーター理論におけるユーザの区分と普及率の溝 \n \n セキュリティ \n導入した生成AI...",
    "content_length": 538,
    "created_at": "2025-05-12T10:04:28.769566+00:00",
    "updated_at": "2025-05-12T10:04:28.769567+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  },
  "[79]": {
    "status": "pending",
    "content": "77 \n \n \n図 6-2: プロンプトテンプレート選択イメージ②。 \n \nC) セキュリティの担保された環境を構築し、利用を促す \n最後に、セキュリティが担保された環境を構築し、ユーザに安心感を与えることも効果的で\nす。具体的には3.2.5にて記載した、セキュリティが担保されたPaaS型サービスの利用や、社\n内ローカル環境に独自の生成AIシステムを構築し、 社内環境の中で回答を生成できるサービス\nの提供です。これによって社内情報の入力制限が不要となり、ユーザの不安感を軽減し、利用\n率の向上を促すことが期待できます。 \n \nこれらの対策例はあくまでも今回ヒアリングを実施した組織における対策であり、これらの対策\nを行ったからといって利用率の問題が必ず解消されるわけではありません。そのため、上述の対策\n例を参考にしつつも、自身の組織において何が利用率の低さの根本原因なのかを特定した上で、効\n果的な対策を講じていくことが重要です。",
    "content_summary": "77 \n \n \n図 6-2: プロンプトテンプレート選択イメージ②。 \n \nC) セキュリティの担保された環境を構築し、利用を促す \n最後に、セキュリティが担保された環境を構築し、ユーザに安心感を与えることも効果的で\nす。具体的には3.2.5にて記載した、セキュリティが担保されたPaaS型サービスの利用や、社\n内ローカル環境に独自の生成AIシステムを構築し、 社内環境の中で回答を生成できるサービス\nの提供です。これによって社内情報の入力制限が不要となり、ユーザの不安感を軽減し、利用\n率の向上を促...",
    "content_length": 418,
    "created_at": "2025-05-12T10:04:28.769643+00:00",
    "updated_at": "2025-05-12T10:04:28.769644+00:00",
    "file_path": "f55m8k0000003svn.pdf"
  }
}